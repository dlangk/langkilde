[["Map",1,2,9,10],"meta::meta",["Map",3,4,5,6,7,8],"astro-version","5.6.1","content-config-digest","8b1fd7b433211a31","astro-config-digest","{\"root\":{},\"srcDir\":{},\"publicDir\":{},\"outDir\":{},\"cacheDir\":{},\"compressHTML\":true,\"base\":\"/\",\"trailingSlash\":\"ignore\",\"output\":\"static\",\"scopedStyleStrategy\":\"attribute\",\"build\":{\"format\":\"directory\",\"client\":{},\"server\":{},\"assets\":\"_astro\",\"serverEntry\":\"entry.mjs\",\"redirects\":true,\"inlineStylesheets\":\"auto\",\"concurrency\":1},\"server\":{\"open\":false,\"host\":false,\"port\":4321,\"streaming\":true,\"allowedHosts\":[]},\"redirects\":{},\"image\":{\"endpoint\":{\"route\":\"/_image\"},\"service\":{\"entrypoint\":\"astro/assets/services/sharp\",\"config\":{}},\"domains\":[],\"remotePatterns\":[]},\"devToolbar\":{\"enabled\":true},\"markdown\":{\"syntaxHighlight\":{\"type\":\"shiki\",\"excludeLangs\":[\"math\"]},\"shikiConfig\":{\"langs\":[],\"langAlias\":{},\"theme\":\"github-dark\",\"themes\":{},\"wrap\":false,\"transformers\":[]},\"remarkPlugins\":[],\"rehypePlugins\":[],\"remarkRehype\":{},\"gfm\":true,\"smartypants\":true},\"security\":{\"checkOrigin\":true},\"env\":{\"schema\":{},\"validateSecrets\":false},\"experimental\":{\"clientPrerender\":false,\"contentIntellisense\":false,\"responsiveImages\":false,\"svg\":false,\"serializeConfig\":false,\"headingIdCompat\":false,\"preserveScriptOrder\":false},\"legacy\":{\"collections\":false}}","blog",["Map",11,12,41,42,81,82,110,111,136,137,169,170,204,205,230,231,259,260,288,289,317,318,340,341,372,373,413,414,442,443,468,469,503,504,536,537,580,581,606,607,628,629,672,673,711,712,740,741,787,788,819,820,864,865,887,888,919,920,942,943,980,981,1003,1004],"algorithms-are-unable-to-question-data",{"id":11,"data":13,"body":16,"filePath":17,"digest":18,"rendered":19,"legacyId":40},{"title":14,"pubDate":15},"Algorithms are Unable to Question Data","2018-01-17","### The Human Advantage: Reasoning Beyond Data\n\n**Humans have an amazing ability; We are able to reason about things that do not exist anywhere but in our minds.**  We\nexist simultaneously in a physical and imagined reality. Our ability as a society to establish a shared understanding of\nreality is what has lead us to dominate the world. It enables us to use money, invent things and trust each other.\n\n### Limitations of Supervised Learning\n\nThe most widely reported breakthroughs in machine learning in recent years have been in supervised learning. Given\nenough data state-of-the-art supervised learning algorithms can, without question, approximate behavior very well.\n\nHowever, the ability to replicate behavior is not how I think of intelligence. Supervised learning algorithms currently\nlack the ability to establish a shared understanding. Inherent in establishing a shared understanding is questioning\ndata and negotiating a mutually shared interpretation of events.\n\n### Supervised Learning Isnâ€™t General Intelligence\n\n**Donâ€™t get me wrong, supervised machine learning is extremely useful**. It will eliminate boring tasks and free up\nresources better spent elsewhere. But it will not lead to artificial general intelligence. Reading the news right now\nyou might be confused and think artificial general intelligence is just around the corner. It is not.\n\n**Some might say â€œbut what about AlphaGo?â€.**  I think AlphaGo is an amazing scientific and engineering accomplishment.\nIt makes me really excited. At the same time solving\na [perfect information](https://en.wikipedia.org/wiki/Perfect_information) game where the goal is very clear, i.e. score\nthe most points according to very specific rules, is not the same as reasoning under uncertainty the way humans do in\ntheir daily lives.\n\n### The Real Bottleneck: Questioning and Interpreting Data\n\n**The main bottleneck for supervised machine learning is that it requires you to specify the desired output through\nexamples**. Producing consistent examples describing the desired output is challenging as it requires negotiating\ninterpretations of data, questioning what is correct.\n\nLet this be an introduction to something I will be writing more about over the coming months. I am, along with a great\nteam, in the process of building a platform to help people establish a shared understanding of data.\n\n**We believe that even in a world pervaded by intelligent machines, people will remain invaluable because of their\njudgment.**","src/content/blog/algorithms-are-unable-to-question-data.md","f49a35f13840c288",{"html":20,"metadata":21},"\u003Ch3 id=\"the-human-advantage-reasoning-beyond-data\">The Human Advantage: Reasoning Beyond Data\u003C/h3>\n\u003Cp>\u003Cstrong>Humans have an amazing ability; We are able to reason about things that do not exist anywhere but in our minds.\u003C/strong>  We\nexist simultaneously in a physical and imagined reality. Our ability as a society to establish a shared understanding of\nreality is what has lead us to dominate the world. It enables us to use money, invent things and trust each other.\u003C/p>\n\u003Ch3 id=\"limitations-of-supervised-learning\">Limitations of Supervised Learning\u003C/h3>\n\u003Cp>The most widely reported breakthroughs in machine learning in recent years have been in supervised learning. Given\nenough data state-of-the-art supervised learning algorithms can, without question, approximate behavior very well.\u003C/p>\n\u003Cp>However, the ability to replicate behavior is not how I think of intelligence. Supervised learning algorithms currently\nlack the ability to establish a shared understanding. Inherent in establishing a shared understanding is questioning\ndata and negotiating a mutually shared interpretation of events.\u003C/p>\n\u003Ch3 id=\"supervised-learning-isnt-general-intelligence\">Supervised Learning Isnâ€™t General Intelligence\u003C/h3>\n\u003Cp>\u003Cstrong>Donâ€™t get me wrong, supervised machine learning is extremely useful\u003C/strong>. It will eliminate boring tasks and free up\nresources better spent elsewhere. But it will not lead to artificial general intelligence. Reading the news right now\nyou might be confused and think artificial general intelligence is just around the corner. It is not.\u003C/p>\n\u003Cp>\u003Cstrong>Some might say â€œbut what about AlphaGo?â€.\u003C/strong>  I think AlphaGo is an amazing scientific and engineering accomplishment.\nIt makes me really excited. At the same time solving\na \u003Ca href=\"https://en.wikipedia.org/wiki/Perfect_information\">perfect information\u003C/a> game where the goal is very clear, i.e. score\nthe most points according to very specific rules, is not the same as reasoning under uncertainty the way humans do in\ntheir daily lives.\u003C/p>\n\u003Ch3 id=\"the-real-bottleneck-questioning-and-interpreting-data\">The Real Bottleneck: Questioning and Interpreting Data\u003C/h3>\n\u003Cp>\u003Cstrong>The main bottleneck for supervised machine learning is that it requires you to specify the desired output through\nexamples\u003C/strong>. Producing consistent examples describing the desired output is challenging as it requires negotiating\ninterpretations of data, questioning what is correct.\u003C/p>\n\u003Cp>Let this be an introduction to something I will be writing more about over the coming months. I am, along with a great\nteam, in the process of building a platform to help people establish a shared understanding of data.\u003C/p>\n\u003Cp>\u003Cstrong>We believe that even in a world pervaded by intelligent machines, people will remain invaluable because of their\njudgment.\u003C/strong>\u003C/p>",{"headings":22,"localImagePaths":36,"remoteImagePaths":37,"frontmatter":38,"imagePaths":39},[23,27,30,33],{"depth":24,"slug":25,"text":26},3,"the-human-advantage-reasoning-beyond-data","The Human Advantage: Reasoning Beyond Data",{"depth":24,"slug":28,"text":29},"limitations-of-supervised-learning","Limitations of Supervised Learning",{"depth":24,"slug":31,"text":32},"supervised-learning-isnt-general-intelligence","Supervised Learning Isnâ€™t General Intelligence",{"depth":24,"slug":34,"text":35},"the-real-bottleneck-questioning-and-interpreting-data","The Real Bottleneck: Questioning and Interpreting Data",[],[],{"pubDate":15,"title":14},[],"algorithms-are-unable-to-question-data.md","anthropocentrism-alignment-and-personalization",{"id":41,"data":43,"body":46,"filePath":47,"digest":48,"rendered":49,"legacyId":80},{"title":44,"pubDate":45},"Anthropocentrism, Alignment, and Personalization","2023-04-25","# **Executive Summary**\n\n* **First of all, progress in AI is predominantly positive** ðŸŽ‰ ðŸš€ We should enjoy the benefits of advanced machine\n  learning. The risk of a run-away scenario is most likely minimal since the likelihood of\n  a [strong discontinuity](https://pashanomics.substack.com/p/an-ai-realist-manifesto-neither-doomer?ref=thediff.co) in\n  capabilities is small.\n\n* That said, I consider it a moral axiom and obligation to protect the subjective, conscious experiences of humans.\n\n* Humans are valuable, but human existence is not unconditional.\n\n* We impose regulation when self-interest fails to protect our long-term, common good.\n\n* Super-intelligent AIs might be similar to companies, which implies they could be regulated.\n\n* There is an old debate about whether technology risks replacing humans that is accelerating again. It is not clear if\n  â€œthis time is different.â€\n\n* Human goals, preferences, and ethics are constantly changing. This protects us from automation.\n\n### Anthropocentrism and Human Importance\n\nI follow closely the AI debate currently unfolding. The most extreme part of the debate is about whether AI is an\nexistential threat to humans or not. This post explores how we have tried to protect the long-term wellbeing of\nhumanity, and what might make sense now. Humans have a long history of favoring humans. Already in The Book of Genesis,\nwhich could be as old as 3400 years, you can read in verse 1:26:\n\n> â€¦ and God said, let us make [humans] in our image, after our likeness: and **let [humans] have dominion** over the\n> fish of the sea, and over the fowl of the air, and over the cattle, and **over all the earth** , and over every creeping\n> thing that creepeth upon the earth.\n\nI think any discussion about the alignment of human ethics and AI needs to start with the question: **are humans\nimportant?** While the answer might feel like an unmistakable YES, it likely isnâ€™t a binary question for most people;\nitâ€™s a matter of degree. Most humans probably think humans should exist. Any other position would legitimize genocide\nor, at the very least, suicide. And by reading this, youâ€™ve chosen to be alive, which means something.\n\n## Alignment and The Common Good\n\nWhile most of us want to exist, most humans also acknowledge the tension between our material expectations and the\nenvironment. The more possessions we want, the more strain we put on the environment. To manage this tension, **we\nimpose regulatory limits.** Even if we think humans should exist, our existence is not unconditional. Economists talk\nabout [The Tragedy of the Commons](https://en.wikipedia.org/wiki/Tragedy_of_the_commons):\n\n> â€¦ a phenomenon in which common resources to which access is not regulated by fees based on individual users tend to\n> become depleted. If users of such resources act to maximize their self-interest and do not coordinate with others to\n> maximize the overall common good, exhaustion and even permanent destruction of the resource may resultâ€¦\n\nMost humans do not feel good about burning oil and coal, cutting down forests, causing the extinction of endangered\nspecies, polluting coral reefs, or any of the countless other destructive things we nevertheless keep doing. Through our\nconsumption, we contribute to exhausting Earthâ€™s ecosystem. In the absence of decentralized **alignment** , we ask\ngovernments to coordinate. Governments attempt to align personal needs with the long-term, common good.\n\n## AI Alignment and Regulation of Companies\n\nRecent progress in AI has sparked a discussion about the possible impact super-intelligent AI might have on humanity. A\nterm that frequently occurs in this discussion\nis â€œ[AI alignment research](https://en.wikipedia.org/wiki/AI_alignment#:~:text=In%20the%20field%20of%20artificial,it%20advances%20the%20intended%20objectives.)â€:\n\n> â€¦alignment aims to steer systems toward humansâ€™ intended goals, preferences, or ethics\n\nThere are striking similarities between such research and the ultimate purpose of regulation. Government regulation aims\nto steer markets toward humansâ€™ intended goals, preferences, or ethical principles, i.e., to avoid tragedies of the\ncommons where individual greed depletes essential common resources.\n\nAt the receiving end of regulation is the free market. Of all the forms for creating value weâ€™ve tried, free democratic\nmarkets powered by independent academia have been our most significant source of progress. So whatever regulation we\nimpose, it needs to be carefully balanced with the value of a free market. Most current AI regulation is a joke. And,\nwhile Iâ€™m at it, GDPR is a complete waste of money and time that makes Europe drastically less able to compete. I\nconsider it my duty to avoid implementing any compromises due to GDPR. I share this to make sure you do not mistake my\nreasoning in this post as pro â€œbig government.â€ I think a small government is probably better in most cases, but I\ndefinitely think we need governments.\n\nAnyway, central to free markets are independent companies. Companies have a very straightforward, well-defined objective\nfunction: **maximize shareholder value**. In a way, **companies operate as distributed, super-intelligent AIs**. People\nwork together to perform calculations and take actions that strive to capture as much value as possible.\n\nIt turns out that regulation of markets can help us escape certain local minima that, if not escaped, would deplete\ncommon goods. Take electrification as an example: Tesla has\nreceived [billions in subsidies](https://www.latimes.com/business/la-fi-hy-musk-subsidies-20150531-story.html), and\nbuyers of Tesla cars have\nenjoyed [aggressive tax benefits](https://www.reuters.com/business/autos-transportation/tesla-pushes-norways-ev-sales-new-record-2021-10-01/).\nAs a taxpayer, Iâ€™m happy to contribute to getting us off our oil addiction faster. While companies would likely have\nrealized the necessity of transitioning to electric vehicles anyway, government action undeniably accelerated our\ntransition. Most industries welcome regulation. Pharmaceutical companies, for example, want a level playing field. If\nanyone could launch a drug without rigorous testing, the market would be impossible to navigate for doctors and\npatients. A messy pharma market would ultimately hurt drug companies.\n\n### The Debate: Will Technology Replace Humans?\n\nI see a connection between companies in a free market, the tragedy of the commons, and AI. Let me explain: Due to their\nobjective function, companies are naturally focused on efficiency and automation. Often, that boils down to removing\nhumans from processes. Less manual effort means more profitability. **An extreme outcome of this work would be that\nhumans are no longer needed. Is such an outcome an expression of human goals, preferences, and ethical principles?**\n\nI see at least three possible lines of reasoning when responding to this question:\n\n**1\\. AGI is distant, and while AI is getting more capable, technology-driven unemployment isnâ€™t something we need to be\nconcerned about.** Fears about new technology replacing humans are not new. The Luddites were a secret oath-based\norganization of English textile workers in the 19th century who formed a radical faction that destroyed textile\nmachinery. Each such historical scare has been proven wrong by consistent economic growth. Marc Andreessen\nhas [a detailed post on this topic](https://pmarca.substack.com/p/why-ai-wont-cause-unemployment). He isnâ€™t exactly\nneutral, but he makes a good point. His post argues that technology is already illegal in many sectors, such as\nhealthcare, education and housing, and that the result is a steady increase in cost. Sectors in red in this graph are\nheavily regulated, while sectors in blue allow for free competition. Turns out technology and competition has a strong\ndeflationary impact, without actually causing unemployment.\n\n![](https://storage.googleapis.com/langkilde-se-images/6b144d50-2ef9-44d1-acc5-ee458ab07e7f.jpeg)\n\n**2\\. AI is getting more capable, and we risk removing many jobs that provide people with meaning. Our pursuit of profit\ndoes not stand above protecting the subjective human experience of purpose.** Lex Friedman interviewed Max Tegmark\nrecently. Tegmark made a lovely case for why it is wrong for humanity to remove meaningful\nwork. [Tegmark references](https://youtu.be/l3RaPJUhqkM?t=64) a great article by Scott Alexander\ntitled â€œ[Meditations on Moloch](https://slatestarcodex.com/2014/07/30/meditations-on-moloch/).â€ Moloch is a\ngame-theoretic monster that traps people in a race toward an outcome we ultimately do not want. I think Moloch is real,\nand that regulation can help people avoid ending up serving Moloch. It is possible that current AI development\naccelerates to the point that most creative professions become financially worthless. I.e. it is possible this\nunemployment scare is different. But we do not know. Not yet anyway.\n\n**Related to this is an interesting question:** does work constitute a common good that we should or need to protect? Is\nit possible that AI developers could deplete the need for human work by maximizing their self-interest? I think this\nwill be debated a lot in the coming years. Personally, Iâ€™m an optimist. I think we will find new and creative jobs that\nreplace the ones we loose. But Iâ€™m sympathetic with the people who will need to find new jobs. We should help those\npeople transition.\n\n**3\\. AI risks evolving into AGI, which, if not aligned properly, could cause massive problems for humanity. As a\nresult, we need to slow down until we have alignment figured out.** The â€œDoomersâ€ arenâ€™t worried about such trivial\nissues as the preservation of meaningful work. They are concerned about the risk of AGI causing the extinction of\nhumanity. They argue we should stop, or at least slow down, the development of AGI until we have figured out to prevent\nhuman extinction. If you are indeed worried about this, then anything we can do to stop AGI from causing extinction is\nfair game, including, but not limited to, regulation.\n\n### Humansâ€™ Goals, Preferences, and Ethics Evolve\n\nOur best defense against automation is that we do not know the meaning of life. I mentioned alignment as the process of\nsteering systems toward humansâ€™ intended goals, preferences, and ethics. I think discussing our purpose is an eternal\nactivity. Humans have always looked at the sky and asked ourselves: â€œWhy are we here?â€ Culture is built on mystery, and\ndoubt sits at the heart of the human condition. We do not know why we are here, and thatâ€™s great. That means there will\nalways be things to explore. We cannot automate a process for which we do not know the objective function.\n\nThis uncertainty has resulted in ideologies, beliefs, religions, doctrines, ethics, and other frameworks. Or in another\nword, culture:\n\n> Culture is an umbrella term that encompasses the social behavior, institutions, and norms found in human societies, as\n> well as the knowledge, beliefs, arts, laws, customs, capabilities, and habits of the individuals in these groups. **A\ncultural norm codifies acceptable conduct in society**.\n\nSince there is no single axiomatic purpose for human existence, humanity has developed a vast range of different\ncultures, each providing its own version of â€œWhyâ€. There is a fascinating discourse about â€œAre GPT models biased or\nnot?â€. Of course, they are. They reflect the cultural norms present in the training data. It is impossible to eradicate\nbias, since we cannot sterilize the human experience and wash away culture. We are one with culture. Instead, a more\nfeasible solution is personalization. Just as there are different newspapers, books, and social circles, we will want\nAIs that reflect our worldview.\n\n### The Subjective Human Experience is Valuable\n\nThis is not a prediction or speculation. This is a value statement. I think humans are _more_ important than machines. I\nconsider this a moral axiom. I cannot prove why this is true. I just decided it is. I have decided that the subjective\nhuman experience of consciousness is valuable and should be protected. Every time humans have questioned this principle,\ndisaster has ensued, like the Holocaust. We have a moral obligation to preserve other humansâ€™ subjective experiences.\nAnd we should strive to maximize the happiness of all humans. If, at one point, automation or even AGI threatens the\nlong-term safety of humans, then I choose humans over machines. Iâ€™d much rather shut down AI than risk wiping out\nhumanity, but I donâ€™t think there is any reason to shutdown AI progress based available data.\n\nInstead, we should let AI technology flow as freely as possible and put a minimum amount of regulation in place. We\nshould only regulate if companies risk depleting common goods. I donâ€™t think we risk depleting our repository of\nmeaningful work, so right now I doubt much regulation is meaningful.","src/content/blog/anthropocentrism-alignment-and-personalization.md","4ec2a78082180a48",{"html":50,"metadata":51},"\u003Ch1 id=\"executive-summary\">\u003Cstrong>Executive Summary\u003C/strong>\u003C/h1>\n\u003Cul>\n\u003Cli>\n\u003Cp>\u003Cstrong>First of all, progress in AI is predominantly positive\u003C/strong> ðŸŽ‰ ðŸš€ We should enjoy the benefits of advanced machine\nlearning. The risk of a run-away scenario is most likely minimal since the likelihood of\na \u003Ca href=\"https://pashanomics.substack.com/p/an-ai-realist-manifesto-neither-doomer?ref=thediff.co\">strong discontinuity\u003C/a> in\ncapabilities is small.\u003C/p>\n\u003C/li>\n\u003Cli>\n\u003Cp>That said, I consider it a moral axiom and obligation to protect the subjective, conscious experiences of humans.\u003C/p>\n\u003C/li>\n\u003Cli>\n\u003Cp>Humans are valuable, but human existence is not unconditional.\u003C/p>\n\u003C/li>\n\u003Cli>\n\u003Cp>We impose regulation when self-interest fails to protect our long-term, common good.\u003C/p>\n\u003C/li>\n\u003Cli>\n\u003Cp>Super-intelligent AIs might be similar to companies, which implies they could be regulated.\u003C/p>\n\u003C/li>\n\u003Cli>\n\u003Cp>There is an old debate about whether technology risks replacing humans that is accelerating again. It is not clear if\nâ€œthis time is different.â€\u003C/p>\n\u003C/li>\n\u003Cli>\n\u003Cp>Human goals, preferences, and ethics are constantly changing. This protects us from automation.\u003C/p>\n\u003C/li>\n\u003C/ul>\n\u003Ch3 id=\"anthropocentrism-and-human-importance\">Anthropocentrism and Human Importance\u003C/h3>\n\u003Cp>I follow closely the AI debate currently unfolding. The most extreme part of the debate is about whether AI is an\nexistential threat to humans or not. This post explores how we have tried to protect the long-term wellbeing of\nhumanity, and what might make sense now. Humans have a long history of favoring humans. Already in The Book of Genesis,\nwhich could be as old as 3400 years, you can read in verse 1:26:\u003C/p>\n\u003Cblockquote>\n\u003Cp>â€¦ and God said, let us make [humans] in our image, after our likeness: and \u003Cstrong>let [humans] have dominion\u003C/strong> over the\nfish of the sea, and over the fowl of the air, and over the cattle, and \u003Cstrong>over all the earth\u003C/strong> , and over every creeping\nthing that creepeth upon the earth.\u003C/p>\n\u003C/blockquote>\n\u003Cp>I think any discussion about the alignment of human ethics and AI needs to start with the question: \u003Cstrong>are humans\nimportant?\u003C/strong> While the answer might feel like an unmistakable YES, it likely isnâ€™t a binary question for most people;\nitâ€™s a matter of degree. Most humans probably think humans should exist. Any other position would legitimize genocide\nor, at the very least, suicide. And by reading this, youâ€™ve chosen to be alive, which means something.\u003C/p>\n\u003Ch2 id=\"alignment-and-the-common-good\">Alignment and The Common Good\u003C/h2>\n\u003Cp>While most of us want to exist, most humans also acknowledge the tension between our material expectations and the\nenvironment. The more possessions we want, the more strain we put on the environment. To manage this tension, \u003Cstrong>we\nimpose regulatory limits.\u003C/strong> Even if we think humans should exist, our existence is not unconditional. Economists talk\nabout \u003Ca href=\"https://en.wikipedia.org/wiki/Tragedy_of_the_commons\">The Tragedy of the Commons\u003C/a>:\u003C/p>\n\u003Cblockquote>\n\u003Cp>â€¦ a phenomenon in which common resources to which access is not regulated by fees based on individual users tend to\nbecome depleted. If users of such resources act to maximize their self-interest and do not coordinate with others to\nmaximize the overall common good, exhaustion and even permanent destruction of the resource may resultâ€¦\u003C/p>\n\u003C/blockquote>\n\u003Cp>Most humans do not feel good about burning oil and coal, cutting down forests, causing the extinction of endangered\nspecies, polluting coral reefs, or any of the countless other destructive things we nevertheless keep doing. Through our\nconsumption, we contribute to exhausting Earthâ€™s ecosystem. In the absence of decentralized \u003Cstrong>alignment\u003C/strong> , we ask\ngovernments to coordinate. Governments attempt to align personal needs with the long-term, common good.\u003C/p>\n\u003Ch2 id=\"ai-alignment-and-regulation-of-companies\">AI Alignment and Regulation of Companies\u003C/h2>\n\u003Cp>Recent progress in AI has sparked a discussion about the possible impact super-intelligent AI might have on humanity. A\nterm that frequently occurs in this discussion\nis â€œ\u003Ca href=\"https://en.wikipedia.org/wiki/AI_alignment#:~:text=In%20the%20field%20of%20artificial,it%20advances%20the%20intended%20objectives.\">AI alignment research\u003C/a>â€:\u003C/p>\n\u003Cblockquote>\n\u003Cp>â€¦alignment aims to steer systems toward humansâ€™ intended goals, preferences, or ethics\u003C/p>\n\u003C/blockquote>\n\u003Cp>There are striking similarities between such research and the ultimate purpose of regulation. Government regulation aims\nto steer markets toward humansâ€™ intended goals, preferences, or ethical principles, i.e., to avoid tragedies of the\ncommons where individual greed depletes essential common resources.\u003C/p>\n\u003Cp>At the receiving end of regulation is the free market. Of all the forms for creating value weâ€™ve tried, free democratic\nmarkets powered by independent academia have been our most significant source of progress. So whatever regulation we\nimpose, it needs to be carefully balanced with the value of a free market. Most current AI regulation is a joke. And,\nwhile Iâ€™m at it, GDPR is a complete waste of money and time that makes Europe drastically less able to compete. I\nconsider it my duty to avoid implementing any compromises due to GDPR. I share this to make sure you do not mistake my\nreasoning in this post as pro â€œbig government.â€ I think a small government is probably better in most cases, but I\ndefinitely think we need governments.\u003C/p>\n\u003Cp>Anyway, central to free markets are independent companies. Companies have a very straightforward, well-defined objective\nfunction: \u003Cstrong>maximize shareholder value\u003C/strong>. In a way, \u003Cstrong>companies operate as distributed, super-intelligent AIs\u003C/strong>. People\nwork together to perform calculations and take actions that strive to capture as much value as possible.\u003C/p>\n\u003Cp>It turns out that regulation of markets can help us escape certain local minima that, if not escaped, would deplete\ncommon goods. Take electrification as an example: Tesla has\nreceived \u003Ca href=\"https://www.latimes.com/business/la-fi-hy-musk-subsidies-20150531-story.html\">billions in subsidies\u003C/a>, and\nbuyers of Tesla cars have\nenjoyed \u003Ca href=\"https://www.reuters.com/business/autos-transportation/tesla-pushes-norways-ev-sales-new-record-2021-10-01/\">aggressive tax benefits\u003C/a>.\nAs a taxpayer, Iâ€™m happy to contribute to getting us off our oil addiction faster. While companies would likely have\nrealized the necessity of transitioning to electric vehicles anyway, government action undeniably accelerated our\ntransition. Most industries welcome regulation. Pharmaceutical companies, for example, want a level playing field. If\nanyone could launch a drug without rigorous testing, the market would be impossible to navigate for doctors and\npatients. A messy pharma market would ultimately hurt drug companies.\u003C/p>\n\u003Ch3 id=\"the-debate-will-technology-replace-humans\">The Debate: Will Technology Replace Humans?\u003C/h3>\n\u003Cp>I see a connection between companies in a free market, the tragedy of the commons, and AI. Let me explain: Due to their\nobjective function, companies are naturally focused on efficiency and automation. Often, that boils down to removing\nhumans from processes. Less manual effort means more profitability. \u003Cstrong>An extreme outcome of this work would be that\nhumans are no longer needed. Is such an outcome an expression of human goals, preferences, and ethical principles?\u003C/strong>\u003C/p>\n\u003Cp>I see at least three possible lines of reasoning when responding to this question:\u003C/p>\n\u003Cp>\u003Cstrong>1. AGI is distant, and while AI is getting more capable, technology-driven unemployment isnâ€™t something we need to be\nconcerned about.\u003C/strong> Fears about new technology replacing humans are not new. The Luddites were a secret oath-based\norganization of English textile workers in the 19th century who formed a radical faction that destroyed textile\nmachinery. Each such historical scare has been proven wrong by consistent economic growth. Marc Andreessen\nhas \u003Ca href=\"https://pmarca.substack.com/p/why-ai-wont-cause-unemployment\">a detailed post on this topic\u003C/a>. He isnâ€™t exactly\nneutral, but he makes a good point. His post argues that technology is already illegal in many sectors, such as\nhealthcare, education and housing, and that the result is a steady increase in cost. Sectors in red in this graph are\nheavily regulated, while sectors in blue allow for free competition. Turns out technology and competition has a strong\ndeflationary impact, without actually causing unemployment.\u003C/p>\n\u003Cp>\u003Cimg src=\"https://storage.googleapis.com/langkilde-se-images/6b144d50-2ef9-44d1-acc5-ee458ab07e7f.jpeg\" alt=\"\">\u003C/p>\n\u003Cp>\u003Cstrong>2. AI is getting more capable, and we risk removing many jobs that provide people with meaning. Our pursuit of profit\ndoes not stand above protecting the subjective human experience of purpose.\u003C/strong> Lex Friedman interviewed Max Tegmark\nrecently. Tegmark made a lovely case for why it is wrong for humanity to remove meaningful\nwork. \u003Ca href=\"https://youtu.be/l3RaPJUhqkM?t=64\">Tegmark references\u003C/a> a great article by Scott Alexander\ntitled â€œ\u003Ca href=\"https://slatestarcodex.com/2014/07/30/meditations-on-moloch/\">Meditations on Moloch\u003C/a>.â€ Moloch is a\ngame-theoretic monster that traps people in a race toward an outcome we ultimately do not want. I think Moloch is real,\nand that regulation can help people avoid ending up serving Moloch. It is possible that current AI development\naccelerates to the point that most creative professions become financially worthless. I.e. it is possible this\nunemployment scare is different. But we do not know. Not yet anyway.\u003C/p>\n\u003Cp>\u003Cstrong>Related to this is an interesting question:\u003C/strong> does work constitute a common good that we should or need to protect? Is\nit possible that AI developers could deplete the need for human work by maximizing their self-interest? I think this\nwill be debated a lot in the coming years. Personally, Iâ€™m an optimist. I think we will find new and creative jobs that\nreplace the ones we loose. But Iâ€™m sympathetic with the people who will need to find new jobs. We should help those\npeople transition.\u003C/p>\n\u003Cp>\u003Cstrong>3. AI risks evolving into AGI, which, if not aligned properly, could cause massive problems for humanity. As a\nresult, we need to slow down until we have alignment figured out.\u003C/strong> The â€œDoomersâ€ arenâ€™t worried about such trivial\nissues as the preservation of meaningful work. They are concerned about the risk of AGI causing the extinction of\nhumanity. They argue we should stop, or at least slow down, the development of AGI until we have figured out to prevent\nhuman extinction. If you are indeed worried about this, then anything we can do to stop AGI from causing extinction is\nfair game, including, but not limited to, regulation.\u003C/p>\n\u003Ch3 id=\"humans-goals-preferences-and-ethics-evolve\">Humansâ€™ Goals, Preferences, and Ethics Evolve\u003C/h3>\n\u003Cp>Our best defense against automation is that we do not know the meaning of life. I mentioned alignment as the process of\nsteering systems toward humansâ€™ intended goals, preferences, and ethics. I think discussing our purpose is an eternal\nactivity. Humans have always looked at the sky and asked ourselves: â€œWhy are we here?â€ Culture is built on mystery, and\ndoubt sits at the heart of the human condition. We do not know why we are here, and thatâ€™s great. That means there will\nalways be things to explore. We cannot automate a process for which we do not know the objective function.\u003C/p>\n\u003Cp>This uncertainty has resulted in ideologies, beliefs, religions, doctrines, ethics, and other frameworks. Or in another\nword, culture:\u003C/p>\n\u003Cblockquote>\n\u003Cp>Culture is an umbrella term that encompasses the social behavior, institutions, and norms found in human societies, as\nwell as the knowledge, beliefs, arts, laws, customs, capabilities, and habits of the individuals in these groups. \u003Cstrong>A\ncultural norm codifies acceptable conduct in society\u003C/strong>.\u003C/p>\n\u003C/blockquote>\n\u003Cp>Since there is no single axiomatic purpose for human existence, humanity has developed a vast range of different\ncultures, each providing its own version of â€œWhyâ€. There is a fascinating discourse about â€œAre GPT models biased or\nnot?â€. Of course, they are. They reflect the cultural norms present in the training data. It is impossible to eradicate\nbias, since we cannot sterilize the human experience and wash away culture. We are one with culture. Instead, a more\nfeasible solution is personalization. Just as there are different newspapers, books, and social circles, we will want\nAIs that reflect our worldview.\u003C/p>\n\u003Ch3 id=\"the-subjective-human-experience-is-valuable\">The Subjective Human Experience is Valuable\u003C/h3>\n\u003Cp>This is not a prediction or speculation. This is a value statement. I think humans are \u003Cem>more\u003C/em> important than machines. I\nconsider this a moral axiom. I cannot prove why this is true. I just decided it is. I have decided that the subjective\nhuman experience of consciousness is valuable and should be protected. Every time humans have questioned this principle,\ndisaster has ensued, like the Holocaust. We have a moral obligation to preserve other humansâ€™ subjective experiences.\nAnd we should strive to maximize the happiness of all humans. If, at one point, automation or even AGI threatens the\nlong-term safety of humans, then I choose humans over machines. Iâ€™d much rather shut down AI than risk wiping out\nhumanity, but I donâ€™t think there is any reason to shutdown AI progress based available data.\u003C/p>\n\u003Cp>Instead, we should let AI technology flow as freely as possible and put a minimum amount of regulation in place. We\nshould only regulate if companies risk depleting common goods. I donâ€™t think we risk depleting our repository of\nmeaningful work, so right now I doubt much regulation is meaningful.\u003C/p>",{"headings":52,"localImagePaths":76,"remoteImagePaths":77,"frontmatter":78,"imagePaths":79},[53,57,60,64,67,70,73],{"depth":54,"slug":55,"text":56},1,"executive-summary","Executive Summary",{"depth":24,"slug":58,"text":59},"anthropocentrism-and-human-importance","Anthropocentrism and Human Importance",{"depth":61,"slug":62,"text":63},2,"alignment-and-the-common-good","Alignment and The Common Good",{"depth":61,"slug":65,"text":66},"ai-alignment-and-regulation-of-companies","AI Alignment and Regulation of Companies",{"depth":24,"slug":68,"text":69},"the-debate-will-technology-replace-humans","The Debate: Will Technology Replace Humans?",{"depth":24,"slug":71,"text":72},"humans-goals-preferences-and-ethics-evolve","Humansâ€™ Goals, Preferences, and Ethics Evolve",{"depth":24,"slug":74,"text":75},"the-subjective-human-experience-is-valuable","The Subjective Human Experience is Valuable",[],[],{"pubDate":45,"title":44},[],"anthropocentrism-alignment-and-personalization.md","breakthroughness-and-the-virtuous-cycle",{"id":81,"data":83,"body":86,"filePath":87,"digest":88,"rendered":89,"legacyId":109},{"title":84,"pubDate":85},"Breakthroughness and The Virtuous Cycle","2023-02-27","### Life is a Flywheel\n\n**I think life is a flywheel.** While Iâ€™m humble about the fact that your starting point in life has a huge impact, the\nideas in this post apply to everyone. Life starts with random exploration. You stumble and fall. Find dead ends. Enjoy\nsome things, hate others. But eventually, you start seeing patterns. You start setting goals. First, short-term, then\nlonger and longer into the future. If done carefully, you can establish an exponential growth trajectory. Building\nstarts early; you attend a good school, nurture relationships, read books, and hone your skills. Each step might feel\ninsignificant. Each person you meet or book you read might not feel like all that much. The beginning of an exponential\ncurve is always tedious. But maybe, just maybe, you sense that speed is picking up.\n\n![](https://storage.googleapis.com/langkilde-se-images/1e539247-fac2-4938-b14f-83b149152665.jpeg)\n\nPhysicists have a set of carefully defined terms to describe this. There is force. Force is defined as an influence that\ncauses the motion of an object with mass to change its velocity, i.e., to accelerate. And there is momentum. **Momentum\n** is the product of the mass and velocity of an object. Both force and momentum are vector quantities possessing both a\nmagnitude and a direction. I think life is about applying a directional force to create acceleration toward your\nlong-term goal. Your momentum builds as long as you are accelerating.\n\n### Compound Interest and The Virtuous Cycle\n\nIn finance, people call this **Compound Interest**. Venture capitalists talk about it as **The Virtuous Cycle**.\nTop-tier funds get to their position by maintaining a long winning streak. That winning streak is, to some extent,\nself-sustaining. If you get a few good, early wins, you can build on those. The best entrepreneurs will seek you out.\nThe best LPs will want to invest in your fund. While you are never more than a few bad deals away from losing your\nacceleration, skilled managers can maintain momentum for a long time. And even increase their acceleration if they make\nreally good decisions. Some of that is luck, but you can manufacture some amount of luck as part of a virtuous cycle.\nSelecting from a better set of alternatives will make you feel and look luckier. Or more â€œskilledâ€.\n\n### Breakthroughness and Critical Mass\n\nI think combining **The Virtuous Cycle** with the idea of **Breakthroughness** is fascinating. Breakthroughness is a new\nterm I learned recently from [Google BIG-bench](https://github.com/google/BIG-bench). Breakthroughness is defined as a\nmeasure of the extent to which a model is able to learn a task only once the model grows beyond a critical size. This is\nin contrast to tasks that exhibit linear improvements with scale. The benchmark concludes that for some tasks, models\nare useless until they suddenly arenâ€™t. The authors reason about the possibility that such tasks, in fact, do have\nsmooth performance improvements with size if decomposed successfully, but that the combined task appears to have\nâ€œbreakthroughness.â€ Either way, itâ€™s clear that critical mass unlocks the ability to perform tasks that are impossible\nwith fewer parameters.\n\n![](https://storage.googleapis.com/langkilde-se-images/bfa8d8c9-b7be-4cea-a170-69885542bf9f.jpeg)\n\nIâ€™m\nreading â€œ[Super Founders](https://www.amazon.se/Super-Founders-Reveals-Billion-Dollar-Startups/dp/1541768426/ref=asc_df_1541768426/?hvadid=476556295340&hvdev=c&hvdvcmdl=&hvlocint=&hvlocphy=1012511&hvnetw=g&hvpone=&hvpos=&hvptwo=&hvqmt=&hvrand=10669114641641229857&hvtargid=pla-1128305520704&linkCode=df0&psc=1&tag=shpngadsglede-21)â€\nright now. It takes a data-driven approach to understand what differentiates founders of billion-dollar companies. It\nturns out one of the statistically most important advantages you can have is being a â€œsecond-time founder.â€\nEntrepreneurs with experience in scaling a business, even to a modest size, are significantly more likely to start a\nbillion-dollar business. The book argues that a large part of this advantage is a result of **preferential access**.\nSecond-time founders already have a network of potential early-stage employees, investors, and advisors to lean on.\nThatâ€™s a game changer for a nascent company. Another conclusion in the book is that successful founders usually have\nbeen creating organizations and networks from a very early age. That likely contributes to an accumulated network. Of\ncourse, there are lots of other traits that improve your odds, too, like: intelligence, adaptability, vision, risk\ntolerance, and operational efficiency.\n\n### Gradually, Then Suddenly\n\nHemingway has a poetic way of describing â€œBreakthroughnessâ€ in The Sun Also Rises: â€œHow did you go bankrupt? Two ways.\nGradually, then suddenly.â€ I think the same is true for success. And for products. And for companies. And for most\nthings. How did it happen? Gradually, then suddenly. Be patient. Invest in your skills, your network, and your\nrelationships. Make time even for that which feels insignificant.\n\nWith luck and a lot of hard work, you can get on an exponential trajectory.","src/content/blog/breakthroughness-and-the-virtuous-cycle.md","65583fcd0d7730cd",{"html":90,"metadata":91},"\u003Ch3 id=\"life-is-a-flywheel\">Life is a Flywheel\u003C/h3>\n\u003Cp>\u003Cstrong>I think life is a flywheel.\u003C/strong> While Iâ€™m humble about the fact that your starting point in life has a huge impact, the\nideas in this post apply to everyone. Life starts with random exploration. You stumble and fall. Find dead ends. Enjoy\nsome things, hate others. But eventually, you start seeing patterns. You start setting goals. First, short-term, then\nlonger and longer into the future. If done carefully, you can establish an exponential growth trajectory. Building\nstarts early; you attend a good school, nurture relationships, read books, and hone your skills. Each step might feel\ninsignificant. Each person you meet or book you read might not feel like all that much. The beginning of an exponential\ncurve is always tedious. But maybe, just maybe, you sense that speed is picking up.\u003C/p>\n\u003Cp>\u003Cimg src=\"https://storage.googleapis.com/langkilde-se-images/1e539247-fac2-4938-b14f-83b149152665.jpeg\" alt=\"\">\u003C/p>\n\u003Cp>Physicists have a set of carefully defined terms to describe this. There is force. Force is defined as an influence that\ncauses the motion of an object with mass to change its velocity, i.e., to accelerate. And there is momentum. **Momentum\n** is the product of the mass and velocity of an object. Both force and momentum are vector quantities possessing both a\nmagnitude and a direction. I think life is about applying a directional force to create acceleration toward your\nlong-term goal. Your momentum builds as long as you are accelerating.\u003C/p>\n\u003Ch3 id=\"compound-interest-and-the-virtuous-cycle\">Compound Interest and The Virtuous Cycle\u003C/h3>\n\u003Cp>In finance, people call this \u003Cstrong>Compound Interest\u003C/strong>. Venture capitalists talk about it as \u003Cstrong>The Virtuous Cycle\u003C/strong>.\nTop-tier funds get to their position by maintaining a long winning streak. That winning streak is, to some extent,\nself-sustaining. If you get a few good, early wins, you can build on those. The best entrepreneurs will seek you out.\nThe best LPs will want to invest in your fund. While you are never more than a few bad deals away from losing your\nacceleration, skilled managers can maintain momentum for a long time. And even increase their acceleration if they make\nreally good decisions. Some of that is luck, but you can manufacture some amount of luck as part of a virtuous cycle.\nSelecting from a better set of alternatives will make you feel and look luckier. Or more â€œskilledâ€.\u003C/p>\n\u003Ch3 id=\"breakthroughness-and-critical-mass\">Breakthroughness and Critical Mass\u003C/h3>\n\u003Cp>I think combining \u003Cstrong>The Virtuous Cycle\u003C/strong> with the idea of \u003Cstrong>Breakthroughness\u003C/strong> is fascinating. Breakthroughness is a new\nterm I learned recently from \u003Ca href=\"https://github.com/google/BIG-bench\">Google BIG-bench\u003C/a>. Breakthroughness is defined as a\nmeasure of the extent to which a model is able to learn a task only once the model grows beyond a critical size. This is\nin contrast to tasks that exhibit linear improvements with scale. The benchmark concludes that for some tasks, models\nare useless until they suddenly arenâ€™t. The authors reason about the possibility that such tasks, in fact, do have\nsmooth performance improvements with size if decomposed successfully, but that the combined task appears to have\nâ€œbreakthroughness.â€ Either way, itâ€™s clear that critical mass unlocks the ability to perform tasks that are impossible\nwith fewer parameters.\u003C/p>\n\u003Cp>\u003Cimg src=\"https://storage.googleapis.com/langkilde-se-images/bfa8d8c9-b7be-4cea-a170-69885542bf9f.jpeg\" alt=\"\">\u003C/p>\n\u003Cp>Iâ€™m\nreading â€œ\u003Ca href=\"https://www.amazon.se/Super-Founders-Reveals-Billion-Dollar-Startups/dp/1541768426/ref=asc_df_1541768426/?hvadid=476556295340&#x26;hvdev=c&#x26;hvdvcmdl=&#x26;hvlocint=&#x26;hvlocphy=1012511&#x26;hvnetw=g&#x26;hvpone=&#x26;hvpos=&#x26;hvptwo=&#x26;hvqmt=&#x26;hvrand=10669114641641229857&#x26;hvtargid=pla-1128305520704&#x26;linkCode=df0&#x26;psc=1&#x26;tag=shpngadsglede-21\">Super Founders\u003C/a>â€\nright now. It takes a data-driven approach to understand what differentiates founders of billion-dollar companies. It\nturns out one of the statistically most important advantages you can have is being a â€œsecond-time founder.â€\nEntrepreneurs with experience in scaling a business, even to a modest size, are significantly more likely to start a\nbillion-dollar business. The book argues that a large part of this advantage is a result of \u003Cstrong>preferential access\u003C/strong>.\nSecond-time founders already have a network of potential early-stage employees, investors, and advisors to lean on.\nThatâ€™s a game changer for a nascent company. Another conclusion in the book is that successful founders usually have\nbeen creating organizations and networks from a very early age. That likely contributes to an accumulated network. Of\ncourse, there are lots of other traits that improve your odds, too, like: intelligence, adaptability, vision, risk\ntolerance, and operational efficiency.\u003C/p>\n\u003Ch3 id=\"gradually-then-suddenly\">Gradually, Then Suddenly\u003C/h3>\n\u003Cp>Hemingway has a poetic way of describing â€œBreakthroughnessâ€ in The Sun Also Rises: â€œHow did you go bankrupt? Two ways.\nGradually, then suddenly.â€ I think the same is true for success. And for products. And for companies. And for most\nthings. How did it happen? Gradually, then suddenly. Be patient. Invest in your skills, your network, and your\nrelationships. Make time even for that which feels insignificant.\u003C/p>\n\u003Cp>With luck and a lot of hard work, you can get on an exponential trajectory.\u003C/p>",{"headings":92,"localImagePaths":105,"remoteImagePaths":106,"frontmatter":107,"imagePaths":108},[93,96,99,102],{"depth":24,"slug":94,"text":95},"life-is-a-flywheel","Life is a Flywheel",{"depth":24,"slug":97,"text":98},"compound-interest-and-the-virtuous-cycle","Compound Interest and The Virtuous Cycle",{"depth":24,"slug":100,"text":101},"breakthroughness-and-critical-mass","Breakthroughness and Critical Mass",{"depth":24,"slug":103,"text":104},"gradually-then-suddenly","Gradually, Then Suddenly",[],[],{"pubDate":85,"title":84},[],"breakthroughness-and-the-virtuous-cycle.md","believe-in-something",{"id":110,"data":112,"body":115,"filePath":116,"digest":117,"rendered":118,"legacyId":135},{"title":113,"pubDate":114},"Believe in something","2019-12-27","### The Limits of Pure Logic\n\n**I think society as a whole is trapped by the fallacy that logic always beats emotion.** This conviction stifles\ninnovation, removes personal responsibility and harms our wellbeing. The best people I know are able to mix logic with\nemotion.\n\n> \"_When dealing with people, let us remember we are not dealing with creatures of logic. We are dealing with creatures\n> of emotion, creatures bristling with prejudices and motivated by pride and vanity._\"\n>\n> â€” Dale Carnegie\n\n**Companies invest a great deal of money in ensuring they make logical decisions.** Large companies believe the only\ngood decisions are based on facts. The problem is that in most situations there is not enough information to make a\nlogical decision. Instead, you have to resort to emotion and ethics.\n\n### Innovation Requires Belief\n\n**Innovation to me is the process of willing something new into existence against all odds.** Itâ€™s an emotional process,\njust as much as a logical one. Bringing something completely new into the world requires faith. You have to believe that\nyour idea will lead to something worthwhile. There will never be enough facts to know for sure.\n\n**Risk and reward are closely connected for exactly this reason.** Risk is exposing yourself to uncertainty and danger.\nYou might be wrong, but if you are not, you have a chance to win big. If you completely remove risk from decisions, you\nwill drastically reduce the potential returns. Being afraid of being wrong or failing will hold you back.\n\n### Encourage Courageous Decisions\n\n**I encourage everyone who works for me to make risky decisions. Believe in something.** Try something new. I will\nreward courage as much as success. If you do your homework, gather facts, make a decision and own it, I will support you\nno matter the outcome.\n\nHesitating and delaying is much more costly than moving forward with the belief it will work out!\n\n**Happy New Year!**","src/content/blog/believe-in-something.md","5f28138a74328ffa",{"html":119,"metadata":120},"\u003Ch3 id=\"the-limits-of-pure-logic\">The Limits of Pure Logic\u003C/h3>\n\u003Cp>\u003Cstrong>I think society as a whole is trapped by the fallacy that logic always beats emotion.\u003C/strong> This conviction stifles\ninnovation, removes personal responsibility and harms our wellbeing. The best people I know are able to mix logic with\nemotion.\u003C/p>\n\u003Cblockquote>\n\u003Cp>â€œ\u003Cem>When dealing with people, let us remember we are not dealing with creatures of logic. We are dealing with creatures\nof emotion, creatures bristling with prejudices and motivated by pride and vanity.\u003C/em>â€\u003C/p>\n\u003Cp>â€” Dale Carnegie\u003C/p>\n\u003C/blockquote>\n\u003Cp>\u003Cstrong>Companies invest a great deal of money in ensuring they make logical decisions.\u003C/strong> Large companies believe the only\ngood decisions are based on facts. The problem is that in most situations there is not enough information to make a\nlogical decision. Instead, you have to resort to emotion and ethics.\u003C/p>\n\u003Ch3 id=\"innovation-requires-belief\">Innovation Requires Belief\u003C/h3>\n\u003Cp>\u003Cstrong>Innovation to me is the process of willing something new into existence against all odds.\u003C/strong> Itâ€™s an emotional process,\njust as much as a logical one. Bringing something completely new into the world requires faith. You have to believe that\nyour idea will lead to something worthwhile. There will never be enough facts to know for sure.\u003C/p>\n\u003Cp>\u003Cstrong>Risk and reward are closely connected for exactly this reason.\u003C/strong> Risk is exposing yourself to uncertainty and danger.\nYou might be wrong, but if you are not, you have a chance to win big. If you completely remove risk from decisions, you\nwill drastically reduce the potential returns. Being afraid of being wrong or failing will hold you back.\u003C/p>\n\u003Ch3 id=\"encourage-courageous-decisions\">Encourage Courageous Decisions\u003C/h3>\n\u003Cp>\u003Cstrong>I encourage everyone who works for me to make risky decisions. Believe in something.\u003C/strong> Try something new. I will\nreward courage as much as success. If you do your homework, gather facts, make a decision and own it, I will support you\nno matter the outcome.\u003C/p>\n\u003Cp>Hesitating and delaying is much more costly than moving forward with the belief it will work out!\u003C/p>\n\u003Cp>\u003Cstrong>Happy New Year!\u003C/strong>\u003C/p>",{"headings":121,"localImagePaths":131,"remoteImagePaths":132,"frontmatter":133,"imagePaths":134},[122,125,128],{"depth":24,"slug":123,"text":124},"the-limits-of-pure-logic","The Limits of Pure Logic",{"depth":24,"slug":126,"text":127},"innovation-requires-belief","Innovation Requires Belief",{"depth":24,"slug":129,"text":130},"encourage-courageous-decisions","Encourage Courageous Decisions",[],[],{"pubDate":114,"title":113},[],"believe-in-something.md","artificial-intelligence-scaling-laws",{"id":136,"data":138,"body":141,"filePath":142,"digest":143,"rendered":144,"legacyId":168},{"title":139,"pubDate":140},"Artificial Intelligence and Scaling Laws","2023-04-06","## Executive Summary\n\n* **Progress in AI is predominantly positive ðŸŽ‰ðŸš€** We should enjoy and embrace the benefits of advanced machine learning\n  and nascent AI and look forward to the many incredible products we will see in the coming months and years.\n\n* **Super-intelligent AGI is most likely still distant,** and I find it unlikely (\u003C5%) that current models will become\n  capable of self-improvement. That said, AGI-like systems are here to stay, and Iâ€™m increasingly comfortable referring\n  to things as AI systems rather than â€œmereâ€ machine learning systems.\n\n* Due to the surprising abilities of Auto-Regressive Large Language Models (AR LLMs), **we cannot rule out the\n  possibility of emerging self-improvement capabilities.**\n\n* **We have no idea how super-intelligent AGI would impact society.** You can come up with a plausible story in which\n  super-intelligent AGI has catastrophic consequences for humanity. But it could also be amazing ðŸ¤·ðŸ¼ðŸ™‚\n\n* Ultimately, your feelings about current AI development depend on **how you prefer to handle tail risk.** What do you\n  do if there is a tiny, tiny probability of a really, really bad outcome?\n\n* **In the meantime, we should enjoy all the great products we can now build while dealing with the practical issues we\n  know to be real** â€” misinformation, labor market reskilling, carbon emissions, and more. But none of these are reasons\n  to stop progress.\n\n## Background\n\nAuto-Regressive Large Language Models (AR LLMs) is an emerging technology gaining increasingly broad real-world use. As\nthese models become larger and larger their capacity and open-endedness create a difficult-to-predict scope of emergent\nbehavior. Developers of AR LLMs regularly discover unexpected model capabilities.\n\n> Which stage of the Gartner hype cycle is â€œpeople lose their fucking minds and argue that we should start a nuclear war\n> to prevent people from using mathsâ€? Asking for a friend.\n>\n> -- Benedict Evans (\n> @benedictevans) [March 30, 2023](https://twitter.com/benedictevans/status/1641500204481368064?ref_src=twsrc%5Etfw)\n\nDue to the enigmatic internals of these models, it is challenging to make predictions of future capabilities using the\nscientific method. Central to the scientific method is [falsifiability](https://en.wikipedia.org/wiki/Falsifiability),\ni.e., that empirical tests can logically contradict theories or hypotheses. Currently, the scientific method is\nstruggling to keep up with engineering progress. Engineers are making much faster progress on scaling up models,\nresulting in emergent behavior researchers cannot fully explain. This presents a problem for everyone observing progress\nin AI: where are we heading? Without accepted scientific theories, people start extrapolating based on their\ninterpretation. As a result, people who are usually sensible can suddenly end up with extreme views. They also tend to\noscillate quickly between being impressed and scared. **This post attempts to make sense of the different theories and\ndevelop a position on the question of â€œWhat does the future of AI in society look like?â€.**\n\n**First of all: Iâ€™ve always taken the position that existing artificial intelligence is far worse than human\nintelligence.** I started learning about machine learning in the late 1990s, and every time I learn about the inner\nworkings of a new machine-learning algorithm, I feel, â€œIs this it?â€. It is hard to feel that something is intelligent\nwhen you understand the mechanics. Even Transformers evoke this feeling for me. The algorithm\nis [short and simple](https://github.com/karpathy/nanoGPT) and not something that feels nearly as sophisticated and\ncomplex as the human brain. Just read a few pages from any of\nthe [great books Nick Lane has written (e.g., The Ten Great Inventions of Evolution)](https://www.amazon.com/Life-Ascending-Great-Inventions-Evolution/dp/0393338665),\nand youâ€™ll realize how much goes into our biological system. Coming into the question of AGI, my starting point is:\nweâ€™re far from human-like intelligence, and we should be humble.\n\n## What trajectories do people imagine when forecasting the future of AI?\n\nTo grossly oversimplify, there appears to be a matrix with two dimensions:\n\n* **AGI Timeline.** Will we get AGI soon, or is it still in the distant future?\n\n* **AGI Impact.** Will AGI be great, or will it result in the extinction of humans?\n\n![](https://storage.googleapis.com/langkilde-se-images/d2334493-322f-454c-8e2e-6713cd65c9f9.jpeg)\n\nIâ€™ll focus on three groups that Iâ€™ll call: **â€œThe Optimists,â€** **â€œThe Pessimists,â€** and **â€œAGI is Distant.â€**\n\n**The Optimists.** You can tell a plausible story where humanity greatly benefits from the emergence of AGI. Assuming we\ncan reign in AGI and use it for the betterment of humanity, an intelligence vastly more capable than a human could\nunlock secrets of the universe we can only dream of today.\n\n* **Short-term positive.** Auto-Regressive Large Language Models automate tedious work and allow people to focus on more\n  exciting things. Generative visual models will give many more people the power to visualize their thoughts. Overall,\n  this will be great for humanity.\n\n* **Long-term positive.** As models get smarter and smarter and have access to more and more information about the\n  universe, we might start to get novel insights about how the world works emerging from models. There is no guarantee\n  this will happen, but since we are already surprised by what AR LLMs can do, we cannot reject the possibility.\n\n**The Pessimists.** You can also tell a plausible story in which AGI has a very negative impact on humanity. AI can be\nmuch more intelligent than humans and use information more efficiently. For example, AlphaZero learned to be superhuman\nat Go in only a few days. A misaligned AI smarter than\nhumans [could cause human extinction](https://www.lesswrong.com/posts/Wic2P2bGejbFH3Sxb/summary-of-agi-ruin-a-list-of-lethalities).\nIt would also be virtually impossible to stop it if things go off the rails.\n\n> I think that the magnitude of the AI alignment problem has been ridiculously overblown & our ability to solve it\n> widely underestimated.\n>\n> I've been publicly called stupid before, but never as often as by the \"AI is a significant existential risk\" crowd.\n>\n> That's OK, I'm used to it.\n>\n> -- Yann LeCun (@ylecun) [March 20, 2023](https://twitter.com/ylecun/status/1637883960578682883?ref_src=twsrc%5Etfw)\n\n* **Short-term negative.** AR LLMs are a threat to democracy, truth, and the internet. Bad actors will use AR LLMs to\n  flood the internet with false information in a way that is indistinguishable from trustworthy information. Information\n  warfare will be dramatically escalated.\n\n* **Long-term negative.** A super-intelligent algorithm able to take real-world actions deliberately or accidentally\n  takes actions that harm or even extinguish humanity.\n\n**AGI is Distant.** You could also argue that current systems are far from comparable to humans, let alone\nsuper-intelligent. The fact that super-intelligence is so distant makes the debate about the impact of AGI hypothetical\nto the point of being a waste of time. Yann LeCun is one of the most experienced and knowledgeable people who has taken\nthis position. He outlines his position\nin [this deck](https://drive.google.com/file/d/1BU5bV3X5w65DwSMapKcsr0ZvrMRU_Nbi/view) (e.g., page 9: â€œUnpopular Opinion\nabout AR-LLMs: AR LLMs are doomed.â€)\n\n## AGI Timeline\n\nHow likely is it that we will see super-intelligent algorithms in, say, the next five years? Most people reason about\nthis in the context of the so-called [Scaling Hypothesis](https://lastweekin.ai/p/the-ai-scaling-hypothesis), i.e., that\nmodels get better the larger they get. [Google BIG-bench](https://github.com/google/BIG-bench) has an excellent overview\nof progress so far that I keep referring to:\n\n![](https://storage.googleapis.com/langkilde-se-images/993e2fac-2436-4463-9d0c-401a5bbde200.jpeg)\n\nSince models are getting larger and larger, and access to training data keeps increasing, you could make the case that\nwe are in the early stages of an exponential trajectory. There is both quantitative and qualitative evidence of improved\nperformance, so there is no denying this trend exists. But you could also argue that performance evaluations are limited\nin scope and that we will find performance on broader, real-world tasks less impressive.\n\n![](https://storage.googleapis.com/langkilde-se-images/30b0e6c9-3900-4eb4-8956-f93158bc9a13.jpeg)\n\nSince we cannot explain the connection between the number of parameters and the reasoning capabilities of\ntransformer-based models, projections are speculation. No one knows if we will face diminishing returns or not. Some\nforms of progress arrive in an S-curve-like way. Early progress is slow; then, there is a rapid rush of improvement,\nfollowed by a plateau of diminishing returns. This could very well prove to be true for current models.\n\n![](https://storage.googleapis.com/langkilde-se-images/2669e65c-2bfd-4a53-b581-53579b7d2d27.jpeg)\n\nWithout an agreed-upon way to predict and explain how capabilities are related to the internal mechanics of these\nmodels, the scientific method is left in the dust cloud left behind by engineers. Whenever important issues become a\nmatter of speculation, things quickly get messy. People project their values, preferences, and ideology on the issue,\ncomplicating public discourse. Add to that the drastic impact that self-improvement could add. Those who argue that\nsuper-intelligent systems could arrive very soon speculate that Auto-Regressive Large Language Models might be capable\nof self-improvement, unleashing a rapid and uncontrollable force.\n\n**My position on â€œAGI Timelineâ€:** Empirical evidence indicates we will see continued performance improvements from\nauto-regressive language models, but there are no guarantees we wonâ€™t start seeing diminishing returns. I think models\nwill keep getting better on many forms of tasks, but some tasks will be out of reach for this paradigm of models (e.g.,\nsearching decision trees, optimizing policies, and symbolic reasoning). Furthermore, I find it unlikely (\u003C5%) that\ncurrent auto-regressive language models become capable of self-improvement, but I cannot altogether reject the\npossibility of it happening. I have, however, started feeling comfortable calling LLMs a form of AI and not just mere\nmachine-learning models. And I consider [AGI\n_-like_ systems to be already available](https://langkilde.se/post/2023-03-22-updated-assumptions-about-agi) today.\n\n## AGI Impact\n\n> I propose the Yann-Jaan continuum of existential risk from a misaligned AGI. At one end you\n> have [@ylecun](https://twitter.com/ylecun?ref_src=twsrc%5Etfw) who argues we are a long way off AGI and that alignment\n> will be easy. At the other end you have Jaan Tallinn, signatory to the moratorium letter.\n>\n> -- Ian Hogarth (\n> @soundboy) [April 4, 2023](https://twitter.com/soundboy/status/1643180253186072578?ref_src=twsrc%5Etfw)\n\nThis is the most speculative aspect. The shortest version of this section would be: we have no idea how the existence of\nartificial super-intelligence will impact humanity since it doesnâ€™t exist, and we have no experience on which to base\nour forecast. If you think that AGI is imminent, then by all means, speculate. Iâ€™m open-minded and think many versions\nof life with AGI are plausible, ranging from amazing to catastrophic.\n\n**My position on â€œAGI Impactâ€:** I embrace the benefits of advanced machine learning and nascent AI as predominantly\npositive. We will be able to get rid of tons of tedious work and unlock new, amazing products that will improve the\nquality of life for humans. We will also face new challenges, such as rampant misinformation, carbon emissions, etc.\nThis will require significant effort to handle, but it can be done. At the same time, I cannot altogether reject the\nrisks that super-intelligence comes with, simply because thereâ€™s very little based on which we can predict impact. In\nthe financial world, this would be referred to as [tail risk](https://en.wikipedia.org/wiki/Tail_risk): itâ€™s unlikely\nthat AGI is an existential threat to humanity, but it cannot be ruled out, and if it happens, the impact is\ncatastrophic. If and how you hedge against tail risk is a matter of preference.\n\n## Practicalities\n\nLeaving the issue of AGI aside, there is a long list of short-term challenges we must work on to make AI a net positive\nfor humanity. This list includes issues like:\n\n* A misinformation epidemic that is driven by zero-cost content creation.\n\n* Urgent need for reskilling people who are displaced in the labor market.\n\n* Carbon emissions from large-scale model training and inference.\n\n* The concentration of economic power with a small number of companies.\n\n* How to handle copyright and IP in an age of generative AI?\n\nWhile the negative impact of each of these issues is arguably less catastrophic than a super-intelligence causing the\nextinction of humanity, they are also significantly more likely problems.\n\n**In closing:** I choose to be an optimist, and I think AI will improve the quality of life for humans. We should enjoy\nall the great products we can build now while dealing with the practical issues we know to be real. Even if I cannot\nreject the possibility that there is\na [higher-order bit](https://www.urbandictionary.com/define.php?term=higher-order%20bit) we might be getting wrong.","src/content/blog/artificial-intelligence-scaling-laws.md","701388d9a5c0be60",{"html":145,"metadata":146},"\u003Ch2 id=\"executive-summary\">Executive Summary\u003C/h2>\n\u003Cul>\n\u003Cli>\n\u003Cp>\u003Cstrong>Progress in AI is predominantly positive ðŸŽ‰ðŸš€\u003C/strong> We should enjoy and embrace the benefits of advanced machine learning\nand nascent AI and look forward to the many incredible products we will see in the coming months and years.\u003C/p>\n\u003C/li>\n\u003Cli>\n\u003Cp>\u003Cstrong>Super-intelligent AGI is most likely still distant,\u003C/strong> and I find it unlikely (&#x3C;5%) that current models will become\ncapable of self-improvement. That said, AGI-like systems are here to stay, and Iâ€™m increasingly comfortable referring\nto things as AI systems rather than â€œmereâ€ machine learning systems.\u003C/p>\n\u003C/li>\n\u003Cli>\n\u003Cp>Due to the surprising abilities of Auto-Regressive Large Language Models (AR LLMs), \u003Cstrong>we cannot rule out the\npossibility of emerging self-improvement capabilities.\u003C/strong>\u003C/p>\n\u003C/li>\n\u003Cli>\n\u003Cp>\u003Cstrong>We have no idea how super-intelligent AGI would impact society.\u003C/strong> You can come up with a plausible story in which\nsuper-intelligent AGI has catastrophic consequences for humanity. But it could also be amazing ðŸ¤·ðŸ¼ðŸ™‚\u003C/p>\n\u003C/li>\n\u003Cli>\n\u003Cp>Ultimately, your feelings about current AI development depend on \u003Cstrong>how you prefer to handle tail risk.\u003C/strong> What do you\ndo if there is a tiny, tiny probability of a really, really bad outcome?\u003C/p>\n\u003C/li>\n\u003Cli>\n\u003Cp>\u003Cstrong>In the meantime, we should enjoy all the great products we can now build while dealing with the practical issues we\nknow to be real\u003C/strong> â€” misinformation, labor market reskilling, carbon emissions, and more. But none of these are reasons\nto stop progress.\u003C/p>\n\u003C/li>\n\u003C/ul>\n\u003Ch2 id=\"background\">Background\u003C/h2>\n\u003Cp>Auto-Regressive Large Language Models (AR LLMs) is an emerging technology gaining increasingly broad real-world use. As\nthese models become larger and larger their capacity and open-endedness create a difficult-to-predict scope of emergent\nbehavior. Developers of AR LLMs regularly discover unexpected model capabilities.\u003C/p>\n\u003Cblockquote>\n\u003Cp>Which stage of the Gartner hype cycle is â€œpeople lose their fucking minds and argue that we should start a nuclear war\nto prevent people from using mathsâ€? Asking for a friend.\u003C/p>\n\u003Cp>â€” Benedict Evans (\n@benedictevans) \u003Ca href=\"https://twitter.com/benedictevans/status/1641500204481368064?ref_src=twsrc%5Etfw\">March 30, 2023\u003C/a>\u003C/p>\n\u003C/blockquote>\n\u003Cp>Due to the enigmatic internals of these models, it is challenging to make predictions of future capabilities using the\nscientific method. Central to the scientific method is \u003Ca href=\"https://en.wikipedia.org/wiki/Falsifiability\">falsifiability\u003C/a>,\ni.e., that empirical tests can logically contradict theories or hypotheses. Currently, the scientific method is\nstruggling to keep up with engineering progress. Engineers are making much faster progress on scaling up models,\nresulting in emergent behavior researchers cannot fully explain. This presents a problem for everyone observing progress\nin AI: where are we heading? Without accepted scientific theories, people start extrapolating based on their\ninterpretation. As a result, people who are usually sensible can suddenly end up with extreme views. They also tend to\noscillate quickly between being impressed and scared. \u003Cstrong>This post attempts to make sense of the different theories and\ndevelop a position on the question of â€œWhat does the future of AI in society look like?â€.\u003C/strong>\u003C/p>\n\u003Cp>\u003Cstrong>First of all: Iâ€™ve always taken the position that existing artificial intelligence is far worse than human\nintelligence.\u003C/strong> I started learning about machine learning in the late 1990s, and every time I learn about the inner\nworkings of a new machine-learning algorithm, I feel, â€œIs this it?â€. It is hard to feel that something is intelligent\nwhen you understand the mechanics. Even Transformers evoke this feeling for me. The algorithm\nis \u003Ca href=\"https://github.com/karpathy/nanoGPT\">short and simple\u003C/a> and not something that feels nearly as sophisticated and\ncomplex as the human brain. Just read a few pages from any of\nthe \u003Ca href=\"https://www.amazon.com/Life-Ascending-Great-Inventions-Evolution/dp/0393338665\">great books Nick Lane has written (e.g., The Ten Great Inventions of Evolution)\u003C/a>,\nand youâ€™ll realize how much goes into our biological system. Coming into the question of AGI, my starting point is:\nweâ€™re far from human-like intelligence, and we should be humble.\u003C/p>\n\u003Ch2 id=\"what-trajectories-do-people-imagine-when-forecasting-the-future-of-ai\">What trajectories do people imagine when forecasting the future of AI?\u003C/h2>\n\u003Cp>To grossly oversimplify, there appears to be a matrix with two dimensions:\u003C/p>\n\u003Cul>\n\u003Cli>\n\u003Cp>\u003Cstrong>AGI Timeline.\u003C/strong> Will we get AGI soon, or is it still in the distant future?\u003C/p>\n\u003C/li>\n\u003Cli>\n\u003Cp>\u003Cstrong>AGI Impact.\u003C/strong> Will AGI be great, or will it result in the extinction of humans?\u003C/p>\n\u003C/li>\n\u003C/ul>\n\u003Cp>\u003Cimg src=\"https://storage.googleapis.com/langkilde-se-images/d2334493-322f-454c-8e2e-6713cd65c9f9.jpeg\" alt=\"\">\u003C/p>\n\u003Cp>Iâ€™ll focus on three groups that Iâ€™ll call: \u003Cstrong>â€œThe Optimists,â€\u003C/strong> \u003Cstrong>â€œThe Pessimists,â€\u003C/strong> and \u003Cstrong>â€œAGI is Distant.â€\u003C/strong>\u003C/p>\n\u003Cp>\u003Cstrong>The Optimists.\u003C/strong> You can tell a plausible story where humanity greatly benefits from the emergence of AGI. Assuming we\ncan reign in AGI and use it for the betterment of humanity, an intelligence vastly more capable than a human could\nunlock secrets of the universe we can only dream of today.\u003C/p>\n\u003Cul>\n\u003Cli>\n\u003Cp>\u003Cstrong>Short-term positive.\u003C/strong> Auto-Regressive Large Language Models automate tedious work and allow people to focus on more\nexciting things. Generative visual models will give many more people the power to visualize their thoughts. Overall,\nthis will be great for humanity.\u003C/p>\n\u003C/li>\n\u003Cli>\n\u003Cp>\u003Cstrong>Long-term positive.\u003C/strong> As models get smarter and smarter and have access to more and more information about the\nuniverse, we might start to get novel insights about how the world works emerging from models. There is no guarantee\nthis will happen, but since we are already surprised by what AR LLMs can do, we cannot reject the possibility.\u003C/p>\n\u003C/li>\n\u003C/ul>\n\u003Cp>\u003Cstrong>The Pessimists.\u003C/strong> You can also tell a plausible story in which AGI has a very negative impact on humanity. AI can be\nmuch more intelligent than humans and use information more efficiently. For example, AlphaZero learned to be superhuman\nat Go in only a few days. A misaligned AI smarter than\nhumans \u003Ca href=\"https://www.lesswrong.com/posts/Wic2P2bGejbFH3Sxb/summary-of-agi-ruin-a-list-of-lethalities\">could cause human extinction\u003C/a>.\nIt would also be virtually impossible to stop it if things go off the rails.\u003C/p>\n\u003Cblockquote>\n\u003Cp>I think that the magnitude of the AI alignment problem has been ridiculously overblown &#x26; our ability to solve it\nwidely underestimated.\u003C/p>\n\u003Cp>Iâ€™ve been publicly called stupid before, but never as often as by the â€œAI is a significant existential riskâ€ crowd.\u003C/p>\n\u003Cp>Thatâ€™s OK, Iâ€™m used to it.\u003C/p>\n\u003Cp>â€” Yann LeCun (@ylecun) \u003Ca href=\"https://twitter.com/ylecun/status/1637883960578682883?ref_src=twsrc%5Etfw\">March 20, 2023\u003C/a>\u003C/p>\n\u003C/blockquote>\n\u003Cul>\n\u003Cli>\n\u003Cp>\u003Cstrong>Short-term negative.\u003C/strong> AR LLMs are a threat to democracy, truth, and the internet. Bad actors will use AR LLMs to\nflood the internet with false information in a way that is indistinguishable from trustworthy information. Information\nwarfare will be dramatically escalated.\u003C/p>\n\u003C/li>\n\u003Cli>\n\u003Cp>\u003Cstrong>Long-term negative.\u003C/strong> A super-intelligent algorithm able to take real-world actions deliberately or accidentally\ntakes actions that harm or even extinguish humanity.\u003C/p>\n\u003C/li>\n\u003C/ul>\n\u003Cp>\u003Cstrong>AGI is Distant.\u003C/strong> You could also argue that current systems are far from comparable to humans, let alone\nsuper-intelligent. The fact that super-intelligence is so distant makes the debate about the impact of AGI hypothetical\nto the point of being a waste of time. Yann LeCun is one of the most experienced and knowledgeable people who has taken\nthis position. He outlines his position\nin \u003Ca href=\"https://drive.google.com/file/d/1BU5bV3X5w65DwSMapKcsr0ZvrMRU_Nbi/view\">this deck\u003C/a> (e.g., page 9: â€œUnpopular Opinion\nabout AR-LLMs: AR LLMs are doomed.â€)\u003C/p>\n\u003Ch2 id=\"agi-timeline\">AGI Timeline\u003C/h2>\n\u003Cp>How likely is it that we will see super-intelligent algorithms in, say, the next five years? Most people reason about\nthis in the context of the so-called \u003Ca href=\"https://lastweekin.ai/p/the-ai-scaling-hypothesis\">Scaling Hypothesis\u003C/a>, i.e., that\nmodels get better the larger they get. \u003Ca href=\"https://github.com/google/BIG-bench\">Google BIG-bench\u003C/a> has an excellent overview\nof progress so far that I keep referring to:\u003C/p>\n\u003Cp>\u003Cimg src=\"https://storage.googleapis.com/langkilde-se-images/993e2fac-2436-4463-9d0c-401a5bbde200.jpeg\" alt=\"\">\u003C/p>\n\u003Cp>Since models are getting larger and larger, and access to training data keeps increasing, you could make the case that\nwe are in the early stages of an exponential trajectory. There is both quantitative and qualitative evidence of improved\nperformance, so there is no denying this trend exists. But you could also argue that performance evaluations are limited\nin scope and that we will find performance on broader, real-world tasks less impressive.\u003C/p>\n\u003Cp>\u003Cimg src=\"https://storage.googleapis.com/langkilde-se-images/30b0e6c9-3900-4eb4-8956-f93158bc9a13.jpeg\" alt=\"\">\u003C/p>\n\u003Cp>Since we cannot explain the connection between the number of parameters and the reasoning capabilities of\ntransformer-based models, projections are speculation. No one knows if we will face diminishing returns or not. Some\nforms of progress arrive in an S-curve-like way. Early progress is slow; then, there is a rapid rush of improvement,\nfollowed by a plateau of diminishing returns. This could very well prove to be true for current models.\u003C/p>\n\u003Cp>\u003Cimg src=\"https://storage.googleapis.com/langkilde-se-images/2669e65c-2bfd-4a53-b581-53579b7d2d27.jpeg\" alt=\"\">\u003C/p>\n\u003Cp>Without an agreed-upon way to predict and explain how capabilities are related to the internal mechanics of these\nmodels, the scientific method is left in the dust cloud left behind by engineers. Whenever important issues become a\nmatter of speculation, things quickly get messy. People project their values, preferences, and ideology on the issue,\ncomplicating public discourse. Add to that the drastic impact that self-improvement could add. Those who argue that\nsuper-intelligent systems could arrive very soon speculate that Auto-Regressive Large Language Models might be capable\nof self-improvement, unleashing a rapid and uncontrollable force.\u003C/p>\n\u003Cp>\u003Cstrong>My position on â€œAGI Timelineâ€:\u003C/strong> Empirical evidence indicates we will see continued performance improvements from\nauto-regressive language models, but there are no guarantees we wonâ€™t start seeing diminishing returns. I think models\nwill keep getting better on many forms of tasks, but some tasks will be out of reach for this paradigm of models (e.g.,\nsearching decision trees, optimizing policies, and symbolic reasoning). Furthermore, I find it unlikely (&#x3C;5%) that\ncurrent auto-regressive language models become capable of self-improvement, but I cannot altogether reject the\npossibility of it happening. I have, however, started feeling comfortable calling LLMs a form of AI and not just mere\nmachine-learning models. And I consider \u003Ca href=\"https://langkilde.se/post/2023-03-22-updated-assumptions-about-agi\">AGI\n\u003Cem>-like\u003C/em> systems to be already available\u003C/a> today.\u003C/p>\n\u003Ch2 id=\"agi-impact\">AGI Impact\u003C/h2>\n\u003Cblockquote>\n\u003Cp>I propose the Yann-Jaan continuum of existential risk from a misaligned AGI. At one end you\nhave \u003Ca href=\"https://twitter.com/ylecun?ref_src=twsrc%5Etfw\">@ylecun\u003C/a> who argues we are a long way off AGI and that alignment\nwill be easy. At the other end you have Jaan Tallinn, signatory to the moratorium letter.\u003C/p>\n\u003Cp>â€” Ian Hogarth (\n@soundboy) \u003Ca href=\"https://twitter.com/soundboy/status/1643180253186072578?ref_src=twsrc%5Etfw\">April 4, 2023\u003C/a>\u003C/p>\n\u003C/blockquote>\n\u003Cp>This is the most speculative aspect. The shortest version of this section would be: we have no idea how the existence of\nartificial super-intelligence will impact humanity since it doesnâ€™t exist, and we have no experience on which to base\nour forecast. If you think that AGI is imminent, then by all means, speculate. Iâ€™m open-minded and think many versions\nof life with AGI are plausible, ranging from amazing to catastrophic.\u003C/p>\n\u003Cp>\u003Cstrong>My position on â€œAGI Impactâ€:\u003C/strong> I embrace the benefits of advanced machine learning and nascent AI as predominantly\npositive. We will be able to get rid of tons of tedious work and unlock new, amazing products that will improve the\nquality of life for humans. We will also face new challenges, such as rampant misinformation, carbon emissions, etc.\nThis will require significant effort to handle, but it can be done. At the same time, I cannot altogether reject the\nrisks that super-intelligence comes with, simply because thereâ€™s very little based on which we can predict impact. In\nthe financial world, this would be referred to as \u003Ca href=\"https://en.wikipedia.org/wiki/Tail_risk\">tail risk\u003C/a>: itâ€™s unlikely\nthat AGI is an existential threat to humanity, but it cannot be ruled out, and if it happens, the impact is\ncatastrophic. If and how you hedge against tail risk is a matter of preference.\u003C/p>\n\u003Ch2 id=\"practicalities\">Practicalities\u003C/h2>\n\u003Cp>Leaving the issue of AGI aside, there is a long list of short-term challenges we must work on to make AI a net positive\nfor humanity. This list includes issues like:\u003C/p>\n\u003Cul>\n\u003Cli>\n\u003Cp>A misinformation epidemic that is driven by zero-cost content creation.\u003C/p>\n\u003C/li>\n\u003Cli>\n\u003Cp>Urgent need for reskilling people who are displaced in the labor market.\u003C/p>\n\u003C/li>\n\u003Cli>\n\u003Cp>Carbon emissions from large-scale model training and inference.\u003C/p>\n\u003C/li>\n\u003Cli>\n\u003Cp>The concentration of economic power with a small number of companies.\u003C/p>\n\u003C/li>\n\u003Cli>\n\u003Cp>How to handle copyright and IP in an age of generative AI?\u003C/p>\n\u003C/li>\n\u003C/ul>\n\u003Cp>While the negative impact of each of these issues is arguably less catastrophic than a super-intelligence causing the\nextinction of humanity, they are also significantly more likely problems.\u003C/p>\n\u003Cp>\u003Cstrong>In closing:\u003C/strong> I choose to be an optimist, and I think AI will improve the quality of life for humans. We should enjoy\nall the great products we can build now while dealing with the practical issues we know to be real. Even if I cannot\nreject the possibility that there is\na \u003Ca href=\"https://www.urbandictionary.com/define.php?term=higher-order%20bit\">higher-order bit\u003C/a> we might be getting wrong.\u003C/p>",{"headings":147,"localImagePaths":164,"remoteImagePaths":165,"frontmatter":166,"imagePaths":167},[148,149,152,155,158,161],{"depth":61,"slug":55,"text":56},{"depth":61,"slug":150,"text":151},"background","Background",{"depth":61,"slug":153,"text":154},"what-trajectories-do-people-imagine-when-forecasting-the-future-of-ai","What trajectories do people imagine when forecasting the future of AI?",{"depth":61,"slug":156,"text":157},"agi-timeline","AGI Timeline",{"depth":61,"slug":159,"text":160},"agi-impact","AGI Impact",{"depth":61,"slug":162,"text":163},"practicalities","Practicalities",[],[],{"pubDate":140,"title":139},[],"artificial-intelligence-scaling-laws.md","building-a-world-class-team",{"id":169,"data":171,"body":174,"filePath":175,"digest":176,"rendered":177,"legacyId":203},{"title":172,"pubDate":173},"Building a world-class team","2023-09-19","_This is an excerpt from a recent Company Update email I sent to the team at Kognic:_\n\n\n### Foundations of a Great Team\n\n**What does it take to build a world-class team?** To learn and evolve, I read biographies about companies and their\nleaders and talk to as many CEOs of great companies as possible. A recurring theme of books and conversations is the\ncritical importance of strong teams of excellent people. That, in turn, requires great culture and outstanding\nleadership. But what is a great culture and outstanding leadership? I start with a few principles:\n\n\\- **Transparency.** Great teams share information freely. They give and collect lots of feedback.  \n\\- **Performance.** Great teams expect greatness. They challenge themselves and others to grow.  \n\\- **Empowerment.** Great teams empower each other and win together.  \n\\- **Rapid** **Iteration.** Great teams iterate faster than everyone else.\n\nBut, as we all know, culture is the sum of our daily actions, not something we write in a document. Letâ€™s start with\nsome theory before we dig into specific challenges.\n\n### The Principal-Agent Problem\n\nThe [Principal-Agent](https://en.wikipedia.org/wiki/Principal%E2%80%93agent_problem) problem describes the conflict of interest that arises when one entity takes action on behalf of another. The problem worsens the larger the\ndiscrepancy between the two entitiesâ€™ interests and information. The difference between what the agent does and what is\nactually in the principal's interest is known as the â€œagency cost.â€ To make this more concrete: Shareholders in a\ncompany hire a CEO. How can shareholders trust the CEO to make decisions in their interest? How are you sure the CEO\ndoes not just act in her best interest? The CEO will have time, expertise, and information that shareholders do not. The\nsame problem applies to all executives and their teams.\n\nI usually share something one of my mentors tells me: \"_Smart people with the same information and goals come to the\nsame conclusion. The problem is that people have different information (or experience) and different goals (or risk\npreferences).\"_ **Culture is to select people based on their commitment to similar goals, risk preferences, and\ndetermination.** It's exclusive but not based on gender, ethnicity, or experience - it's exclusive based on goals,\npreferences, and determination. If someone isn't smart enough or driven enough, I reserve the right to terminate that\nperson. And I think that's what most of you want. You want to work with like-minded, inspiring, and incredible people.\n\n![](https://storage.googleapis.com/langkilde-se-images/5906ddf8-a8e9-4acc-90ef-b973e302a4dc.jpeg)\n\n### Motivation, Culture, and High Expectations\n\nHandling the Principal-Agent problem is the central challenge of managing teams and companies. You have to account for a\nvast range of things:\n\n**What makes you motivated?** This is the first critical divider in terms of culture. Different people are motivated\nby different things. Some want work-life balance, psychological safety, and predictability. My wife is an example of\nthat: we complement each other in a great way because she favors a stable household and lots of time available for her\nnon-work interests. She likes her job, but it's not nearly as important to her as it is for me. She'd hate working with\nme professionally, and I love her for that. I need to wake up in the morning and feel like I'm impacting the world. I\nneed to feel like I'm constantly learning. Why? Well, I suppose I have my fair share of demons. At least I've learned to\nharness them and channel that energy to create exciting things. There is a Hunter S. Thompson quote that sums up my\nworldview pretty well: _â€œLife should not be a journey to the grave with the intention of arriving safely in a pretty and\nwell-preserved body, but rather to skid in broadside in a cloud of smoke, thoroughly used up, totally worn out, and\nloudly proclaiming \"Wow! What a Ride!â€_ (Caveat: HST was a gun-loving drug addict who died by suicide. But it's still a\ngreat quote!)\n\n**I tell everyone who is about to join Kognic: there are much easier jobs than working at Kognic.** We offer a\nhigh-growth environment and are determined to be the best in the world. That's a mindset that we are looking for in\ncandidates and ourselves. You must be smart and driven to thrive in our environment. And we must have the courage to\nassume we can continue hiring insanely intelligent and driven people. Sometimes, that means it will take longer to hire\nfor specific roles. It also means hiring managers must be attractive leaders for whom great talent wants to work.\nLeaders cannot sit around and complain about facing a low-quality hiring pipeline. That's just a symptom they are not\nspending enough time out there attracting talent. **Great leaders are talent magnets**. Poor leadership is the main\nreason great talent leaves. This does not mean we expect everyone to work crazy hours - it is a marathon, not a sprint.\nYou will have bad days and good days. We cannot always bring our best every day - but we can always be committed to\nbecoming the best over time. I'd much rather feel the heat of high expectations than be bored, and we look for people\nlike that when hiring. It's not for everyone, but it is what we look for at Kognic.\n\n### Balancing High Performance with Psychological Safety\n\n**How do you balance high expectations with being friendly and social?** I'm proud that we have a â€œzero asshole\npolicy.â€ I do not tolerate team members going around being rude or disrespectful. Hearing someone talk shit about\nsomeone else when they are not around is a grave offense in my book. If you have feedback, tell it to that personâ€™s\nface. If that doesn't help, bring it to your or their manager. Once you've done that, act like a professional. There is\nno reason we cannot combine being fair to each other, have fun together, and expect extraordinary things from each\nother. Sure, leaders in the company need to be prepared to make difficult decisions that might hurt people when\nrequired. But there's no reason to be an asshole about it. I think we've done an excellent job balancing high\nperformance with a strong social bond in the team. Toxic team members can quickly spread a lot of negative energy.\nEveryone should welcome raising issues, but the best people can constructively raise issues. They don't just whine about\nit. Most people I talk to are impressed by how friendly and nice our team is, and I agree. Clearly, we can both create a\nhigh-performance culture and be nice. All that said, at the end of the day, we are _colleagues first, friends second_. I\nwill always make decisions based on what is in the interest of Kognic and our mission to accelerate alignment.\nSometimes, that will be at the expense of individuals. I acknowledge this, and I think all companies and leaders should\nbe honest about this. I encourage everyone to have a solid social network outside of work. If you don't, you become very\nvulnerable.\n\n### Trust, Empowerment, and Accountability\n\n**How do you balance being challenged with being trusted?** There is an inherent tension between having a manager\nwho challenges you and feeling that you are trusted. I think we all want to feel trusted. But I also firmly believe that\nhigh-performing individuals want to be challenged. I would never work for a leader who doesn't express expectations or\ncannot push my personal growth. I want to work for people I admire and am inspired by, and I think we need people who\nfeel this way across the company. Steve Jobs\ndespised \"[the professional-managerial class](https://www.youtube.com/watch?v=QplyFXgIx7Q)\", and so does Elon Musk. I\ntend to agree: Kognic wants leaders who are able to jump into the arena when needed and who can inspire teams to do\nbetter based on their experience and expertise. Clearly, great ICs **_are not necessarily_** great leaders, but the best\nleaders are usually **_also_** great ICs in some area. We have to believe we can find those that are both. We have\nseveral great examples of people like this at Kognic: leaders who could step into most roles and do a pretty good job. I\nexpect those who lead at Kognic to know what is going on in their team, to have a working knowledge of essential\ndetails, and to have the ability to inspire their team members with their experience and expertise. And what you lack in\nexperience, you can always make up for with determination, grit, or raw talent. In my case, I make up for my lack of\nexperience by working moreâ€”a lot more. I need to collect and spend way more time analyzing information to be the CEO\nKognic needs since I'm 35 years old without any previous experience running a company. I'm not complaining; I'm just\nsaying it takes a huge effort.\n\n**Empowered teams with context can make better decisions, but leaders need to still challenge and coach.** At\nKognic, we are strong believers in empowered teams. We think teams must be accountable for delivering value without\nleaders imposing solutions. We expect leaders to set priorities, declare intentions, and then hand them to teams to own\nthe outcome. That's not the same as \"servant leadership\". Leaders are not simply there to observe and support. They are\nthere to inspire, challenge, coach, and help when needed. They should be knowledgeable enough to analyze the situation\nand ask critical questions when needed. They should challenge the scope. They should trust but verify. We cannot let a\ndesire to \"get out of the way of teams\" be confused with \"not setting high expectations and challenging each other.â€\nLeaders need to ask, \"Can this be done faster?\" or \"Is this necessary?\" or \"Have you considered this priority?\". That\ndoes not go against our intention of letting teams take ownership of their work. Empowerment is a more demanding way to\nwork. It requires everyone on the team to take ownership of what creates value. You cannot just expect a manager to tell\nyou what to do; that's a cop-out. We have selected a very demanding operating mode, and it only works if we have\nexcellent people we trust can take full responsibility. I always argue leaders should coach, and ultimately replace,\npeople if they feel compelled to micromanage them. Always resist the temptation to start micromanaging. If you donâ€™t\nthink your direct report can handle the responsibility you give them, you coach them as far as you can. If that doesn't\nwork, you replace them.\n\n**We are morally obligated to act ethically as a company and individuals.** It's not just about winning but also\n_how_ we win. We would win more by lowering ourselves to Scaleâ€™s workforce compensation level. We won't as long as I'm\nCEO. I refuse. I don't want money gained at the expense of other people suffering. I also won't summarily fire someone\nthe way Musk or Jobs seem to have done during their careers. I won't publicly berate someone for being an idiot, even\nwhen they are, in fact, being an idiot. It goes against my morals to incur suffering like that, regardless of how\nrighteous I might feel. **Does this limit my success? I don't care**. I genuinely think we can be ethical and win;\nhowever, being ethical is non-negotiable. Again, being ethical is not the same as lowering expectations or failing to\nmake hard decisions when required. I will terminate people who do not meet the bar for working at Kognic. But I won't\npublicly murder them. We will do it fairly, and we will be generous if we've failed when hiring. I think we will be more\nsuccessful if we prioritize physical and mental health in the team. Sleeping under your desk is stupid. It might make\nyou feel like a hero, but I think it just makes you look like an unstable person who has no idea how to manage time or\nteams. People can only do so many productive hours of work in a sustained way anyway. There are many other types of \"\nposing\" like that out there that I think are entirely irrational.\n\n**How do we balance psychological safety versus urgency and accountability?** Fear is the mind-killer. Scared people\nwill not take enough risk. They won't think outside the box. They won't object to the premise of misguided requests from\nmanagement. Fear will make people shut up and focus on survival. Fear shuts down the flow of information, and it hurts\ncreative thinking. Management by fear has severe adverse side effects. At the same time, urgency and accountability\nencourage creativity and progress. Being too relaxed is not suitable for doing a great job. Most people get more done\nright before deadlines. Just look at the finishing time for the London Marathon. Spoiler: it is not a\nnormal-distribution.\n\n![](https://storage.googleapis.com/langkilde-se-images/d066b5e4-a1aa-4ccb-824d-aaf7bded9639.jpeg)\n\n**= > I believe that leaders need to create a strong sense of urgency but without scaring people.** I try to combine\nrelentless urgency with profound optimism. We have to always be in a hurry to make progress, but we have to approach\ntasks with joy and curiosity. If someone gives you a timeline for six months, ask what we can do to make it take two\nmonths, but do not threaten the person who gave you the estimate. Delete everything that isn't critical to your mission,\nbut do it with curiosity. Build excitement around speed. Faster is always better. It's so easy to fall into the trap of\nassuming, \"This needs to take X months.\" Large companies have such low expectations from individual contributors that\nthey get used to things taking a long time. If every person in a chain of five lowers the bar by 10%, you end up with a\nsignificant accumulated delay. But if each layer hunts down 10% of speed-up instead, you have a massive difference in\naccumulated advantage. That's the difference between mediocre and great companies. You will move slowly if you hire slow\npeople and let them make slow plans. Instead, put impatient and relentless people in charge and eliminate all the slow\npeople. I promise you that you will get results much faster. And talented people will be happier when things move\nforward quickly. My experience is that 90% of the work can be finished in 10% of the time if you are OK with 20% of\nthings going wrong instead of 10%. That's an acceptable failure rate to be faster than everyone else. The value of being\n10x faster far exceeds being right 10% more often. Most decisions can be changed anyway. As you know, I prefer being\nright over being consistent. So, I expect leaders to challenge timelines and hunt for speed whenever possible. You have\nto question the scope of projects to find just the right effort for our stage. Tuning the scope requires a deep\nunderstanding of the work being done and a fair amount of impatience. Delete as much as possible, and if you add about\n20% back in later, you've probably found an decent deleting level.\n\n**How transparent can we be?** I prefer to deal with things openly in a large group, over 1-1s, or closed groups.\nThe more information we can push into the open, the better. The fewer closed Slack channels, the better. You can all\nlearn to filter that which is relevant from the rest. Being exposed and tuning your filter is better than being out of\ntouch. Cross-functional teams with direct communication between ICs far exceed hierarchy in speed and efficiency.\nManagers are not there to monitor and approve things but to challenge, inspire, and support. Report your conclusions and\nbroadcast them as widely as possible. But do not slow down by going through intermediates. Rather than talk to someone's\nmanager to figure something out, talk directly to the person you need to talk to. I expect leaders to share openly the\ngood, the bad, and the ugly.\n\n**There are some limits to transparency.** We do not publicly criticize a person's performance. We do not share all\nthe details when someone is terminated. We cannot talk about sensitive aspects of negotiations with customers or\ninvestors. We cannot share if/when someone offers to buy the company. There are limits. But we set a high bar for what\nshould be shared. We always share if we have problems in a process or if some deal is going south. We openly share our\ncall reports, meeting reports, financials, etc. I'd much rather send a few emails too many than too few.\n\n### Leaders Create Accelerating Flywheels\n\n**Leaders create accelerating flywheels.** The most successful leaders create \"flywheel teams.\" Teams that\naccelerate more and more and eventually spin really, really fast with minimum external force applied. That requires\nremoving friction, setting a clear focus, and ensuring everyone on the team is excellent. When I read, e.g., the\nbiography about Musk, he appears not to scale. At all. I think that's his greatest weakness. Teams appear highly\ndependent on his intervention. While he gets the urgency right and can attract incredibly talented people, he constantly\ninvolves himself to such a degree that the future of his companies is uncertain without him. I suspect he craves being\nat the center of attention more than is in the interest of his companies. But I guess you must take the good and the bad\nwith some people.\n\n**Leadership is telling an engaging story.** A big part of leadership is being a great storyteller. We are all part\nof a narrative. Kognic is a story about a team trying to develop safe and reliable embodied AI. We believe that AI is\nthe \"highest order bit.\" It is the most important thing we can work on during our lifetime. If we get AI Alignment\nright, everything else will follow. Every decision we take, every customer we sign, or every product feature we build\nneeds to move us toward our vision of accelerating alignment. To reach our goal, we must dance with armed elephants,\nfight Kafka-esque complexity, and overcome many other challenges. It's an adventure. Leaders at Kognic are expected to\nbe able to connect their work and the work of their team to our vision. To weave their thread into the story. What is\nyour team doing to accelerate alignment? There are many ways to help: contributing to a lean data factory, helping hire\nfantastic talent, ensuring we get paid for our work, signing great contracts with customers, etc. We must be useful and\nvaluable to customers _now_ to gain the trust and resources needed to change the world. Every day, we become bigger and\nmore capable, and everyone on the team is part of making that happen.\n\nKognic is not looking to be like _most_ companies. **We are the best company in the world at accelerating autonomy**.\nOutstanding leadership at all company levels is required for us to succeed. While demanding, the reward is that we get\nto enjoy **a hell of a ride** with ambitious and smart people.","src/content/blog/building-a-world-class-team.md","663a9de32aa0ab3f",{"html":178,"metadata":179},"\u003Cp>\u003Cem>This is an excerpt from a recent Company Update email I sent to the team at Kognic:\u003C/em>\u003C/p>\n\u003Ch3 id=\"foundations-of-a-great-team\">Foundations of a Great Team\u003C/h3>\n\u003Cp>\u003Cstrong>What does it take to build a world-class team?\u003C/strong> To learn and evolve, I read biographies about companies and their\nleaders and talk to as many CEOs of great companies as possible. A recurring theme of books and conversations is the\ncritical importance of strong teams of excellent people. That, in turn, requires great culture and outstanding\nleadership. But what is a great culture and outstanding leadership? I start with a few principles:\u003C/p>\n\u003Cp>- \u003Cstrong>Transparency.\u003C/strong> Great teams share information freely. They give and collect lots of feedback.\u003Cbr>\n- \u003Cstrong>Performance.\u003C/strong> Great teams expect greatness. They challenge themselves and others to grow.\u003Cbr>\n- \u003Cstrong>Empowerment.\u003C/strong> Great teams empower each other and win together.\u003Cbr>\n- \u003Cstrong>Rapid\u003C/strong> \u003Cstrong>Iteration.\u003C/strong> Great teams iterate faster than everyone else.\u003C/p>\n\u003Cp>But, as we all know, culture is the sum of our daily actions, not something we write in a document. Letâ€™s start with\nsome theory before we dig into specific challenges.\u003C/p>\n\u003Ch3 id=\"the-principal-agent-problem\">The Principal-Agent Problem\u003C/h3>\n\u003Cp>The \u003Ca href=\"https://en.wikipedia.org/wiki/Principal%E2%80%93agent_problem\">Principal-Agent\u003C/a> problem describes the conflict of interest that arises when one entity takes action on behalf of another. The problem worsens the larger the\ndiscrepancy between the two entitiesâ€™ interests and information. The difference between what the agent does and what is\nactually in the principalâ€™s interest is known as the â€œagency cost.â€ To make this more concrete: Shareholders in a\ncompany hire a CEO. How can shareholders trust the CEO to make decisions in their interest? How are you sure the CEO\ndoes not just act in her best interest? The CEO will have time, expertise, and information that shareholders do not. The\nsame problem applies to all executives and their teams.\u003C/p>\n\u003Cp>I usually share something one of my mentors tells me: â€œ\u003Cem>Smart people with the same information and goals come to the\nsame conclusion. The problem is that people have different information (or experience) and different goals (or risk\npreferences).â€\u003C/em> \u003Cstrong>Culture is to select people based on their commitment to similar goals, risk preferences, and\ndetermination.\u003C/strong> Itâ€™s exclusive but not based on gender, ethnicity, or experience - itâ€™s exclusive based on goals,\npreferences, and determination. If someone isnâ€™t smart enough or driven enough, I reserve the right to terminate that\nperson. And I think thatâ€™s what most of you want. You want to work with like-minded, inspiring, and incredible people.\u003C/p>\n\u003Cp>\u003Cimg src=\"https://storage.googleapis.com/langkilde-se-images/5906ddf8-a8e9-4acc-90ef-b973e302a4dc.jpeg\" alt=\"\">\u003C/p>\n\u003Ch3 id=\"motivation-culture-and-high-expectations\">Motivation, Culture, and High Expectations\u003C/h3>\n\u003Cp>Handling the Principal-Agent problem is the central challenge of managing teams and companies. You have to account for a\nvast range of things:\u003C/p>\n\u003Cp>\u003Cstrong>What makes you motivated?\u003C/strong> This is the first critical divider in terms of culture. Different people are motivated\nby different things. Some want work-life balance, psychological safety, and predictability. My wife is an example of\nthat: we complement each other in a great way because she favors a stable household and lots of time available for her\nnon-work interests. She likes her job, but itâ€™s not nearly as important to her as it is for me. Sheâ€™d hate working with\nme professionally, and I love her for that. I need to wake up in the morning and feel like Iâ€™m impacting the world. I\nneed to feel like Iâ€™m constantly learning. Why? Well, I suppose I have my fair share of demons. At least Iâ€™ve learned to\nharness them and channel that energy to create exciting things. There is a Hunter S. Thompson quote that sums up my\nworldview pretty well: \u003Cem>â€œLife should not be a journey to the grave with the intention of arriving safely in a pretty and\nwell-preserved body, but rather to skid in broadside in a cloud of smoke, thoroughly used up, totally worn out, and\nloudly proclaiming â€œWow! What a Ride!â€\u003C/em> (Caveat: HST was a gun-loving drug addict who died by suicide. But itâ€™s still a\ngreat quote!)\u003C/p>\n\u003Cp>\u003Cstrong>I tell everyone who is about to join Kognic: there are much easier jobs than working at Kognic.\u003C/strong> We offer a\nhigh-growth environment and are determined to be the best in the world. Thatâ€™s a mindset that we are looking for in\ncandidates and ourselves. You must be smart and driven to thrive in our environment. And we must have the courage to\nassume we can continue hiring insanely intelligent and driven people. Sometimes, that means it will take longer to hire\nfor specific roles. It also means hiring managers must be attractive leaders for whom great talent wants to work.\nLeaders cannot sit around and complain about facing a low-quality hiring pipeline. Thatâ€™s just a symptom they are not\nspending enough time out there attracting talent. \u003Cstrong>Great leaders are talent magnets\u003C/strong>. Poor leadership is the main\nreason great talent leaves. This does not mean we expect everyone to work crazy hours - it is a marathon, not a sprint.\nYou will have bad days and good days. We cannot always bring our best every day - but we can always be committed to\nbecoming the best over time. Iâ€™d much rather feel the heat of high expectations than be bored, and we look for people\nlike that when hiring. Itâ€™s not for everyone, but it is what we look for at Kognic.\u003C/p>\n\u003Ch3 id=\"balancing-high-performance-with-psychological-safety\">Balancing High Performance with Psychological Safety\u003C/h3>\n\u003Cp>\u003Cstrong>How do you balance high expectations with being friendly and social?\u003C/strong> Iâ€™m proud that we have a â€œzero asshole\npolicy.â€ I do not tolerate team members going around being rude or disrespectful. Hearing someone talk shit about\nsomeone else when they are not around is a grave offense in my book. If you have feedback, tell it to that personâ€™s\nface. If that doesnâ€™t help, bring it to your or their manager. Once youâ€™ve done that, act like a professional. There is\nno reason we cannot combine being fair to each other, have fun together, and expect extraordinary things from each\nother. Sure, leaders in the company need to be prepared to make difficult decisions that might hurt people when\nrequired. But thereâ€™s no reason to be an asshole about it. I think weâ€™ve done an excellent job balancing high\nperformance with a strong social bond in the team. Toxic team members can quickly spread a lot of negative energy.\nEveryone should welcome raising issues, but the best people can constructively raise issues. They donâ€™t just whine about\nit. Most people I talk to are impressed by how friendly and nice our team is, and I agree. Clearly, we can both create a\nhigh-performance culture and be nice. All that said, at the end of the day, we are \u003Cem>colleagues first, friends second\u003C/em>. I\nwill always make decisions based on what is in the interest of Kognic and our mission to accelerate alignment.\nSometimes, that will be at the expense of individuals. I acknowledge this, and I think all companies and leaders should\nbe honest about this. I encourage everyone to have a solid social network outside of work. If you donâ€™t, you become very\nvulnerable.\u003C/p>\n\u003Ch3 id=\"trust-empowerment-and-accountability\">Trust, Empowerment, and Accountability\u003C/h3>\n\u003Cp>\u003Cstrong>How do you balance being challenged with being trusted?\u003C/strong> There is an inherent tension between having a manager\nwho challenges you and feeling that you are trusted. I think we all want to feel trusted. But I also firmly believe that\nhigh-performing individuals want to be challenged. I would never work for a leader who doesnâ€™t express expectations or\ncannot push my personal growth. I want to work for people I admire and am inspired by, and I think we need people who\nfeel this way across the company. Steve Jobs\ndespised â€œ\u003Ca href=\"https://www.youtube.com/watch?v=QplyFXgIx7Q\">the professional-managerial class\u003C/a>â€, and so does Elon Musk. I\ntend to agree: Kognic wants leaders who are able to jump into the arena when needed and who can inspire teams to do\nbetter based on their experience and expertise. Clearly, great ICs \u003Cstrong>\u003Cem>are not necessarily\u003C/em>\u003C/strong> great leaders, but the best\nleaders are usually \u003Cstrong>\u003Cem>also\u003C/em>\u003C/strong> great ICs in some area. We have to believe we can find those that are both. We have\nseveral great examples of people like this at Kognic: leaders who could step into most roles and do a pretty good job. I\nexpect those who lead at Kognic to know what is going on in their team, to have a working knowledge of essential\ndetails, and to have the ability to inspire their team members with their experience and expertise. And what you lack in\nexperience, you can always make up for with determination, grit, or raw talent. In my case, I make up for my lack of\nexperience by working moreâ€”a lot more. I need to collect and spend way more time analyzing information to be the CEO\nKognic needs since Iâ€™m 35 years old without any previous experience running a company. Iâ€™m not complaining; Iâ€™m just\nsaying it takes a huge effort.\u003C/p>\n\u003Cp>\u003Cstrong>Empowered teams with context can make better decisions, but leaders need to still challenge and coach.\u003C/strong> At\nKognic, we are strong believers in empowered teams. We think teams must be accountable for delivering value without\nleaders imposing solutions. We expect leaders to set priorities, declare intentions, and then hand them to teams to own\nthe outcome. Thatâ€™s not the same as â€œservant leadershipâ€. Leaders are not simply there to observe and support. They are\nthere to inspire, challenge, coach, and help when needed. They should be knowledgeable enough to analyze the situation\nand ask critical questions when needed. They should challenge the scope. They should trust but verify. We cannot let a\ndesire to â€œget out of the way of teamsâ€ be confused with â€œnot setting high expectations and challenging each other.â€\nLeaders need to ask, â€œCan this be done faster?â€ or â€œIs this necessary?â€ or â€œHave you considered this priority?â€. That\ndoes not go against our intention of letting teams take ownership of their work. Empowerment is a more demanding way to\nwork. It requires everyone on the team to take ownership of what creates value. You cannot just expect a manager to tell\nyou what to do; thatâ€™s a cop-out. We have selected a very demanding operating mode, and it only works if we have\nexcellent people we trust can take full responsibility. I always argue leaders should coach, and ultimately replace,\npeople if they feel compelled to micromanage them. Always resist the temptation to start micromanaging. If you donâ€™t\nthink your direct report can handle the responsibility you give them, you coach them as far as you can. If that doesnâ€™t\nwork, you replace them.\u003C/p>\n\u003Cp>\u003Cstrong>We are morally obligated to act ethically as a company and individuals.\u003C/strong> Itâ€™s not just about winning but also\n\u003Cem>how\u003C/em> we win. We would win more by lowering ourselves to Scaleâ€™s workforce compensation level. We wonâ€™t as long as Iâ€™m\nCEO. I refuse. I donâ€™t want money gained at the expense of other people suffering. I also wonâ€™t summarily fire someone\nthe way Musk or Jobs seem to have done during their careers. I wonâ€™t publicly berate someone for being an idiot, even\nwhen they are, in fact, being an idiot. It goes against my morals to incur suffering like that, regardless of how\nrighteous I might feel. \u003Cstrong>Does this limit my success? I donâ€™t care\u003C/strong>. I genuinely think we can be ethical and win;\nhowever, being ethical is non-negotiable. Again, being ethical is not the same as lowering expectations or failing to\nmake hard decisions when required. I will terminate people who do not meet the bar for working at Kognic. But I wonâ€™t\npublicly murder them. We will do it fairly, and we will be generous if weâ€™ve failed when hiring. I think we will be more\nsuccessful if we prioritize physical and mental health in the team. Sleeping under your desk is stupid. It might make\nyou feel like a hero, but I think it just makes you look like an unstable person who has no idea how to manage time or\nteams. People can only do so many productive hours of work in a sustained way anyway. There are many other types of â€\nposingâ€ like that out there that I think are entirely irrational.\u003C/p>\n\u003Cp>\u003Cstrong>How do we balance psychological safety versus urgency and accountability?\u003C/strong> Fear is the mind-killer. Scared people\nwill not take enough risk. They wonâ€™t think outside the box. They wonâ€™t object to the premise of misguided requests from\nmanagement. Fear will make people shut up and focus on survival. Fear shuts down the flow of information, and it hurts\ncreative thinking. Management by fear has severe adverse side effects. At the same time, urgency and accountability\nencourage creativity and progress. Being too relaxed is not suitable for doing a great job. Most people get more done\nright before deadlines. Just look at the finishing time for the London Marathon. Spoiler: it is not a\nnormal-distribution.\u003C/p>\n\u003Cp>\u003Cimg src=\"https://storage.googleapis.com/langkilde-se-images/d066b5e4-a1aa-4ccb-824d-aaf7bded9639.jpeg\" alt=\"\">\u003C/p>\n\u003Cp>\u003Cstrong>= > I believe that leaders need to create a strong sense of urgency but without scaring people.\u003C/strong> I try to combine\nrelentless urgency with profound optimism. We have to always be in a hurry to make progress, but we have to approach\ntasks with joy and curiosity. If someone gives you a timeline for six months, ask what we can do to make it take two\nmonths, but do not threaten the person who gave you the estimate. Delete everything that isnâ€™t critical to your mission,\nbut do it with curiosity. Build excitement around speed. Faster is always better. Itâ€™s so easy to fall into the trap of\nassuming, â€œThis needs to take X months.â€ Large companies have such low expectations from individual contributors that\nthey get used to things taking a long time. If every person in a chain of five lowers the bar by 10%, you end up with a\nsignificant accumulated delay. But if each layer hunts down 10% of speed-up instead, you have a massive difference in\naccumulated advantage. Thatâ€™s the difference between mediocre and great companies. You will move slowly if you hire slow\npeople and let them make slow plans. Instead, put impatient and relentless people in charge and eliminate all the slow\npeople. I promise you that you will get results much faster. And talented people will be happier when things move\nforward quickly. My experience is that 90% of the work can be finished in 10% of the time if you are OK with 20% of\nthings going wrong instead of 10%. Thatâ€™s an acceptable failure rate to be faster than everyone else. The value of being\n10x faster far exceeds being right 10% more often. Most decisions can be changed anyway. As you know, I prefer being\nright over being consistent. So, I expect leaders to challenge timelines and hunt for speed whenever possible. You have\nto question the scope of projects to find just the right effort for our stage. Tuning the scope requires a deep\nunderstanding of the work being done and a fair amount of impatience. Delete as much as possible, and if you add about\n20% back in later, youâ€™ve probably found an decent deleting level.\u003C/p>\n\u003Cp>\u003Cstrong>How transparent can we be?\u003C/strong> I prefer to deal with things openly in a large group, over 1-1s, or closed groups.\nThe more information we can push into the open, the better. The fewer closed Slack channels, the better. You can all\nlearn to filter that which is relevant from the rest. Being exposed and tuning your filter is better than being out of\ntouch. Cross-functional teams with direct communication between ICs far exceed hierarchy in speed and efficiency.\nManagers are not there to monitor and approve things but to challenge, inspire, and support. Report your conclusions and\nbroadcast them as widely as possible. But do not slow down by going through intermediates. Rather than talk to someoneâ€™s\nmanager to figure something out, talk directly to the person you need to talk to. I expect leaders to share openly the\ngood, the bad, and the ugly.\u003C/p>\n\u003Cp>\u003Cstrong>There are some limits to transparency.\u003C/strong> We do not publicly criticize a personâ€™s performance. We do not share all\nthe details when someone is terminated. We cannot talk about sensitive aspects of negotiations with customers or\ninvestors. We cannot share if/when someone offers to buy the company. There are limits. But we set a high bar for what\nshould be shared. We always share if we have problems in a process or if some deal is going south. We openly share our\ncall reports, meeting reports, financials, etc. Iâ€™d much rather send a few emails too many than too few.\u003C/p>\n\u003Ch3 id=\"leaders-create-accelerating-flywheels\">Leaders Create Accelerating Flywheels\u003C/h3>\n\u003Cp>\u003Cstrong>Leaders create accelerating flywheels.\u003C/strong> The most successful leaders create â€œflywheel teams.â€ Teams that\naccelerate more and more and eventually spin really, really fast with minimum external force applied. That requires\nremoving friction, setting a clear focus, and ensuring everyone on the team is excellent. When I read, e.g., the\nbiography about Musk, he appears not to scale. At all. I think thatâ€™s his greatest weakness. Teams appear highly\ndependent on his intervention. While he gets the urgency right and can attract incredibly talented people, he constantly\ninvolves himself to such a degree that the future of his companies is uncertain without him. I suspect he craves being\nat the center of attention more than is in the interest of his companies. But I guess you must take the good and the bad\nwith some people.\u003C/p>\n\u003Cp>\u003Cstrong>Leadership is telling an engaging story.\u003C/strong> A big part of leadership is being a great storyteller. We are all part\nof a narrative. Kognic is a story about a team trying to develop safe and reliable embodied AI. We believe that AI is\nthe â€œhighest order bit.â€ It is the most important thing we can work on during our lifetime. If we get AI Alignment\nright, everything else will follow. Every decision we take, every customer we sign, or every product feature we build\nneeds to move us toward our vision of accelerating alignment. To reach our goal, we must dance with armed elephants,\nfight Kafka-esque complexity, and overcome many other challenges. Itâ€™s an adventure. Leaders at Kognic are expected to\nbe able to connect their work and the work of their team to our vision. To weave their thread into the story. What is\nyour team doing to accelerate alignment? There are many ways to help: contributing to a lean data factory, helping hire\nfantastic talent, ensuring we get paid for our work, signing great contracts with customers, etc. We must be useful and\nvaluable to customers \u003Cem>now\u003C/em> to gain the trust and resources needed to change the world. Every day, we become bigger and\nmore capable, and everyone on the team is part of making that happen.\u003C/p>\n\u003Cp>Kognic is not looking to be like \u003Cem>most\u003C/em> companies. \u003Cstrong>We are the best company in the world at accelerating autonomy\u003C/strong>.\nOutstanding leadership at all company levels is required for us to succeed. While demanding, the reward is that we get\nto enjoy \u003Cstrong>a hell of a ride\u003C/strong> with ambitious and smart people.\u003C/p>",{"headings":180,"localImagePaths":199,"remoteImagePaths":200,"frontmatter":201,"imagePaths":202},[181,184,187,190,193,196],{"depth":24,"slug":182,"text":183},"foundations-of-a-great-team","Foundations of a Great Team",{"depth":24,"slug":185,"text":186},"the-principal-agent-problem","The Principal-Agent Problem",{"depth":24,"slug":188,"text":189},"motivation-culture-and-high-expectations","Motivation, Culture, and High Expectations",{"depth":24,"slug":191,"text":192},"balancing-high-performance-with-psychological-safety","Balancing High Performance with Psychological Safety",{"depth":24,"slug":194,"text":195},"trust-empowerment-and-accountability","Trust, Empowerment, and Accountability",{"depth":24,"slug":197,"text":198},"leaders-create-accelerating-flywheels","Leaders Create Accelerating Flywheels",[],[],{"pubDate":173,"title":172},[],"building-a-world-class-team.md","commercial-ikigai",{"id":204,"data":206,"body":209,"filePath":210,"digest":211,"rendered":212,"legacyId":229},{"title":207,"pubDate":208},"Commercial Ikigai","2020-06-20","Ikigai consists of the words â€˜ikiâ€™ (to live) and â€˜gaiâ€™ (reason) and refers to the importance of having a purpose in\nlife. Yes, writing about Japanese philosophy probably comes off as pretentious, but Iâ€™ve read so much about this concept\nrecently that I feel I have to share. It started when I saw the amazing\nmovie [\"Jiro Dreams of Sushi\"](https://en.wikipedia.org/wiki/Jiro_Dreams_of_Sushi). I got completely fascinated by the\nold mans relentless pursuit for perfection, and reading about him I realized how deeply rooted his way of life is in\nJapanese culture.\n\nI think finding your purpose is as necessary for companies as it is for people. The world is a maelstrom of\nopportunities and competition, and forces pull us in all directions at every moment. Finding purpose, and building a\nculture of joy around that, is necessary to thrive. So what does it take to find purpose?\n\n### Three Pillars of Commercial Ikigai\n\n**Focused commitment.** I am a devout believer in focus. I think a lot of the anxiety people and companies suffer from\ntoday stems from an inability to focus and commit to a cause. I think itâ€™s also an important reason once-successful\ncompanies deteriorate and die. We see a world of endless opportunities and waste effort every day considering all the\nthings we could do, instead of focusing on doing _something_. Or we try and do too much, loose quality in what we do,\nand are killed by more focused competitors. Creating a successful life, and company, requires being obsessed with a very\nspecific problem for many, many years. Access to information is both a blessing and a curse. We know about all options,\nwhich can be overwhelming. I recommend\nreading â€œ[The Paradox of Choice](https://www.ted.com/talks/barry_schwartz_the_paradox_of_choice?language=en)â€ by Barry\nSchwartz on this topic. While freedom and autonomy are critical to our well-being, limiting our options and imposing a\nsort of â€œvoluntary simplicityâ€ can reduce anxiety.\n\n**Craftsmanship and a state of flow.** One of the most powerful things with focus is the flow that it enables. When a\ncompany, team, or person can focus on something that they enjoy, that is needed, and that they can get paid for, they\nare radically more productive, not to mention happier. A company that tries to do too many things will fail in a world\nwhere there is no second place. They will waste time constantly switching from one thing to another. Only the best\nproduct survives global competition, and that takes focused craftsmanship.\n\n**Excellence in everything.** Focused teams that strive for excellence in everything they do accumulate enormous\nmomentum over time. As a company, you have to be willing to spend on excellence. You need to invest in the most talented\nindividuals, the best tools, the best environment, the best training, and the highest engineering velocity. The moment\nyou start compromising, more focused competitors will crush you. Not to mention that mastering a craft can be very\nsatisfying.\n\n### Why is Focus Hard?\n\nMost engineers I know would love to work according to these three principles. So why arenâ€™t more companies organized\nthis way if itâ€™s so great? I see three main forces that tug at the attention of product teams:\n\n**Market size.** The risk with focus is that you limit the financial potential of what you, or your company, is doing. A\nparticular product will only warrant investment proportional to the potential value of its market. Some products have\nhuge markets and merit massive investments. Others have smaller markets and lead to smaller companies and investments.\nItâ€™s similar to personal skills. Getting a PhD narrows your â€œskill market sizeâ€ but allows for deeper focus. Itâ€™s\ntempting to search for ways to increase the potential market for a product you are working on, but this only makes sense\nif you can maintain quality - or you might end up losing the foothold you already have. On the other hand, a competitor\nwith a significantly larger scope might be able to outspend you so much that they win anyway. Herein lies the hardest\npart of building a successful business; it has to be large enough to be strong but focused enough to be the best, and\nall of this while moving extremely fast. Most companies will be tempted to grow a bit more at the expense of quality.\n\n**Timing and network effects.** Speed is critical in todayâ€™s market. A great product might be launched too early, and\nfail because there isnâ€™t enough need for it. Or too late when everyone has already found a different solution. Switching\ncosts create significant hurdles, even if the alternative is much better than what you have. Timing is closely related\nto network effects. It doesnâ€™t matter if you are building a great social network today unless you can somehow get\neveryone onto that platform. Machine learning has similar traits, where the one with the most data can outcompete\neveryone else by better automation. That means attention to detail and quality might not be something companies can\nafford without missing their chance at a market.\n\n**Disruption and experimentation.** Another concern I hear about focus is that you might get blinded-sided by unexpected\nshifts in society or technology. Personally I think this is a misconception. True craftsmanship includes constantly\nsearching for better ways to solve the problem you are focused on, and constantly reading about the latest development\nin your domain. While you have to commit to certain solutions for enough time to transform them into high-quality\nproducts, you should always experiment with the next generation of products. And be ready to let go of outdated\nsolutions quickly.\n\n### Conclusion\n\nSearch for a problem that is valuable enough to solve to warrant a lot of work, and focus on that for many years. Learn\nto enjoy that problem and use it to hone your skills. Iâ€™ve found that this brings me a sense of calm and happiness. And\nas far as I can tell it makes a good basis for a company too.","src/content/blog/commercial-ikigai.md","18ac5c7fe4fb5d87",{"html":213,"metadata":214},"\u003Cp>Ikigai consists of the words â€˜ikiâ€™ (to live) and â€˜gaiâ€™ (reason) and refers to the importance of having a purpose in\nlife. Yes, writing about Japanese philosophy probably comes off as pretentious, but Iâ€™ve read so much about this concept\nrecently that I feel I have to share. It started when I saw the amazing\nmovie \u003Ca href=\"https://en.wikipedia.org/wiki/Jiro_Dreams_of_Sushi\">â€œJiro Dreams of Sushiâ€\u003C/a>. I got completely fascinated by the\nold mans relentless pursuit for perfection, and reading about him I realized how deeply rooted his way of life is in\nJapanese culture.\u003C/p>\n\u003Cp>I think finding your purpose is as necessary for companies as it is for people. The world is a maelstrom of\nopportunities and competition, and forces pull us in all directions at every moment. Finding purpose, and building a\nculture of joy around that, is necessary to thrive. So what does it take to find purpose?\u003C/p>\n\u003Ch3 id=\"three-pillars-of-commercial-ikigai\">Three Pillars of Commercial Ikigai\u003C/h3>\n\u003Cp>\u003Cstrong>Focused commitment.\u003C/strong> I am a devout believer in focus. I think a lot of the anxiety people and companies suffer from\ntoday stems from an inability to focus and commit to a cause. I think itâ€™s also an important reason once-successful\ncompanies deteriorate and die. We see a world of endless opportunities and waste effort every day considering all the\nthings we could do, instead of focusing on doing \u003Cem>something\u003C/em>. Or we try and do too much, loose quality in what we do,\nand are killed by more focused competitors. Creating a successful life, and company, requires being obsessed with a very\nspecific problem for many, many years. Access to information is both a blessing and a curse. We know about all options,\nwhich can be overwhelming. I recommend\nreading â€œ\u003Ca href=\"https://www.ted.com/talks/barry_schwartz_the_paradox_of_choice?language=en\">The Paradox of Choice\u003C/a>â€ by Barry\nSchwartz on this topic. While freedom and autonomy are critical to our well-being, limiting our options and imposing a\nsort of â€œvoluntary simplicityâ€ can reduce anxiety.\u003C/p>\n\u003Cp>\u003Cstrong>Craftsmanship and a state of flow.\u003C/strong> One of the most powerful things with focus is the flow that it enables. When a\ncompany, team, or person can focus on something that they enjoy, that is needed, and that they can get paid for, they\nare radically more productive, not to mention happier. A company that tries to do too many things will fail in a world\nwhere there is no second place. They will waste time constantly switching from one thing to another. Only the best\nproduct survives global competition, and that takes focused craftsmanship.\u003C/p>\n\u003Cp>\u003Cstrong>Excellence in everything.\u003C/strong> Focused teams that strive for excellence in everything they do accumulate enormous\nmomentum over time. As a company, you have to be willing to spend on excellence. You need to invest in the most talented\nindividuals, the best tools, the best environment, the best training, and the highest engineering velocity. The moment\nyou start compromising, more focused competitors will crush you. Not to mention that mastering a craft can be very\nsatisfying.\u003C/p>\n\u003Ch3 id=\"why-is-focus-hard\">Why is Focus Hard?\u003C/h3>\n\u003Cp>Most engineers I know would love to work according to these three principles. So why arenâ€™t more companies organized\nthis way if itâ€™s so great? I see three main forces that tug at the attention of product teams:\u003C/p>\n\u003Cp>\u003Cstrong>Market size.\u003C/strong> The risk with focus is that you limit the financial potential of what you, or your company, is doing. A\nparticular product will only warrant investment proportional to the potential value of its market. Some products have\nhuge markets and merit massive investments. Others have smaller markets and lead to smaller companies and investments.\nItâ€™s similar to personal skills. Getting a PhD narrows your â€œskill market sizeâ€ but allows for deeper focus. Itâ€™s\ntempting to search for ways to increase the potential market for a product you are working on, but this only makes sense\nif you can maintain quality - or you might end up losing the foothold you already have. On the other hand, a competitor\nwith a significantly larger scope might be able to outspend you so much that they win anyway. Herein lies the hardest\npart of building a successful business; it has to be large enough to be strong but focused enough to be the best, and\nall of this while moving extremely fast. Most companies will be tempted to grow a bit more at the expense of quality.\u003C/p>\n\u003Cp>\u003Cstrong>Timing and network effects.\u003C/strong> Speed is critical in todayâ€™s market. A great product might be launched too early, and\nfail because there isnâ€™t enough need for it. Or too late when everyone has already found a different solution. Switching\ncosts create significant hurdles, even if the alternative is much better than what you have. Timing is closely related\nto network effects. It doesnâ€™t matter if you are building a great social network today unless you can somehow get\neveryone onto that platform. Machine learning has similar traits, where the one with the most data can outcompete\neveryone else by better automation. That means attention to detail and quality might not be something companies can\nafford without missing their chance at a market.\u003C/p>\n\u003Cp>\u003Cstrong>Disruption and experimentation.\u003C/strong> Another concern I hear about focus is that you might get blinded-sided by unexpected\nshifts in society or technology. Personally I think this is a misconception. True craftsmanship includes constantly\nsearching for better ways to solve the problem you are focused on, and constantly reading about the latest development\nin your domain. While you have to commit to certain solutions for enough time to transform them into high-quality\nproducts, you should always experiment with the next generation of products. And be ready to let go of outdated\nsolutions quickly.\u003C/p>\n\u003Ch3 id=\"conclusion\">Conclusion\u003C/h3>\n\u003Cp>Search for a problem that is valuable enough to solve to warrant a lot of work, and focus on that for many years. Learn\nto enjoy that problem and use it to hone your skills. Iâ€™ve found that this brings me a sense of calm and happiness. And\nas far as I can tell it makes a good basis for a company too.\u003C/p>",{"headings":215,"localImagePaths":225,"remoteImagePaths":226,"frontmatter":227,"imagePaths":228},[216,219,222],{"depth":24,"slug":217,"text":218},"three-pillars-of-commercial-ikigai","Three Pillars of Commercial Ikigai",{"depth":24,"slug":220,"text":221},"why-is-focus-hard","Why is Focus Hard?",{"depth":24,"slug":223,"text":224},"conclusion","Conclusion",[],[],{"pubDate":208,"title":207},[],"commercial-ikigai.md","building-extremely-valuable-companies",{"id":230,"data":232,"body":235,"filePath":236,"digest":237,"rendered":238,"legacyId":258},{"title":233,"pubDate":234},"Building Extremely Valuable Companies","2023-01-09","I write a lot about building companies. At one\npoint [in the past](https://langkilde.se/post/2021-10-25-risk-and-reward-in-technology), I wrote: \"If you care about\nraising a huge round from a top-tier VC, then you need to make very deliberate choices.\" I want to dig deeper into what\nIâ€™ve learned about what such deliberate choices might look like. My usual caveat is that my thoughts are only about\nbuilding extremely valuable companies. There are many other ways to build smaller and less risky companies.\n\n## Risk-Adjusted Returns\n\nI'll start with something that might feel weird to a startup person, but I think you should learn about the concept of\nrisk-adjusted returns. Risk-adjusted return is the return on investment compared to cash.\n\nThe more I learn about building a company, the more I come to terms with the fact that all companies eventually become\nassets in someoneâ€™s portfolio. Your company may start as your baby, but it will sooner or later become a vehicle for\nfinancial returns. While _you_ , as a founder, care more about the mission, later-stage investors will primarily look at\nthe risk-reward profile. When a company is put on the public market, unless you are a meme stock with tremendous retail\ninvestor support, large financial institutes will determine your value based on your risk-adjusted returns. Analysts\nwill dissect every piece of you and determine an appropriate risk-adjusted valuation.\n\nThe Sharpe Ratio is one of the most commonly cited measures of risk-adjusted returns, and it is defined as:\n\n**Sharpe Ratio = (Return - Risk-Free Rate) / Variance of Return**\n\nThe higher the Sharpe Ratio, the more attractive the investment is from a risk-adjusted perspective. Let's say you can\nreturn five on an investment, the risk-free return is one, and the standard deviation is one. Then you will get between\n3-6 in return in 68% of the cases. In 2% of cases, you will get between 0-3, and in 15% of cases, you will get between\n0-4. If we changed the standard deviation to 0.3, i.e., cut the risk to one-third, you would get above 4 in returns in\n99.95% of cases.\n\n## Venture Capital\n\nIn recent months Iâ€™ve kept returning to this report from Morgan\nStanley, â€œ[Public to Private Equity in the United States: A Long-Term Look](https://www.morganstanley.com/im/publication/insights/articles/articles_publictoprivateequityintheusalongtermlook_us.pdf).â€\nIn it, we find several interesting exhibits:\n\n![](https://storage.googleapis.com/langkilde-se-images/aed8f097-6b85-4609-ba98-2bb1f91cbb7d.jpeg)\n\n![](https://storage.googleapis.com/langkilde-se-images/12030485-06d3-490d-a101-23ef93ce5997.jpeg)\n\n![](https://storage.googleapis.com/langkilde-se-images/ae214644-e82f-43e2-82d4-7540f962ccba.jpeg)\n\n![](https://storage.googleapis.com/langkilde-se-images/e1d35c01-98a6-48c3-b335-b8185c0ebf2c.jpeg)\n\n![](https://storage.googleapis.com/langkilde-se-images/8f9690c6-a354-4d0b-a42d-4fd3ab414bce.jpeg)\n\n* **Venture Capital is a power-law asset class.** VCs depend on homeruns. You want to go to bat to hit it out of the\n  park every time: high risk, high reward. Most venture investments yield \u003C1x returns, i.e., less than what you put in.\n  It is exceedingly rare to get returns above 4-5x. The line can barely be seen in the graph beyond that point.\n  Interestingly there is a hump around 1, probably due to downside protection (\n  e.g., â€œ[liquidation preferences](https://www.investopedia.com/terms/l/liquidation-preference.asp)â€).\n\n* **Top-performing VCs and bottom-performing VCs are very, very far apart.** Variance is enormous among VCs, and many\n  venture capital funds provide significant negative returns. Morgan Stanley: â€œIdentifying which funds are in the top\n  quartile can be tricky [â€¦] more than one-quarter of all funds claim to be in the top quartile.â€œ Median returns to\n  investors have actually been pretty bad since 2000, but top funds have provided excellent returns.\n\n* **VC returns are persistent, probably due to preferential access.** This is maybe the most interesting point of all\n  about VCs: A top quartile fund had nearly a fifty percent likelihood of being followed by another top quartile fund.\n  Some scholars attribute the persistence of VC returns to â€œpreferential accessâ€ to subsequent attractive investments as\n  the result of better-than-average results with initial investments. It could also be their ability to mentor founders\n  and influence operations, but less scientific evidence supports such a claim.\n\n* **Most VC investments lead to M &A. **It used to be that VC bets IPOed. Thatâ€™s no longer the case. Since about the\n  year 2000, a lot fewer investments have IPOed. If you connect this with observation around persistent returns, you get\n  a clueâ€”providing high returns when investing is as much about steering companies onto the highway as having paved\n  offramps when the time is right. Being able to offload good, but not IPO-great, portfolio companies to friends you\n  have previously invested in is an excellent way to improve your returns. It would be best if you still had your home\n  runs and IPOs, but this mechanism likely significantly improves your numbers.\n\n## Observations from Founding a Company\n\nI will try to merge earlier exhibits and conclusions with my own observations from early-stage company building. My most\nrecent update of â€œmain challenges when building a companyâ€ includes the following:\n\n* **You have to****create****a market for your product.** Most people start with the question: â€œHow large **_is_** the\n  market for this product?â€. Thatâ€™s the wrong question for a venture bet. You are getting into a red ocean if there is\n  already a market. You should ask: â€œHow large of a market **_will we create_** with our product?â€ and â€œWhat trends in\n  society will help grow that market in the next ten years?â€. Of course, you do not know the future, so this is when you\n  need imagination. Dream.\n\n* **You have to create a narrative that makes your company the preferred choice for both customers and employees.** The world [runs on stories](https://langkilde.se/post/2023-01-04-reflections-on-life-and-entrepreneurship). Most\n  people make decisions based on consensus. Humans generally need to be part of a shared narrative. It is possible to\n  shape societal narratives. Great companies make something go from strange to obvious. It is too late to create\n  outsized returns if the market is already apparent. Telling a great story is necessary to do that. Do not fool\n  yourself into thinking that product performance and facts alone will sway the market. Eventually, great products win.\n  But early on, a great story is required to get started. You cannot build the best product without money, and raising\n  money requires faith. And faith requires a story. While individual consumers may be rational, markets tend toward\n  consensus, and the consensus is frequently irrational. Enterprises can be more rational than consumers, but even they\n  tend to buy â€œthe established thing.â€ Or from â€œthe most prominent company.â€ Or â€œthe cheapest option.â€ It is rare for\n  large enterprises to make high-risk vendor bets - especially not if your solution is expensive. They only do it if an\n  excellent story inspires them to believe in the prospect of significant returns, which you then deliver on through\n  excellent product performance.\n\n* **It is hard to maintain momentum when experimenting a lot.** Experimentation means killing a lot of darlings. You\n  will get in trouble if you get too attached to things in the early days. At the same time, humans have a natural\n  tendency to develop feelings for things they create. They defend them. They want to make them great. If you insist on\n  writing rock-solid code before you have product-sales fit, you will move too slowly and waste too much money. Kill\n  your darlings and stay fast, then switch to scaling it up.\n\n* **The most valuable companies relentlessly iterate short-term to find products that are highly profitable at a large\n  scale.** The biggest value of venture money is that it allows you to experiment without profit to search for something\n  with excellent large-scale unit economics. It is not about the amount of money you can invoice in the beginning; it is\n  about the effort by which you expect to deliver that value long-term. You can start with a manual process, but it will\n  only be valuable if there is a good chance of removing the manual steps. Case studies for this could be; Uber and\n  Spotify. Both have high direct costs (drivers and record labels). Compared to Apple, both companies can extract a\n  lower unit price and, consequently, get worse margins. All three companies are way more valuable than a consulting\n  company. Consulting companies cannot get valuable, but they have low risk. Great for people who lack courage.\n\n* **Once you get traction, you have to become big, really fast.** Knowing when to hit the accelerator and hyper-grow\n  your business is very hard. If you are too early, you might spend too many resources on something that isnâ€™t strong\n  enough. If you wait too long, someone else will crush you by becoming huge. Iâ€™ve come to believe that size is the\n  ultimate defense, but the difficulty of timing the race to become big is another reason why startups are so risky. The\n  barrier to competing with you will inevitably be much more significant if your company is enormous. If you buy\n  everything that comes into your orbit, you will stay a scarce resource longer. You can hire for things that help you\n  conserve your energy. You can research new products if you have a lot of cash flow for R&D. The list of benefits goes\n  on.\n\n## Conclusions as a Founder\n\n* **A founder's job is to be visionary, take risks, and then execute to minimize the variance of the outcome.** Startups\n  are the mutations in our commercial genome. Like â€œavant garde artâ€ is for culture. It seems crazy and feels unfamiliar\n  to most people observing it. Because it is. Most radical ideas fail to get traction. That is the nature of\n  experimentation. But some of it will find fertile soil and prosper. Founders are people who are OK with experimenting,\n  can live with repeated failure, and still maintain a high-risk appetite. They are persistent optimists despite\n  overwhelmingly pessimistic odds. But - it would be best if you also were an excellent operator. Too much\n  experimentation and you will fail due to lack of discipline. The rarest of all are people who are both crazy\n  experimenters and commercially rational executives. Dream big, but make sure to have your books in order. Take risks,\n  but be honest about them when estimating potential returns. Know what sort of asset you are, and be clear about it.\n\n* **Be optimistic and evolve through failure.** Come up with ideas, get people excited, and put them to the test. Learn\n  and evolve. If it works, great. If it fails, try again. Most people cannot take the amount of failure you experience\n  when you are bold enough to suggest novel things. They loose hope. Or they cannot get people excited. Or they see too\n  many obstacles. It is a rare trait to be persistently optimistic through failure and hardship.\n\n* **Feed noise into your decision-making process.** While I believe in data-driven decision-making, you must feed it\n  with the right amount of noise. If all your decisions are based on rigorous analysis of facts, you will likely get\n  stuck in the land of commodities. You must throw caution to the wind and let go of established truths. Most people do\n  not know what they need until they see it. You cannot just ask your way to a unique solution. You can refine a concept\n  through feedback, but you cannot expect your customer to innovate for you. The best way to find new things is to keep\n  proposing them and quickly iterate based on customer feedback. While risky, these new ideas and suggestions are\n  necessary to sustain scarcity.\n\n* **Be honest about risks, and make sure your returns are proportional to your risk.** If you want to take a massive\n  risk, make sure it is possible to get massive returns. This is why venture funds only bet on things with an unlimited\n  upside. Risk-adjusted returns will not favor large bets unless the returns are potentially huge. As trends go from\n  speculation to established wisdom, the risk goes down but so do the returns. I'm not saying you need to calculate the\n  Sharpe Ratio for your company, but I think you need to understand that there is no such thing as risk-free investing.\n\n* **Be both optimistic and pessimistic. Trust but verify.** There is a strong tension between paranoia and skepticism on\n  the one hand, and trust and creativity on the other hand. Most people tend to one or the other. Either they are mostly\n  skeptical or they are mostly optimistic. The best operators manage to be both optimistic and pessimistic. You have to\n  be optimistic about the future, and about your vision. You also have to have the courage to trust people along the\n  way. But at the same time, you have to be paranoid in execution. Always on the look out for problems ahead. Always\n  make sure to demand excellence from your team. Creating things and testing them without letting your own analytical\n  thinking shoot you down too quickly can be trained. Observe your thoughts and switch modes in a deliberate way. Create\n  freely for a while, then take a step back and shoot it down. Put faith in people and hire young talent, then take a\n  step back and review performance and provide feedback.\n\n* **Larger companies are probably less innovative because their owners want predictable, risk-adjusted returns.** Most\n  people blame stagnant culture, poor management, or other factors when dismissing large companiesâ€™ ability to innovate.\n  While that may be the case, Iâ€™m confident most problems start with the owners. What risk-adjusted returns are they\n  expecting? How much are owners comfortable investing in R&D to sustain scarcity? If owners phlebotomize companies,\n  they will see much less innovation.","src/content/blog/building-extremely-valuable-companies.md","acbfb33f4486ba1a",{"html":239,"metadata":240},"\u003Cp>I write a lot about building companies. At one\npoint \u003Ca href=\"https://langkilde.se/post/2021-10-25-risk-and-reward-in-technology\">in the past\u003C/a>, I wrote: â€œIf you care about\nraising a huge round from a top-tier VC, then you need to make very deliberate choices.â€ I want to dig deeper into what\nIâ€™ve learned about what such deliberate choices might look like. My usual caveat is that my thoughts are only about\nbuilding extremely valuable companies. There are many other ways to build smaller and less risky companies.\u003C/p>\n\u003Ch2 id=\"risk-adjusted-returns\">Risk-Adjusted Returns\u003C/h2>\n\u003Cp>Iâ€™ll start with something that might feel weird to a startup person, but I think you should learn about the concept of\nrisk-adjusted returns. Risk-adjusted return is the return on investment compared to cash.\u003C/p>\n\u003Cp>The more I learn about building a company, the more I come to terms with the fact that all companies eventually become\nassets in someoneâ€™s portfolio. Your company may start as your baby, but it will sooner or later become a vehicle for\nfinancial returns. While \u003Cem>you\u003C/em> , as a founder, care more about the mission, later-stage investors will primarily look at\nthe risk-reward profile. When a company is put on the public market, unless you are a meme stock with tremendous retail\ninvestor support, large financial institutes will determine your value based on your risk-adjusted returns. Analysts\nwill dissect every piece of you and determine an appropriate risk-adjusted valuation.\u003C/p>\n\u003Cp>The Sharpe Ratio is one of the most commonly cited measures of risk-adjusted returns, and it is defined as:\u003C/p>\n\u003Cp>\u003Cstrong>Sharpe Ratio = (Return - Risk-Free Rate) / Variance of Return\u003C/strong>\u003C/p>\n\u003Cp>The higher the Sharpe Ratio, the more attractive the investment is from a risk-adjusted perspective. Letâ€™s say you can\nreturn five on an investment, the risk-free return is one, and the standard deviation is one. Then you will get between\n3-6 in return in 68% of the cases. In 2% of cases, you will get between 0-3, and in 15% of cases, you will get between\n0-4. If we changed the standard deviation to 0.3, i.e., cut the risk to one-third, you would get above 4 in returns in\n99.95% of cases.\u003C/p>\n\u003Ch2 id=\"venture-capital\">Venture Capital\u003C/h2>\n\u003Cp>In recent months Iâ€™ve kept returning to this report from Morgan\nStanley, â€œ\u003Ca href=\"https://www.morganstanley.com/im/publication/insights/articles/articles_publictoprivateequityintheusalongtermlook_us.pdf\">Public to Private Equity in the United States: A Long-Term Look\u003C/a>.â€\nIn it, we find several interesting exhibits:\u003C/p>\n\u003Cp>\u003Cimg src=\"https://storage.googleapis.com/langkilde-se-images/aed8f097-6b85-4609-ba98-2bb1f91cbb7d.jpeg\" alt=\"\">\u003C/p>\n\u003Cp>\u003Cimg src=\"https://storage.googleapis.com/langkilde-se-images/12030485-06d3-490d-a101-23ef93ce5997.jpeg\" alt=\"\">\u003C/p>\n\u003Cp>\u003Cimg src=\"https://storage.googleapis.com/langkilde-se-images/ae214644-e82f-43e2-82d4-7540f962ccba.jpeg\" alt=\"\">\u003C/p>\n\u003Cp>\u003Cimg src=\"https://storage.googleapis.com/langkilde-se-images/e1d35c01-98a6-48c3-b335-b8185c0ebf2c.jpeg\" alt=\"\">\u003C/p>\n\u003Cp>\u003Cimg src=\"https://storage.googleapis.com/langkilde-se-images/8f9690c6-a354-4d0b-a42d-4fd3ab414bce.jpeg\" alt=\"\">\u003C/p>\n\u003Cul>\n\u003Cli>\n\u003Cp>\u003Cstrong>Venture Capital is a power-law asset class.\u003C/strong> VCs depend on homeruns. You want to go to bat to hit it out of the\npark every time: high risk, high reward. Most venture investments yield &#x3C;1x returns, i.e., less than what you put in.\nIt is exceedingly rare to get returns above 4-5x. The line can barely be seen in the graph beyond that point.\nInterestingly there is a hump around 1, probably due to downside protection (\ne.g., â€œ\u003Ca href=\"https://www.investopedia.com/terms/l/liquidation-preference.asp\">liquidation preferences\u003C/a>â€).\u003C/p>\n\u003C/li>\n\u003Cli>\n\u003Cp>\u003Cstrong>Top-performing VCs and bottom-performing VCs are very, very far apart.\u003C/strong> Variance is enormous among VCs, and many\nventure capital funds provide significant negative returns. Morgan Stanley: â€œIdentifying which funds are in the top\nquartile can be tricky [â€¦] more than one-quarter of all funds claim to be in the top quartile.â€œ Median returns to\ninvestors have actually been pretty bad since 2000, but top funds have provided excellent returns.\u003C/p>\n\u003C/li>\n\u003Cli>\n\u003Cp>\u003Cstrong>VC returns are persistent, probably due to preferential access.\u003C/strong> This is maybe the most interesting point of all\nabout VCs: A top quartile fund had nearly a fifty percent likelihood of being followed by another top quartile fund.\nSome scholars attribute the persistence of VC returns to â€œpreferential accessâ€ to subsequent attractive investments as\nthe result of better-than-average results with initial investments. It could also be their ability to mentor founders\nand influence operations, but less scientific evidence supports such a claim.\u003C/p>\n\u003C/li>\n\u003Cli>\n\u003Cp>**Most VC investments lead to M &#x26;A. **It used to be that VC bets IPOed. Thatâ€™s no longer the case. Since about the\nyear 2000, a lot fewer investments have IPOed. If you connect this with observation around persistent returns, you get\na clueâ€”providing high returns when investing is as much about steering companies onto the highway as having paved\nofframps when the time is right. Being able to offload good, but not IPO-great, portfolio companies to friends you\nhave previously invested in is an excellent way to improve your returns. It would be best if you still had your home\nruns and IPOs, but this mechanism likely significantly improves your numbers.\u003C/p>\n\u003C/li>\n\u003C/ul>\n\u003Ch2 id=\"observations-from-founding-a-company\">Observations from Founding a Company\u003C/h2>\n\u003Cp>I will try to merge earlier exhibits and conclusions with my own observations from early-stage company building. My most\nrecent update of â€œmain challenges when building a companyâ€ includes the following:\u003C/p>\n\u003Cul>\n\u003Cli>\n\u003Cp>\u003Cstrong>You have to\u003Cstrong>\u003Cstrong>create\u003C/strong>\u003C/strong>a market for your product.\u003C/strong> Most people start with the question: â€œHow large \u003Cstrong>\u003Cem>is\u003C/em>\u003C/strong> the\nmarket for this product?â€. Thatâ€™s the wrong question for a venture bet. You are getting into a red ocean if there is\nalready a market. You should ask: â€œHow large of a market \u003Cstrong>\u003Cem>will we create\u003C/em>\u003C/strong> with our product?â€ and â€œWhat trends in\nsociety will help grow that market in the next ten years?â€. Of course, you do not know the future, so this is when you\nneed imagination. Dream.\u003C/p>\n\u003C/li>\n\u003Cli>\n\u003Cp>\u003Cstrong>You have to create a narrative that makes your company the preferred choice for both customers and employees.\u003C/strong> The world \u003Ca href=\"https://langkilde.se/post/2023-01-04-reflections-on-life-and-entrepreneurship\">runs on stories\u003C/a>. Most\npeople make decisions based on consensus. Humans generally need to be part of a shared narrative. It is possible to\nshape societal narratives. Great companies make something go from strange to obvious. It is too late to create\noutsized returns if the market is already apparent. Telling a great story is necessary to do that. Do not fool\nyourself into thinking that product performance and facts alone will sway the market. Eventually, great products win.\nBut early on, a great story is required to get started. You cannot build the best product without money, and raising\nmoney requires faith. And faith requires a story. While individual consumers may be rational, markets tend toward\nconsensus, and the consensus is frequently irrational. Enterprises can be more rational than consumers, but even they\ntend to buy â€œthe established thing.â€ Or from â€œthe most prominent company.â€ Or â€œthe cheapest option.â€ It is rare for\nlarge enterprises to make high-risk vendor bets - especially not if your solution is expensive. They only do it if an\nexcellent story inspires them to believe in the prospect of significant returns, which you then deliver on through\nexcellent product performance.\u003C/p>\n\u003C/li>\n\u003Cli>\n\u003Cp>\u003Cstrong>It is hard to maintain momentum when experimenting a lot.\u003C/strong> Experimentation means killing a lot of darlings. You\nwill get in trouble if you get too attached to things in the early days. At the same time, humans have a natural\ntendency to develop feelings for things they create. They defend them. They want to make them great. If you insist on\nwriting rock-solid code before you have product-sales fit, you will move too slowly and waste too much money. Kill\nyour darlings and stay fast, then switch to scaling it up.\u003C/p>\n\u003C/li>\n\u003Cli>\n\u003Cp>\u003Cstrong>The most valuable companies relentlessly iterate short-term to find products that are highly profitable at a large\nscale.\u003C/strong> The biggest value of venture money is that it allows you to experiment without profit to search for something\nwith excellent large-scale unit economics. It is not about the amount of money you can invoice in the beginning; it is\nabout the effort by which you expect to deliver that value long-term. You can start with a manual process, but it will\nonly be valuable if there is a good chance of removing the manual steps. Case studies for this could be; Uber and\nSpotify. Both have high direct costs (drivers and record labels). Compared to Apple, both companies can extract a\nlower unit price and, consequently, get worse margins. All three companies are way more valuable than a consulting\ncompany. Consulting companies cannot get valuable, but they have low risk. Great for people who lack courage.\u003C/p>\n\u003C/li>\n\u003Cli>\n\u003Cp>\u003Cstrong>Once you get traction, you have to become big, really fast.\u003C/strong> Knowing when to hit the accelerator and hyper-grow\nyour business is very hard. If you are too early, you might spend too many resources on something that isnâ€™t strong\nenough. If you wait too long, someone else will crush you by becoming huge. Iâ€™ve come to believe that size is the\nultimate defense, but the difficulty of timing the race to become big is another reason why startups are so risky. The\nbarrier to competing with you will inevitably be much more significant if your company is enormous. If you buy\neverything that comes into your orbit, you will stay a scarce resource longer. You can hire for things that help you\nconserve your energy. You can research new products if you have a lot of cash flow for R&#x26;D. The list of benefits goes\non.\u003C/p>\n\u003C/li>\n\u003C/ul>\n\u003Ch2 id=\"conclusions-as-a-founder\">Conclusions as a Founder\u003C/h2>\n\u003Cul>\n\u003Cli>\n\u003Cp>\u003Cstrong>A founderâ€™s job is to be visionary, take risks, and then execute to minimize the variance of the outcome.\u003C/strong> Startups\nare the mutations in our commercial genome. Like â€œavant garde artâ€ is for culture. It seems crazy and feels unfamiliar\nto most people observing it. Because it is. Most radical ideas fail to get traction. That is the nature of\nexperimentation. But some of it will find fertile soil and prosper. Founders are people who are OK with experimenting,\ncan live with repeated failure, and still maintain a high-risk appetite. They are persistent optimists despite\noverwhelmingly pessimistic odds. But - it would be best if you also were an excellent operator. Too much\nexperimentation and you will fail due to lack of discipline. The rarest of all are people who are both crazy\nexperimenters and commercially rational executives. Dream big, but make sure to have your books in order. Take risks,\nbut be honest about them when estimating potential returns. Know what sort of asset you are, and be clear about it.\u003C/p>\n\u003C/li>\n\u003Cli>\n\u003Cp>\u003Cstrong>Be optimistic and evolve through failure.\u003C/strong> Come up with ideas, get people excited, and put them to the test. Learn\nand evolve. If it works, great. If it fails, try again. Most people cannot take the amount of failure you experience\nwhen you are bold enough to suggest novel things. They loose hope. Or they cannot get people excited. Or they see too\nmany obstacles. It is a rare trait to be persistently optimistic through failure and hardship.\u003C/p>\n\u003C/li>\n\u003Cli>\n\u003Cp>\u003Cstrong>Feed noise into your decision-making process.\u003C/strong> While I believe in data-driven decision-making, you must feed it\nwith the right amount of noise. If all your decisions are based on rigorous analysis of facts, you will likely get\nstuck in the land of commodities. You must throw caution to the wind and let go of established truths. Most people do\nnot know what they need until they see it. You cannot just ask your way to a unique solution. You can refine a concept\nthrough feedback, but you cannot expect your customer to innovate for you. The best way to find new things is to keep\nproposing them and quickly iterate based on customer feedback. While risky, these new ideas and suggestions are\nnecessary to sustain scarcity.\u003C/p>\n\u003C/li>\n\u003Cli>\n\u003Cp>\u003Cstrong>Be honest about risks, and make sure your returns are proportional to your risk.\u003C/strong> If you want to take a massive\nrisk, make sure it is possible to get massive returns. This is why venture funds only bet on things with an unlimited\nupside. Risk-adjusted returns will not favor large bets unless the returns are potentially huge. As trends go from\nspeculation to established wisdom, the risk goes down but so do the returns. Iâ€™m not saying you need to calculate the\nSharpe Ratio for your company, but I think you need to understand that there is no such thing as risk-free investing.\u003C/p>\n\u003C/li>\n\u003Cli>\n\u003Cp>\u003Cstrong>Be both optimistic and pessimistic. Trust but verify.\u003C/strong> There is a strong tension between paranoia and skepticism on\nthe one hand, and trust and creativity on the other hand. Most people tend to one or the other. Either they are mostly\nskeptical or they are mostly optimistic. The best operators manage to be both optimistic and pessimistic. You have to\nbe optimistic about the future, and about your vision. You also have to have the courage to trust people along the\nway. But at the same time, you have to be paranoid in execution. Always on the look out for problems ahead. Always\nmake sure to demand excellence from your team. Creating things and testing them without letting your own analytical\nthinking shoot you down too quickly can be trained. Observe your thoughts and switch modes in a deliberate way. Create\nfreely for a while, then take a step back and shoot it down. Put faith in people and hire young talent, then take a\nstep back and review performance and provide feedback.\u003C/p>\n\u003C/li>\n\u003Cli>\n\u003Cp>\u003Cstrong>Larger companies are probably less innovative because their owners want predictable, risk-adjusted returns.\u003C/strong> Most\npeople blame stagnant culture, poor management, or other factors when dismissing large companiesâ€™ ability to innovate.\nWhile that may be the case, Iâ€™m confident most problems start with the owners. What risk-adjusted returns are they\nexpecting? How much are owners comfortable investing in R&#x26;D to sustain scarcity? If owners phlebotomize companies,\nthey will see much less innovation.\u003C/p>\n\u003C/li>\n\u003C/ul>",{"headings":241,"localImagePaths":254,"remoteImagePaths":255,"frontmatter":256,"imagePaths":257},[242,245,248,251],{"depth":61,"slug":243,"text":244},"risk-adjusted-returns","Risk-Adjusted Returns",{"depth":61,"slug":246,"text":247},"venture-capital","Venture Capital",{"depth":61,"slug":249,"text":250},"observations-from-founding-a-company","Observations from Founding a Company",{"depth":61,"slug":252,"text":253},"conclusions-as-a-founder","Conclusions as a Founder",[],[],{"pubDate":234,"title":233},[],"building-extremely-valuable-companies.md","complexity-intelligence-and-anti-fragility",{"id":259,"data":261,"body":264,"filePath":265,"digest":266,"rendered":267,"legacyId":287},{"title":262,"pubDate":263},"Complexity, Intelligence and Anti-Fragility","2024-06-13","Engineers and mathematicians (and CEOs) want to reduce the world to simple models. The pursuit of simplicity and\nelegance is a noble one. I love refactoring code to improve abstractions and remove repetition. I get the same warm and\nfuzzy feeling when simplifying a business process. The enemy of simplicity is complexity. I think understanding\nintelligence requires a deep understanding of the difference between complex and complicated.\n\n![](https://storage.googleapis.com/langkilde-se-images/3f46e427-a400-493e-ab63-d46f53446368.jpeg)\n\n### Complicated Systems\n\nComplicated systems include machines like airplanes, computer programs, and other engineered systems. These systems,\nwhile intricate and detailed, can be understood through analysis. Complicated systems typically have a finite number of\nstates with well understood state-transitions. That makes them predictable and deterministic. Engineers love that!\nLimited feedback loops, separation of concern, linear relationship between input and output. Complicated systems can be\nanalyzed and understood. That makes us feel we can trust them. Obviously, the simpler the system the easier it is to\ntrust, but complication does not generally prevent predictability.\n\nMost of our academic training as children is focused on learning to solve complicated problems. Problems that are\ndeterministic and linear. \"Read this book and then answer these questions\". Tasks do not generally have dependencies or\nunexpected feedback loops. This favours kids that have reliable storage (memory) and powerful compute (raw\nintelligence). Fortunately, school also includes a social dimension through which kids learn about complexity. A gang of\nteenagers learning to socialize exhibit all the markers of an interconnected, sensitive and non-linear system.\n\n### Complex Systems\n\nComplex systems have a number of characteristics that make them different from complicated systems:\n\n- **Sensitivity.** Small differences in initial conditions can lead to vastly different outcomes,\n  often referred to as the \"butterfly effect.\" Or my favorite: \"The approximate present does not predict the approximate\n  future.\"\n\n- **Non-linearity.** The behavior of the system is not proportional to the input. Small changes can lead to\n  disproportionately large effects, and vice versa.\n\n- **Emergence.** The system exhibits properties and behaviors that are not evident from the properties and behaviors of\n  individual components. These emergent properties arise from the interactions among the system's parts.\n\n- **Interconnectedness.** The components of the system are highly interconnected and interdependent. Changes in one part\n  of the system can propagate and influence other parts.\n\n- **Feedback Loops.** Both positive and negative feedback loops are present. Positive feedback amplifies changes and can\n  lead to exponential growth or decline, while negative feedback stabilizes the system.\n\n- **Diversity of Components.** The system consists of a variety of components with different properties and behaviors,\n  contributing to the overall complexity.\n\n- **Multiple Scales.** Complex systems operate at multiple scales, both in time and space. Behaviors and interactions at\n  one scale can influence those at another.\n\n- **Decentralized Control.** There is no single point of control or central authority governing the system. Control is\n  distributed across the components.\n\n- **Robustness and Fragility.** While complex systems can be robust and resilient to certain perturbations, they can\n  also be fragile and susceptible to collapse under certain conditions.\n\nThese are obviously terrible properties of a system if you like control and simplicity. Yet, anyone who has managed a\nteam or built a company or run a political campaign knows that society is complex, not complicated. Groups of humans\nform complex systems. To make matters worse, a group of humans is a complex system made up of complex systems. And each\nhuman body is a complex system with countless interconnected components, feedback loops and emerging abilities.\n\nPeople drastically underestimate how complex our bodies and brains are. I've recently taken up studying neuroanatomy and\nthe first thing you realize is that talking about the brain gives you the impression that we process information in a\nsingle place. We don't. There is the peripheral nervous system, the spinal cord, the thalamus, the hypothalamus, the\ncerebral cortex and many more components. Each of these systems are complex chemical and biological systems in and of\nthemselves. Together, they form a dizzyingly complex web of dependencies. There is\nlayer after layer of fragile interconnectedness. Humans are easily killed because of all these dependencies. Small\nerrors in our genetic programming can lead to catastrophic disabilities. On the other hand, when it works, it's\nmarvelous.\n\nComplex systems are usually not engineered. They are evolved through experimentation. Genetic mutation is the Original\nGangster (OG) of experimentation. Ultraviolet radiation\nis [the reason humans are intelligent](https://en.wikipedia.org/wiki/Pyrimidine_dimer) ðŸ˜‰. \"Errors\" are introduced but\nturn out to be a better solution than the previously dominating\nsolution. [Startups are the genetic mutations](https://langkilde.se/post/2022-07-30-extraordinary-success-requires-betting)\nof the complex system that is our free market. Founders like to think their skill is the main source of success but as\nwith all mutation there is\na [huge amount of randomness](https://langkilde.se/post/2024-03-27-untangling-luck-and-skill-in-business). Equilibrium\nemerges temporarily, but as subsystems change equilibrium moves. And complex systems can operate far from their\nequilibrium for a long time, making it hard to tell if the situation is stable or not.\n\nThe universe does not lend itself to prediction to such a degree that we can engineer highly complex systems. We\nover-estimate our ability to predict and engineer the future, and under-estimate the amount of randomness. The\nalternative is that we are not in control, which is uncomfortable to most humans. The computational cost of modelling\nenough details to predict the future likely exceeds our available energy.\n\n### Anti-Fragility\n\nI'm a big fan of Nassim Taleb and his concept of [anti-fragility](https://en.wikipedia.org/wiki/Antifragility). He\ndescribes Black Swan events, i.e. rare, unexpected events with massive consequences. Such events are possible because\ncomplex systems are non-linear. If a complex system is shocked by unexpected information it can lead to cascading\nfailures and huge impact. This is true for the human body, our financial markets and ecosystems.\n\nTaleb suggests we should design anti-fragile systems, i.e. systems that get stronger if shocked. Anti-fragility requires\nredundancy and optionality as strategies to navigate complex systems. Decision-makers should bear the consequences of\ntheir actions to align incentives and encourages more responsible and prudent behavior. Humans are anti-fragile in the\nsense that we have strong incentives to look out for ourselves, we have many redundant sources of food and we are\nadaptable to changes in our environment. You can throw humans into completely new environments with different\ntemperature, humidity and food sources, and a surprisingly large number will survive.\n\n### Intelligence\n\nHow is all of this connected to intelligence? Well, I think intelligence is a form of anti-fragility that has emerged\nthrough evolution as a defence against complexity. The human body, with its brain and nervous system, has increased its\nbiological market share since it is able to withstand shocks and get stronger from them. We have evolved the ability to\nzero-shot learn complicated things while simultaneously fitting observations and experiences into models for vast,\ncomplex systems. We are resilient, adaptive and fast-learning.\n\nOur current form of machine learning is better equipped to solve complicated problems. Problems that require storage and\ncompute. The last few hundred years have promoted humans with good storage and compute. But those days are over now. We\nhave invented tools that can amplify our storage and compute, or delegate it all together. What's left to humans now is\nhandling complexity. Solving linear, deterministic tasks that require an analytical approach is rapidly becoming a\ncommodity. This commoditization of storage and compute has been ongoing since the invention of the computer, and is\nexponentially accelerating. At one point, the ability to do arithmetics was highly sought after. Royal courts had\nscholars that memorized large amounts of text. Harvard\nhad [human computers](https://en.wikipedia.org/wiki/Harvard_Computers). Today we all have a calculator in our pocket. Or\nour watch. All analytical work is going in that direction. Crunching numbers, matching patterns, extrapolating trends -\nall of that is becoming a commodity. If your job is to make decisions based on data, you are about to be automated.\nFortunately, that is not at all a threat to humanity. We did not build a dominant position in our ecosystem on\nmemorization. We built our position on the ability to navigate complexity. Lean into that.\n\n**What is my point?** My point is that intelligence is not primarily about solving complicated problems. It's actually\nabout solving complex problems. Decision-making under uncertainty in unpredictable environment with a lot of\ndependencies. Humans remain the uncontested champions of handling such challenges.","src/content/blog/complexity-intelligence-and-anti-fragility.md","a7f077ed7b7ae54b",{"html":268,"metadata":269},"\u003Cp>Engineers and mathematicians (and CEOs) want to reduce the world to simple models. The pursuit of simplicity and\nelegance is a noble one. I love refactoring code to improve abstractions and remove repetition. I get the same warm and\nfuzzy feeling when simplifying a business process. The enemy of simplicity is complexity. I think understanding\nintelligence requires a deep understanding of the difference between complex and complicated.\u003C/p>\n\u003Cp>\u003Cimg src=\"https://storage.googleapis.com/langkilde-se-images/3f46e427-a400-493e-ab63-d46f53446368.jpeg\" alt=\"\">\u003C/p>\n\u003Ch3 id=\"complicated-systems\">Complicated Systems\u003C/h3>\n\u003Cp>Complicated systems include machines like airplanes, computer programs, and other engineered systems. These systems,\nwhile intricate and detailed, can be understood through analysis. Complicated systems typically have a finite number of\nstates with well understood state-transitions. That makes them predictable and deterministic. Engineers love that!\nLimited feedback loops, separation of concern, linear relationship between input and output. Complicated systems can be\nanalyzed and understood. That makes us feel we can trust them. Obviously, the simpler the system the easier it is to\ntrust, but complication does not generally prevent predictability.\u003C/p>\n\u003Cp>Most of our academic training as children is focused on learning to solve complicated problems. Problems that are\ndeterministic and linear. â€œRead this book and then answer these questionsâ€. Tasks do not generally have dependencies or\nunexpected feedback loops. This favours kids that have reliable storage (memory) and powerful compute (raw\nintelligence). Fortunately, school also includes a social dimension through which kids learn about complexity. A gang of\nteenagers learning to socialize exhibit all the markers of an interconnected, sensitive and non-linear system.\u003C/p>\n\u003Ch3 id=\"complex-systems\">Complex Systems\u003C/h3>\n\u003Cp>Complex systems have a number of characteristics that make them different from complicated systems:\u003C/p>\n\u003Cul>\n\u003Cli>\n\u003Cp>\u003Cstrong>Sensitivity.\u003C/strong> Small differences in initial conditions can lead to vastly different outcomes,\noften referred to as the â€œbutterfly effect.â€ Or my favorite: â€œThe approximate present does not predict the approximate\nfuture.â€\u003C/p>\n\u003C/li>\n\u003Cli>\n\u003Cp>\u003Cstrong>Non-linearity.\u003C/strong> The behavior of the system is not proportional to the input. Small changes can lead to\ndisproportionately large effects, and vice versa.\u003C/p>\n\u003C/li>\n\u003Cli>\n\u003Cp>\u003Cstrong>Emergence.\u003C/strong> The system exhibits properties and behaviors that are not evident from the properties and behaviors of\nindividual components. These emergent properties arise from the interactions among the systemâ€™s parts.\u003C/p>\n\u003C/li>\n\u003Cli>\n\u003Cp>\u003Cstrong>Interconnectedness.\u003C/strong> The components of the system are highly interconnected and interdependent. Changes in one part\nof the system can propagate and influence other parts.\u003C/p>\n\u003C/li>\n\u003Cli>\n\u003Cp>\u003Cstrong>Feedback Loops.\u003C/strong> Both positive and negative feedback loops are present. Positive feedback amplifies changes and can\nlead to exponential growth or decline, while negative feedback stabilizes the system.\u003C/p>\n\u003C/li>\n\u003Cli>\n\u003Cp>\u003Cstrong>Diversity of Components.\u003C/strong> The system consists of a variety of components with different properties and behaviors,\ncontributing to the overall complexity.\u003C/p>\n\u003C/li>\n\u003Cli>\n\u003Cp>\u003Cstrong>Multiple Scales.\u003C/strong> Complex systems operate at multiple scales, both in time and space. Behaviors and interactions at\none scale can influence those at another.\u003C/p>\n\u003C/li>\n\u003Cli>\n\u003Cp>\u003Cstrong>Decentralized Control.\u003C/strong> There is no single point of control or central authority governing the system. Control is\ndistributed across the components.\u003C/p>\n\u003C/li>\n\u003Cli>\n\u003Cp>\u003Cstrong>Robustness and Fragility.\u003C/strong> While complex systems can be robust and resilient to certain perturbations, they can\nalso be fragile and susceptible to collapse under certain conditions.\u003C/p>\n\u003C/li>\n\u003C/ul>\n\u003Cp>These are obviously terrible properties of a system if you like control and simplicity. Yet, anyone who has managed a\nteam or built a company or run a political campaign knows that society is complex, not complicated. Groups of humans\nform complex systems. To make matters worse, a group of humans is a complex system made up of complex systems. And each\nhuman body is a complex system with countless interconnected components, feedback loops and emerging abilities.\u003C/p>\n\u003Cp>People drastically underestimate how complex our bodies and brains are. Iâ€™ve recently taken up studying neuroanatomy and\nthe first thing you realize is that talking about the brain gives you the impression that we process information in a\nsingle place. We donâ€™t. There is the peripheral nervous system, the spinal cord, the thalamus, the hypothalamus, the\ncerebral cortex and many more components. Each of these systems are complex chemical and biological systems in and of\nthemselves. Together, they form a dizzyingly complex web of dependencies. There is\nlayer after layer of fragile interconnectedness. Humans are easily killed because of all these dependencies. Small\nerrors in our genetic programming can lead to catastrophic disabilities. On the other hand, when it works, itâ€™s\nmarvelous.\u003C/p>\n\u003Cp>Complex systems are usually not engineered. They are evolved through experimentation. Genetic mutation is the Original\nGangster (OG) of experimentation. Ultraviolet radiation\nis \u003Ca href=\"https://en.wikipedia.org/wiki/Pyrimidine_dimer\">the reason humans are intelligent\u003C/a> ðŸ˜‰. â€œErrorsâ€ are introduced but\nturn out to be a better solution than the previously dominating\nsolution. \u003Ca href=\"https://langkilde.se/post/2022-07-30-extraordinary-success-requires-betting\">Startups are the genetic mutations\u003C/a>\nof the complex system that is our free market. Founders like to think their skill is the main source of success but as\nwith all mutation there is\na \u003Ca href=\"https://langkilde.se/post/2024-03-27-untangling-luck-and-skill-in-business\">huge amount of randomness\u003C/a>. Equilibrium\nemerges temporarily, but as subsystems change equilibrium moves. And complex systems can operate far from their\nequilibrium for a long time, making it hard to tell if the situation is stable or not.\u003C/p>\n\u003Cp>The universe does not lend itself to prediction to such a degree that we can engineer highly complex systems. We\nover-estimate our ability to predict and engineer the future, and under-estimate the amount of randomness. The\nalternative is that we are not in control, which is uncomfortable to most humans. The computational cost of modelling\nenough details to predict the future likely exceeds our available energy.\u003C/p>\n\u003Ch3 id=\"anti-fragility\">Anti-Fragility\u003C/h3>\n\u003Cp>Iâ€™m a big fan of Nassim Taleb and his concept of \u003Ca href=\"https://en.wikipedia.org/wiki/Antifragility\">anti-fragility\u003C/a>. He\ndescribes Black Swan events, i.e. rare, unexpected events with massive consequences. Such events are possible because\ncomplex systems are non-linear. If a complex system is shocked by unexpected information it can lead to cascading\nfailures and huge impact. This is true for the human body, our financial markets and ecosystems.\u003C/p>\n\u003Cp>Taleb suggests we should design anti-fragile systems, i.e. systems that get stronger if shocked. Anti-fragility requires\nredundancy and optionality as strategies to navigate complex systems. Decision-makers should bear the consequences of\ntheir actions to align incentives and encourages more responsible and prudent behavior. Humans are anti-fragile in the\nsense that we have strong incentives to look out for ourselves, we have many redundant sources of food and we are\nadaptable to changes in our environment. You can throw humans into completely new environments with different\ntemperature, humidity and food sources, and a surprisingly large number will survive.\u003C/p>\n\u003Ch3 id=\"intelligence\">Intelligence\u003C/h3>\n\u003Cp>How is all of this connected to intelligence? Well, I think intelligence is a form of anti-fragility that has emerged\nthrough evolution as a defence against complexity. The human body, with its brain and nervous system, has increased its\nbiological market share since it is able to withstand shocks and get stronger from them. We have evolved the ability to\nzero-shot learn complicated things while simultaneously fitting observations and experiences into models for vast,\ncomplex systems. We are resilient, adaptive and fast-learning.\u003C/p>\n\u003Cp>Our current form of machine learning is better equipped to solve complicated problems. Problems that require storage and\ncompute. The last few hundred years have promoted humans with good storage and compute. But those days are over now. We\nhave invented tools that can amplify our storage and compute, or delegate it all together. Whatâ€™s left to humans now is\nhandling complexity. Solving linear, deterministic tasks that require an analytical approach is rapidly becoming a\ncommodity. This commoditization of storage and compute has been ongoing since the invention of the computer, and is\nexponentially accelerating. At one point, the ability to do arithmetics was highly sought after. Royal courts had\nscholars that memorized large amounts of text. Harvard\nhad \u003Ca href=\"https://en.wikipedia.org/wiki/Harvard_Computers\">human computers\u003C/a>. Today we all have a calculator in our pocket. Or\nour watch. All analytical work is going in that direction. Crunching numbers, matching patterns, extrapolating trends -\nall of that is becoming a commodity. If your job is to make decisions based on data, you are about to be automated.\nFortunately, that is not at all a threat to humanity. We did not build a dominant position in our ecosystem on\nmemorization. We built our position on the ability to navigate complexity. Lean into that.\u003C/p>\n\u003Cp>\u003Cstrong>What is my point?\u003C/strong> My point is that intelligence is not primarily about solving complicated problems. Itâ€™s actually\nabout solving complex problems. Decision-making under uncertainty in unpredictable environment with a lot of\ndependencies. Humans remain the uncontested champions of handling such challenges.\u003C/p>",{"headings":270,"localImagePaths":283,"remoteImagePaths":284,"frontmatter":285,"imagePaths":286},[271,274,277,280],{"depth":24,"slug":272,"text":273},"complicated-systems","Complicated Systems",{"depth":24,"slug":275,"text":276},"complex-systems","Complex Systems",{"depth":24,"slug":278,"text":279},"anti-fragility","Anti-Fragility",{"depth":24,"slug":281,"text":282},"intelligence","Intelligence",[],[],{"pubDate":263,"title":262},[],"complexity-intelligence-and-anti-fragility.md","extraordinary-success-requires-betting",{"id":288,"data":290,"body":293,"filePath":294,"digest":295,"rendered":296,"legacyId":316},{"title":291,"pubDate":292},"Extraordinary Success Requires Betting","2022-07-30","**Life starts simple.** All you need to do in school is to understand the instructions and execute them accordingly. If\nyou work hard, you succeed. Simple. The moment you leave school, everything changes. Suddenly, you cannot just work hard\nto be extraordinary. There is no definitive path to greatness anymore. Sure, you can get a job and do what the boss\ntells you, but soon you will find that you cannot achieve breakout success by doing what you are told. Instead, **you\nhave to make bets.**\n\n### Valuable Tasks are Bets\n\nWhen I left school, I was lucky and got an amazing first job at Recorded Future, working for a group of highly\nsuccessful entrepreneurs. They assigned me crazy hard tasks and pushed me to my limit. I am incredibly grateful for\nthat. But, there is one thing I wish I knew then that took me many years to learn:\n\n**Most valuable tasks are bets.** This is particularly true when innovating. You assume something is possible without\nknowing for sure. Before realizing this, I was hesitant to take on really hard tasks. Or even worse, I inadvertently\ntook on extremely risky tasks and suffered when I â€œfailedâ€. It was grueling. I wanted to succeed and do good, but I kept\nfailing. Since I had no experience, I could not articulate why I failed, so I felt like _I was a failure_. I confused\ntaking huge risks and failing, with _being a failure_.\n\n### Communicate Your Bets Clearly\n\n**Learn what sorts of bets you make and tell people upfront.** You can make high-risk bets, which typically come with\nhigh rewards. Or you can make low-risk bets, which typically come with lower rewards. Of course, most of the high-risk\nbets will not pan out. But that does not necessarily mean that the one making the bet is a failure. It just means they\nbet on something unlikely. Of course, skill and hard work can improve your odds. A task that is impossible for someone\nis easy for someone else. In some cases, such as programming, skill has a huge impact. In others, not so much. Some\nclaim that ideas are worthless and execution is everything. My experience tells me otherwise. Some ideas have an\ninherent upper bound value that no amount of skill can overcome. That is why most great venture firms only bet on huge\nmarkets - that way, they eliminate the risk of the idea setting an upper bound for returns.\n\nIt would have been much easier if Iâ€™d known this in my first job. Instead of taking on crazy risky projects without\nsetting expectations, I could have said: â€œI have this crazy idea that might work, but it also might not. If it works,\nitâ€™s super valuable. If it doesnâ€™t, we wonâ€™t get any value except lessons learned. Can I go ahead with this idea?â€. I\nthink my superiors would have allowed me to test most of my ideas. High risk is not inherently bad, as long as everyone\ninvolved _knows_ what sort of bet you are making (and preferably that there is a lot to win). If you are great at\nwhat you do and work hard but still fail, then just try again. And if someone calls you a failure in that case, just\nignore them.\n\n### Boldness vs. Integrity\n\n**I have struggled with the tension between making bold bets and being true to my word.** My instinct is to want to keep\nmy word and not exaggerate. On the other hand, audacious things are only possible if you take great risks. Day by day,\nIâ€™m learning to make the risks of my activities clear while not letting that discourage me. It is not lying or\nexaggerating if you are clear about the risks. To get comfortable with this fact, you must realize there is a huge\ndifference between what is _possible_ and _probable_.\n\n> _Speech is my hammer, bang the world into shape - now let it fall_\n> \n> \"Hip Hop\" on â€œBlack on Both Sidesâ€ by Mos Def\n\n**I firmly believe that action shapes reality.** I expect the world to bend to my will. What we do and say matters. What\nI mean by that is: I believe my actions can significantly change the probability of something happening. The _probable_\nis what happens when no one interferes. The _possible_ is sometimes achieved when _someone takes action_. People too\noften assume that things are normally distributed and beyond their control. They assume they will experience â€œthe most\nlikely outcomeâ€. In reality, many distributions are heavily â€œright-skewedâ€. Or we can make them â€œright-skewedâ€.\n\nFor example, it turns out that global mean income is higher than the median, i.e. income is â€œright-skewed.â€ I think this\nis because highly leveraged bets with huge potential upsides _sometimes_ pay off. In most cases, they do not, and those\nâ€œfailingâ€ resort back to salary-paying jobs. Salaries are probably closer to normally distributed since they are upper\nbound by the amount of time you can work in most cases. While wealth likely begets wealth, most of it results from risky\nbets actually working out.\n\n### Pursue the Possible over the Probable\n\n**Huge value can only come from the unlikely.** In an age of increasing machine intelligence, efficiently doing what is\nexpected will bring lower and lower returns. Humans are not suited to compete with machines regarding memory,\nefficiency, or repeatability. To use a finance term, there is\nno â€œ[alpha](https://en.wikipedia.org/wiki/Alpha_\\(finance\\))â€ in doing what is expected. You can, at best, replicate\nwhat everyone else is doing. Only those with the courage to believe in the _possible_ over the _probable_ will be able\nto generate huge returns. So, learn to let go of your fear of failure and start betting.\n\nPS. If you want downside protection, you can just learn how to program.   \nThat way, you can always make a living. DS.","src/content/blog/extraordinary-success-requires-betting.md","cb38bfe91aad8997",{"html":297,"metadata":298},"\u003Cp>\u003Cstrong>Life starts simple.\u003C/strong> All you need to do in school is to understand the instructions and execute them accordingly. If\nyou work hard, you succeed. Simple. The moment you leave school, everything changes. Suddenly, you cannot just work hard\nto be extraordinary. There is no definitive path to greatness anymore. Sure, you can get a job and do what the boss\ntells you, but soon you will find that you cannot achieve breakout success by doing what you are told. Instead, \u003Cstrong>you\nhave to make bets.\u003C/strong>\u003C/p>\n\u003Ch3 id=\"valuable-tasks-are-bets\">Valuable Tasks are Bets\u003C/h3>\n\u003Cp>When I left school, I was lucky and got an amazing first job at Recorded Future, working for a group of highly\nsuccessful entrepreneurs. They assigned me crazy hard tasks and pushed me to my limit. I am incredibly grateful for\nthat. But, there is one thing I wish I knew then that took me many years to learn:\u003C/p>\n\u003Cp>\u003Cstrong>Most valuable tasks are bets.\u003C/strong> This is particularly true when innovating. You assume something is possible without\nknowing for sure. Before realizing this, I was hesitant to take on really hard tasks. Or even worse, I inadvertently\ntook on extremely risky tasks and suffered when I â€œfailedâ€. It was grueling. I wanted to succeed and do good, but I kept\nfailing. Since I had no experience, I could not articulate why I failed, so I felt like \u003Cem>I was a failure\u003C/em>. I confused\ntaking huge risks and failing, with \u003Cem>being a failure\u003C/em>.\u003C/p>\n\u003Ch3 id=\"communicate-your-bets-clearly\">Communicate Your Bets Clearly\u003C/h3>\n\u003Cp>\u003Cstrong>Learn what sorts of bets you make and tell people upfront.\u003C/strong> You can make high-risk bets, which typically come with\nhigh rewards. Or you can make low-risk bets, which typically come with lower rewards. Of course, most of the high-risk\nbets will not pan out. But that does not necessarily mean that the one making the bet is a failure. It just means they\nbet on something unlikely. Of course, skill and hard work can improve your odds. A task that is impossible for someone\nis easy for someone else. In some cases, such as programming, skill has a huge impact. In others, not so much. Some\nclaim that ideas are worthless and execution is everything. My experience tells me otherwise. Some ideas have an\ninherent upper bound value that no amount of skill can overcome. That is why most great venture firms only bet on huge\nmarkets - that way, they eliminate the risk of the idea setting an upper bound for returns.\u003C/p>\n\u003Cp>It would have been much easier if Iâ€™d known this in my first job. Instead of taking on crazy risky projects without\nsetting expectations, I could have said: â€œI have this crazy idea that might work, but it also might not. If it works,\nitâ€™s super valuable. If it doesnâ€™t, we wonâ€™t get any value except lessons learned. Can I go ahead with this idea?â€. I\nthink my superiors would have allowed me to test most of my ideas. High risk is not inherently bad, as long as everyone\ninvolved \u003Cem>knows\u003C/em> what sort of bet you are making (and preferably that there is a lot to win). If you are great at\nwhat you do and work hard but still fail, then just try again. And if someone calls you a failure in that case, just\nignore them.\u003C/p>\n\u003Ch3 id=\"boldness-vs-integrity\">Boldness vs. Integrity\u003C/h3>\n\u003Cp>\u003Cstrong>I have struggled with the tension between making bold bets and being true to my word.\u003C/strong> My instinct is to want to keep\nmy word and not exaggerate. On the other hand, audacious things are only possible if you take great risks. Day by day,\nIâ€™m learning to make the risks of my activities clear while not letting that discourage me. It is not lying or\nexaggerating if you are clear about the risks. To get comfortable with this fact, you must realize there is a huge\ndifference between what is \u003Cem>possible\u003C/em> and \u003Cem>probable\u003C/em>.\u003C/p>\n\u003Cblockquote>\n\u003Cp>\u003Cem>Speech is my hammer, bang the world into shape - now let it fall\u003C/em>\u003C/p>\n\u003Cp>â€œHip Hopâ€ on â€œBlack on Both Sidesâ€ by Mos Def\u003C/p>\n\u003C/blockquote>\n\u003Cp>\u003Cstrong>I firmly believe that action shapes reality.\u003C/strong> I expect the world to bend to my will. What we do and say matters. What\nI mean by that is: I believe my actions can significantly change the probability of something happening. The \u003Cem>probable\u003C/em>\nis what happens when no one interferes. The \u003Cem>possible\u003C/em> is sometimes achieved when \u003Cem>someone takes action\u003C/em>. People too\noften assume that things are normally distributed and beyond their control. They assume they will experience â€œthe most\nlikely outcomeâ€. In reality, many distributions are heavily â€œright-skewedâ€. Or we can make them â€œright-skewedâ€.\u003C/p>\n\u003Cp>For example, it turns out that global mean income is higher than the median, i.e. income is â€œright-skewed.â€ I think this\nis because highly leveraged bets with huge potential upsides \u003Cem>sometimes\u003C/em> pay off. In most cases, they do not, and those\nâ€œfailingâ€ resort back to salary-paying jobs. Salaries are probably closer to normally distributed since they are upper\nbound by the amount of time you can work in most cases. While wealth likely begets wealth, most of it results from risky\nbets actually working out.\u003C/p>\n\u003Ch3 id=\"pursue-the-possible-over-the-probable\">Pursue the Possible over the Probable\u003C/h3>\n\u003Cp>\u003Cstrong>Huge value can only come from the unlikely.\u003C/strong> In an age of increasing machine intelligence, efficiently doing what is\nexpected will bring lower and lower returns. Humans are not suited to compete with machines regarding memory,\nefficiency, or repeatability. To use a finance term, there is\nno â€œ\u003Ca href=\"https://en.wikipedia.org/wiki/Alpha_(finance)\">alpha\u003C/a>â€ in doing what is expected. You can, at best, replicate\nwhat everyone else is doing. Only those with the courage to believe in the \u003Cem>possible\u003C/em> over the \u003Cem>probable\u003C/em> will be able\nto generate huge returns. So, learn to let go of your fear of failure and start betting.\u003C/p>\n\u003Cp>PS. If you want downside protection, you can just learn how to program.\u003Cbr>\nThat way, you can always make a living. DS.\u003C/p>",{"headings":299,"localImagePaths":312,"remoteImagePaths":313,"frontmatter":314,"imagePaths":315},[300,303,306,309],{"depth":24,"slug":301,"text":302},"valuable-tasks-are-bets","Valuable Tasks are Bets",{"depth":24,"slug":304,"text":305},"communicate-your-bets-clearly","Communicate Your Bets Clearly",{"depth":24,"slug":307,"text":308},"boldness-vs-integrity","Boldness vs. Integrity",{"depth":24,"slug":310,"text":311},"pursue-the-possible-over-the-probable","Pursue the Possible over the Probable",[],[],{"pubDate":292,"title":291},[],"extraordinary-success-requires-betting.md","learning-to-be-an-optimist",{"id":317,"data":319,"body":322,"filePath":323,"digest":324,"rendered":325,"legacyId":339},{"title":320,"pubDate":321},"Learning to be an Optimist","2021-07-15","> _Pessimists sound smart, optimists make money._\n>\n> Nat Friedman, CEO of GitHub\n\n### Realism vs. Optimism\n\nI was born and raised in Sweden, a country that favors consensus and realistic planning. Weâ€™ve survived all sorts of\nhardships by working together. At the same time, weâ€™re an increasingly individualistic society that promotes successful\npeople as role models. This creates an interesting tension between success and realism. While we increasingly celebrate\nsuccess, we still have a certain lack of imagination in execution.\n\nIf someone suggested in 2003 that they would revolutionize the automotive industry by creating their own car brand that\nhas all the things incumbents do not have, most people in Europe would shrug and say â€œno fucking way that will workâ€. In\nfact, they did. Despite that, Elon Musk started Tesla and changed the world. Iâ€™ve long thought he was crazy to try, and\nI lacked the imagination to see a possible execution plan. On the other hand, now that Iâ€™ve gotten to know legacy\nautomotive companies and their way of working, it makes sense. The stagnation and lack of innovation they suffer from\nmake me certain change was necessary. And that huge improvements were, and still are, possible. Today, Iâ€™m bullish that\nTesla is in fact better at most things already. Except for safety... Apparently I can love and hate a company at the\nsame\ntimeâ€¦\n\n> _If the situation is unsustainable, and the options are impossible, the situation wins._\n\n### Some Things Are Inevitable\n\nI may not be clear how, when or at what cost - but it is clear it will happen eventually. We will have to adapt to limit\nclimate change. We will have to find new ways to grow food. We will have to find ways to build more efficient housing.\nWe will have to find new sources of raw materials in space. We will have to find even better sources of renewable\nenergy. Iâ€™m confident we will, even if I do not know how yet. I have a firm belief in human ingenuity, and our ability\nto create a better world for ourselves.\n\n**Why am I writing this?** Well, I look at things around me and try and determine: can this be done? What Iâ€™m realizing\nnow is that this is the wrong question. The question should not be â€œcan this be done?â€, it should be â€œmust this be\ndone?â€. If the answer is yes, then you should not let the _how_ stop you. If something really must be done, others will\nbelieve in it too. That means you will have friends fighting for your cause. You will find money that otherwise wasnâ€™t\navailable. And all of a sudden that which at some point was impossible suddenly becomes possible.\n\nEither way, you will make a positive impact in pushing for necessary change. Failure is fine if the cause is good. Iâ€™m\nstill learning to be a true optimist and to focus on what must be done.","src/content/blog/learning-to-be-an-optimist.md","c610a2ad745e1190",{"html":326,"metadata":327},"\u003Cblockquote>\n\u003Cp>\u003Cem>Pessimists sound smart, optimists make money.\u003C/em>\u003C/p>\n\u003Cp>Nat Friedman, CEO of GitHub\u003C/p>\n\u003C/blockquote>\n\u003Ch3 id=\"realism-vs-optimism\">Realism vs. Optimism\u003C/h3>\n\u003Cp>I was born and raised in Sweden, a country that favors consensus and realistic planning. Weâ€™ve survived all sorts of\nhardships by working together. At the same time, weâ€™re an increasingly individualistic society that promotes successful\npeople as role models. This creates an interesting tension between success and realism. While we increasingly celebrate\nsuccess, we still have a certain lack of imagination in execution.\u003C/p>\n\u003Cp>If someone suggested in 2003 that they would revolutionize the automotive industry by creating their own car brand that\nhas all the things incumbents do not have, most people in Europe would shrug and say â€œno fucking way that will workâ€. In\nfact, they did. Despite that, Elon Musk started Tesla and changed the world. Iâ€™ve long thought he was crazy to try, and\nI lacked the imagination to see a possible execution plan. On the other hand, now that Iâ€™ve gotten to know legacy\nautomotive companies and their way of working, it makes sense. The stagnation and lack of innovation they suffer from\nmake me certain change was necessary. And that huge improvements were, and still are, possible. Today, Iâ€™m bullish that\nTesla is in fact better at most things already. Except for safetyâ€¦ Apparently I can love and hate a company at the\nsame\ntimeâ€¦\u003C/p>\n\u003Cblockquote>\n\u003Cp>\u003Cem>If the situation is unsustainable, and the options are impossible, the situation wins.\u003C/em>\u003C/p>\n\u003C/blockquote>\n\u003Ch3 id=\"some-things-are-inevitable\">Some Things Are Inevitable\u003C/h3>\n\u003Cp>I may not be clear how, when or at what cost - but it is clear it will happen eventually. We will have to adapt to limit\nclimate change. We will have to find new ways to grow food. We will have to find ways to build more efficient housing.\nWe will have to find new sources of raw materials in space. We will have to find even better sources of renewable\nenergy. Iâ€™m confident we will, even if I do not know how yet. I have a firm belief in human ingenuity, and our ability\nto create a better world for ourselves.\u003C/p>\n\u003Cp>\u003Cstrong>Why am I writing this?\u003C/strong> Well, I look at things around me and try and determine: can this be done? What Iâ€™m realizing\nnow is that this is the wrong question. The question should not be â€œcan this be done?â€, it should be â€œmust this be\ndone?â€. If the answer is yes, then you should not let the \u003Cem>how\u003C/em> stop you. If something really must be done, others will\nbelieve in it too. That means you will have friends fighting for your cause. You will find money that otherwise wasnâ€™t\navailable. And all of a sudden that which at some point was impossible suddenly becomes possible.\u003C/p>\n\u003Cp>Either way, you will make a positive impact in pushing for necessary change. Failure is fine if the cause is good. Iâ€™m\nstill learning to be a true optimist and to focus on what must be done.\u003C/p>",{"headings":328,"localImagePaths":335,"remoteImagePaths":336,"frontmatter":337,"imagePaths":338},[329,332],{"depth":24,"slug":330,"text":331},"realism-vs-optimism","Realism vs. Optimism",{"depth":24,"slug":333,"text":334},"some-things-are-inevitable","Some Things Are Inevitable",[],[],{"pubDate":321,"title":320},[],"learning-to-be-an-optimist.md","learning-world-models-for-robust-ai",{"id":340,"data":342,"body":345,"filePath":346,"digest":347,"rendered":348,"legacyId":371},{"title":343,"pubDate":344},"Learning World Models for Robust AI","2023-07-27","**I recently declared that\nIâ€™m [more excited than worried](https://langkilde.se/post/2023-06-08-why-i-am-excited-about-ai) about recent progress in\nAI! ðŸš€** The main reason is my belief that there is a low near-term probability of self-improving AI. I cannot convince\nmyself that asymptotic self-improvement is imminent. That said, I cannot dismiss the potentially catastrophic impact of\na runaway scenario; I just think itâ€™s still a long way off. While the short-term disruption caused by new AI technology\nmight be significant, I think it will be manageable. Assuming self-improvement does not kick in, the benefits of AI\nmassively outweigh the downsides. Part of arriving at this conclusion is the incredible complexity involved in creating\nembodied AI capable of independent self-improvement. Iâ€™ve taken time this summer to read various suggestions of how\nembodied AI might be made real, and I want to share some thoughts.\n\n### Learning World Models\n\n**I think a â€œworld modelâ€ is necessary for robust intelligence.** Iâ€™ve read most of the recent papers by Yann LeCun, and\nI tend to agree with his position that models need â€œ[grounding](v).â€ He points out that all known machine learning\ntechniques are inferior even to simple animals with respect to their learning efficiency. Supervised learning (SL)\nmethods require vast amounts of labels, reinforcement learning (RL) methods require insane amounts of trials, and\nself-supervised learning (SSL) requires an enormous amount of unlabeled samples. Our current auto-regressive language\nmodels are no different. Language models require massive amounts of text for their self-supervised learning to find\nefficient representations that allow human-like token predictions. Animals and humans, on the other hand, can learn very\nquickly, we can reason and plan, and we understand how the world works. How is that possible?\n\n### Representing Reality\n\nFor the sake of this post, assume that we all operate in a shared, objective reality. We observe this reality by sensing\nobjects in space and tracking them through time. The photons that hit our retinas are translated into electrical signals\nthat flow through our brains. Out the other end comes nerve signals telling our bodies to move. How the brain works is\nstill a mystery, but we can build a world model to predict the future and plan our actions. How is our world model\ncreated, and how does it work?\n\nI think there exists â€œ**natural concepts** â€ that are universal across languages and cultures. These concepts are\ndistilled representations of objects, their relationships, and the patterns by which they interact. We start forming\nthese concepts very early on. We learn that every source of light, sound, and touch in the world has a distance from us.\nParallax motion makes depth obvious, making the notion of objects appear and the fact that objects can occlude more\ndistant ones. Once established, objects can be automatically assigned to broad categories as a function of their\nappearance or behavior. At first, these categories are blurry, but the more context that has been gathered, the more\ncrips the ontology becomes. On top of the notion of objects comes the knowledge that objects do not spontaneously\nappear, disappear, change shape, or teleport: they move smoothly and can only be in one place at any time. Once such\nconcepts are acquired, it becomes easy to learn that some objects are static, some have predictable trajectories (\ninanimate objects), some behave in somewhat unpredictable ways (collective phenomena like water, sand, tree leaves in\nthe wind, etc.), and some seem to obey different rules (animate objects like people). Notions of intuitive physics such\nas stability, gravity, inertia, and others will eventually emerge. The effect of animate objects on the world (including\nthe effects of the subjectâ€™s actions) can be used to deduce cause-and-effect relationships, on top of which linguistic\nand social knowledge can be acquired.\n\n![](https://storage.googleapis.com/langkilde-se-images/c697fd91-836d-4e89-907e-f9e1a0b7ecd5.jpeg)\n\n**The cool thing about humans is that we can learn enormous amounts of background knowledge about how the world works\nthrough observation.** We need very few interactions in a task-independent, unsupervised way and yet extract relevant\nthings**.** We are not just stumbling around in the world. Instead, we accumulate knowledge in a â€œ**world model**.â€ We\ncould think of this as common sense. Humans use common sense to inform themselves about what is likely, possible, and\nimpossible. We have knowledge of physics, social interactions, and society that we use to predict outcomes and avoid\nmistakes. Common sense helps us fill in missing information and make us able to handle novel situations. It helps us\nrobustly interpret what we sense and ensure we do not suffer catastrophic failures of perception.\n\nWhile most of the human experience is virtual today, we inform our world model through **perceptual experiences**. In\ncontemporary philosophy, perception roughly means what is conveyed to the subject by her perceptual experience, i.e.,\nthe [phenomenology](https://en.wikipedia.org/wiki/Phenomenology_\\(philosophy\\)) of an experience is what it is like for\nthe subject to have it. At any given point in time, healthy humans typically have experiences in all of the five sensing\nmodalities, along with [proprioceptive](https://en.wikipedia.org/wiki/Proprioception) experience. The boundaries between\nour sensing modalities can be hard to draw, which is probably a hint.\n\nPeople have thought about **how we transform our perceptual experiences into mental states** since the days of\nAristotle. There is, for example, The Representational Theory of Mind (RTM) (or Computational Theory of Mind). RTM takes\nas its starting point commonsense mental states, such as thoughts, beliefs, desires, and perceptions. Such states are\nsaid to have â€œintentionalityâ€ â€“ they are _about_ or _refer_ _to_ things and may be evaluated with respect to properties\nlike consistency, truth, appropriateness, and accuracy. â€œA ripe strawberry is red is accurate,â€ or â€œGeorge Washington\nwith dreadlocks is inaccurate.â€ RTM understands mental processes such as thinking and reasoning as sequences of\nintentional mental states. To infer a proposition _q_ from the propositions _p_ and _if p then q_ is to have a sequence\nof thoughts of the form _p, if p then q, q._ Recent debates about mental representation have centered around\npropositional attitudes (beliefs, desires, etc.), the determination of their contents, and the existence of phenomenal\nproperties and their relation to the content of thought and perceptual experience. Or put more simply: how is what we\nare experiencing and thinking interacting with our beliefs and desires?\n\nSome assume that mental representations come in two primary varieties. There are those, such as thoughts, that are\ncomposed of concepts and have no â€œqualiaâ€ (â€œwhat-itâ€™s-likeâ€), and those, such as sensations, that reversely have\nphenomenal features but no concepts. Famous thinkers like Aristotle, Locke, and Hume seem to assume that non-conceptual\nrepresentations are the only mental representations. Others, like Wittgenstein, argue that lack of generality,\nambiguity, and their unsuitability to function as logical or mathematical concepts means no theory of mind can work\nwith only non-conceptual representations.\n\nRegardless of what theory of mental representation you subscribe to, I know from my subjective conscious experience that\nI see things that cause updates to my world model. This ability, and the efficiency by which humans incorporate new\ninformation into our world model, is central to our versatile intelligence. Iâ€™m personally mainly focused on **Embodied\nAI** (as opposed to, e.g., virtual, text-based language models). To quote the\nMIT [CSAIL Embodied Intelligence lab](https://ei.csail.mit.edu), Embodied AI is focused on _â€œunderstanding the nature of\nintelligent behavior in the physical world through studying human intelligence and designing and implementing\nintelligent robots. [This requires] expertise in perception, sensing, language, learning, and planning, and [we] aim to\nintegrate these disciplines to make physical agents with human-like intelligence.â€_ Most of todayâ€™s autonomous agents (\nrobots, AVs, etc.) have a technology stack that consists of three main parts: **perception** , **prediction,** and *\n*planning**. For each of these layers, scientists and engineers are working on using machine learning techniques like\nsupervised learning (SL), self-supervised learning (SSL), and reinforcement learning (RL) to teach algorithms to behave\nwell.\n\nI imagine two interacting processes: 1) **Forming concepts** and 2) **Predicting the future**. Human success comes down\nto our ability to predict the future based on our actions. The more intelligent, the better humans predict the future,\neven when faced with novel situations or limited data.\n\n![](https://storage.googleapis.com/langkilde-se-images/0141fb0d-b64e-44ca-91b2-037a82793bfc.jpeg)\n\nSo far, engineers designing autonomous systems have **isolated perception** into a specific step. Engineers have focused\non training systems to see where everything is located and assign objects properties like â€œthis is a car.â€ Supervised\nlearning is the most prevalent method, and some companies spend millions of dollars on labeling tens of millions of\nimages to train neural networks to make predictions consistent with said labels. This approach has several **severe\nlimitations** , a critical one being the **need for an agreed-upon ontology of the world** by which you label\ninformation. Even if we can somehow agree on an ontology, that ontology also needs to result in labels that carry enough\ninformation such that later stages of the pipeline can predict the future based on the labels. As it turns out, **humans\nare not good at describing** **the world explicitly** **in ways that allow predictions of the future**. Whatever\nrepresentation we hack together leaves out too many relevant things. Most of the â€œdistillation of perceptionâ€ happens\nunconsciously. When we are forced to try and make it explicit we underestimate how much subtlety we take into account\nwhen viewing the world. Hinton has observed that:\n\n> _The brain has about 10^14 synapses and we only live for about 10^9 seconds. So we have a lot more parameters than\ndata. This motivates the idea that we most do a lot of unsupervised learning since the perceptual input is the only\nplace we can get 10^5 dimensions of constraints per second._\n\nThe biological body is so complex and has 10,000 to 100,000 sensors distributed throughout that this alone makes every\nsingle millisecond of our lives a potentially unique experience. Combine that with the fact that we have on the order of\n100.000s or more muscle fiber units with a massive number of possible mechanical configurations. This means the brain is\ndesigned to handle unexpected events constantly. There is very little repetition if details are considered. Besides,\nthere is also the problem that the world is only partially observable and partially predictable. Even if we assume the\nworld is deterministic, there is still the issue that small perturbations of initial states of nonlinear systems can\ncause massive differences in later states. As a result, **whatever world model we create needs to be built around the\nassumption that almost nothing ever happens. At least not twice.**\n\n**Every aspect of a robust world model needs to be learned from experience and interaction to solve this.** Put\ndifferently, our world model must be a fully differentiable end-to-end model. The world model is optimized to allow the\nbest possible prediction of the future as measured by our ability to maximize some reward function. This would mean\nmerging the perception, prediction, and planning steps into an end-to-end differentiable model. When the development of\nautomated mobility took off about 15 years ago, this was impossible. As a result, a â€œdivide-and-conquerâ€ method was\napplied. Also, many people insist an explicit intermediate representation is required to validate systems. Thatâ€™s a poor\nexcuse not to pursue an end-to-end differentiable approach. There will always be ways to decode a latent model into\nsomething that can be inspected, and unit tests can be designed to test safety-critical aspects of the model.\n\n### A Possible Architecture for Robust Embodied AI\n\nLeCun outlines an end-to-end approach in his position\npaper, â€œ[A Path Towards Autonomous Machine Intelligence](https://openreview.net/pdf?id=BZ5a1r-kVsf). He proposes a\nfoundational architecture for achieving this form of efficient learning with six components: Configurator, Perception,\nWorld Model, Cost, Memory, and Actor.\n\n![](https://storage.googleapis.com/langkilde-se-images/a50357bb-ad01-483a-b785-5a14ba186f41.jpeg)\n\nThe idea is that a **Configurator** interacts with all modules by modulating their parameters and attention circuits,\ni.e., priming them for a particular goal. The **Perception** module receives signals from sensors and estimates the\ncurrent state of the world. Since only a small subset of the perceived state of the world is relevant and valuable, the\nconfigurator will prime the perception system to extract the relevant information from the percept for the task at hand.\nThe **World Model module then has two roles: (1) estimate the missing information about the state of the world not\nprovided by perception, (2) predict plausible future states of the world.** This world model needs to be learned\nentirely, i.e., completely differentiable. It needs to consider both the untouched evolution of the world and future\nstates resulting from a sequence of actions proposed by the actor module. Predictions are performed within an abstract\nrepresentation space**** containing information relevant to the task. A key issue is that the world model needs to be\nable to represent multiple possible predictions of the world state. The natural world is only partially predictable.\nToday, it is not clear how to (1) allow a world model to make multiple plausible predictions and represent uncertainty\nin those predictions and (2) how to train a world model like this. The **Cost** module measures the level of\nâ€œdiscomfortâ€ of the agent. There are probably two types of cost: _Intrinsic Cost_ , i.e., hard-wired discomfort (think\npain, pleasure, hunger, etc.), and _Trainable Cost,_ which predicts an estimate of future intrinsic energies. Both have\nsimilar purposes: to minimize the cost over the long run. The intrinsic cost determines the nature of the agentâ€™s\nbehavior. The **Memory** module stores relevant information about the world's past, current and future states. Other\nsystems can query and modify stored states and costs. The **Actor** module computes proposals for sequences of actions\nand outputs actions to the effectors. The proposed sequence of actions is sent to the world model, which then predicts\nfuture world states from the action sequence and feeds it to the cost module. The actor may comprise two components: (1)\na policy module that directly produces an action from the world state estimate produced by the perception module and\nretrieved from short-term memory, and (2) the action optimizer described above. This would be similar\nto [Kahnemanâ€™s â€œSystem 1â€ and â€œSystem 2â€](https://thedecisionlab.com/reference-guide/philosophy/system-1-and-system-2-thinking)\nthinking. Hereâ€™s an example of a â€œSystem 2â€ thinking process based on this architecture:\n\n1. **Perception:** the perception system extracts a representation of the current state of the world. The cost module\n   computes and stores the immediate cost associated with that state.\n\n2. **Actorâ€™s first proposal** : the actor proposes an initial sequence of actions to be fed to the world model for\n   evaluation.\n\n3. **World Model prediction** : the world model predicts one or several likely sequences of world state representations\n   resulting from the proposed action sequence.\n\n4. **Cost evaluation** : the cost module estimates a total cost from the predicted state sequence, generally as a sum\n   over time steps.\n\n5. **Actor's new proposal** : the actor proposes a new action sequence with a lower cost. This can be done through a\n   gradient-based procedure in which gradients of the cost are back-propagated through the compute graph to the action\n   variables. Complete optimization may require iterating steps 2-5.\n\n6. **Actor sends actions:** after converging on a low-cost action sequence, the actor sends the first action (or first\n   few actions) in the low-cost sequence to the effectors. The entire process is repeated for the next perception-action\n   episode.\n\n7. **Memory** : after every action, the states and associated costs from the intrinsic cost and the critic are stored in\n   the short-term memory. These pairs can be used later to train or adapt the critic.\n\n### Predictions in Latent Spaces\n\nLeCun is famous for his â€œcake analogy,â€ i.e., _â€œIf intelligence is a cake, the bulk of the cake is self-supervised\nlearning, the icing on the cake is supervised learning, and the cherry on the cake is reinforcement learning (RL).â€_ The\nidea is that humans leverage capabilities such as predicting and reasoning to infer the future from available\ninformation. We do not just learn from explicit labels. â€œ _Prediction is the essence of intelligence_.â€\n\nThe centerpiece of the architecture laid out by LeCun is the predictive world model. A challenge with constructing it is\nenabling it to represent multiple plausible predictions. The proposed **Joint Embedding Predictive Architecture (JEPA)**\nis part of solving this. JEPA is\nan [energy-based](https://en.wikipedia.org/wiki/Energy_based_model#:~:text=An%20energy%2Dbased%20model%20\\(EBM,also%20match%20the%20data%20distribution.)\nself-supervised learning model that captures the dependencies between two given inputs, say _x_ and _y_. The specific\nbenefit of this approach is that instead of predicting _y_ from _x_ directly, we are predicting the latent\nrepresentation of _y_ that is most likely to follow _x_. This makes the approach different from generative AI models\nthat directly predict _y,_ and it is what unlocks the ability to represent multiple plausible futures.\n\n![](https://storage.googleapis.com/langkilde-se-images/4e57f718-1f4d-466e-9119-e54e21656dd8.jpeg)\n\nBy predicting in **latent space,** we can minimize the information content leveraged. This is desirable since the world\nis only partially predictable. A direct prediction of future data, e.g., frames in a long video sequence, would be\nenormously resource-consuming. Humans do not predict every â€œpixel,â€ i.e., every tree leaf, the exact texture of the\nfloor, or how clouds will move. Itâ€™s more realistic to assume that we predict some lower-content representation that\nignores certain irrelevant aspects of reality. This would be the world model. Four things are important to this\napproach:\n\n* Make the representation of x maximally informative about x\n\n* Make the representation of y maximally informative about y\n\n* Make the representation of y maximally predictable from the representation of x\n\n* Make the predictor use as little information as possible from the latent variable to represent uncertainty in the\n  prediction.\n\nLeCun has, for example,\nproposed [VICReg](https://arxiv.org/abs/2105.04906?fbclid=IwAR2jCTVpqrK8XCoQ1AXZue33NenZUoEhk7VVp6P8qpx4fpezuHvFV6jJUmg)\nas a method to do this.\n\n![](https://storage.googleapis.com/langkilde-se-images/1afd2c38-0d73-4616-85ed-c45f487f5c49.jpeg)\n\n### Latent Spaces and Reward Functions\n\nThe future belongs to self-supervised methods that observe large quantities of recordings to derive the most informative\nlatent representations for some reward function that requires you to predict the future. This means:\n\n**The control problem is in the latent space interacting with the reward function.** If we want to understand and\ncontrol a system, we must understand the connection between the embeddings and the predictions of the future those\nembeddings lead to. If we want to ensure a specific type of behavior in a specific situation, we must ensure that the\nreward function causes the desired decision for a particular learned representation. As of today, there are no such\nprogramming tools.\n\nThey will inevitably be created.","src/content/blog/learning-world-models-for-robust-ai.md","55e9f055adcfe059",{"html":349,"metadata":350},"\u003Cp>\u003Cstrong>I recently declared that\nIâ€™m \u003Ca href=\"https://langkilde.se/post/2023-06-08-why-i-am-excited-about-ai\">more excited than worried\u003C/a> about recent progress in\nAI! ðŸš€\u003C/strong> The main reason is my belief that there is a low near-term probability of self-improving AI. I cannot convince\nmyself that asymptotic self-improvement is imminent. That said, I cannot dismiss the potentially catastrophic impact of\na runaway scenario; I just think itâ€™s still a long way off. While the short-term disruption caused by new AI technology\nmight be significant, I think it will be manageable. Assuming self-improvement does not kick in, the benefits of AI\nmassively outweigh the downsides. Part of arriving at this conclusion is the incredible complexity involved in creating\nembodied AI capable of independent self-improvement. Iâ€™ve taken time this summer to read various suggestions of how\nembodied AI might be made real, and I want to share some thoughts.\u003C/p>\n\u003Ch3 id=\"learning-world-models\">Learning World Models\u003C/h3>\n\u003Cp>\u003Cstrong>I think a â€œworld modelâ€ is necessary for robust intelligence.\u003C/strong> Iâ€™ve read most of the recent papers by Yann LeCun, and\nI tend to agree with his position that models need â€œ\u003Ca href=\"v\">grounding\u003C/a>.â€ He points out that all known machine learning\ntechniques are inferior even to simple animals with respect to their learning efficiency. Supervised learning (SL)\nmethods require vast amounts of labels, reinforcement learning (RL) methods require insane amounts of trials, and\nself-supervised learning (SSL) requires an enormous amount of unlabeled samples. Our current auto-regressive language\nmodels are no different. Language models require massive amounts of text for their self-supervised learning to find\nefficient representations that allow human-like token predictions. Animals and humans, on the other hand, can learn very\nquickly, we can reason and plan, and we understand how the world works. How is that possible?\u003C/p>\n\u003Ch3 id=\"representing-reality\">Representing Reality\u003C/h3>\n\u003Cp>For the sake of this post, assume that we all operate in a shared, objective reality. We observe this reality by sensing\nobjects in space and tracking them through time. The photons that hit our retinas are translated into electrical signals\nthat flow through our brains. Out the other end comes nerve signals telling our bodies to move. How the brain works is\nstill a mystery, but we can build a world model to predict the future and plan our actions. How is our world model\ncreated, and how does it work?\u003C/p>\n\u003Cp>I think there exists â€œ\u003Cstrong>natural concepts\u003C/strong> â€ that are universal across languages and cultures. These concepts are\ndistilled representations of objects, their relationships, and the patterns by which they interact. We start forming\nthese concepts very early on. We learn that every source of light, sound, and touch in the world has a distance from us.\nParallax motion makes depth obvious, making the notion of objects appear and the fact that objects can occlude more\ndistant ones. Once established, objects can be automatically assigned to broad categories as a function of their\nappearance or behavior. At first, these categories are blurry, but the more context that has been gathered, the more\ncrips the ontology becomes. On top of the notion of objects comes the knowledge that objects do not spontaneously\nappear, disappear, change shape, or teleport: they move smoothly and can only be in one place at any time. Once such\nconcepts are acquired, it becomes easy to learn that some objects are static, some have predictable trajectories (\ninanimate objects), some behave in somewhat unpredictable ways (collective phenomena like water, sand, tree leaves in\nthe wind, etc.), and some seem to obey different rules (animate objects like people). Notions of intuitive physics such\nas stability, gravity, inertia, and others will eventually emerge. The effect of animate objects on the world (including\nthe effects of the subjectâ€™s actions) can be used to deduce cause-and-effect relationships, on top of which linguistic\nand social knowledge can be acquired.\u003C/p>\n\u003Cp>\u003Cimg src=\"https://storage.googleapis.com/langkilde-se-images/c697fd91-836d-4e89-907e-f9e1a0b7ecd5.jpeg\" alt=\"\">\u003C/p>\n\u003Cp>\u003Cstrong>The cool thing about humans is that we can learn enormous amounts of background knowledge about how the world works\nthrough observation.\u003C/strong> We need very few interactions in a task-independent, unsupervised way and yet extract relevant\nthings**.** We are not just stumbling around in the world. Instead, we accumulate knowledge in a â€œ\u003Cstrong>world model\u003C/strong>.â€ We\ncould think of this as common sense. Humans use common sense to inform themselves about what is likely, possible, and\nimpossible. We have knowledge of physics, social interactions, and society that we use to predict outcomes and avoid\nmistakes. Common sense helps us fill in missing information and make us able to handle novel situations. It helps us\nrobustly interpret what we sense and ensure we do not suffer catastrophic failures of perception.\u003C/p>\n\u003Cp>While most of the human experience is virtual today, we inform our world model through \u003Cstrong>perceptual experiences\u003C/strong>. In\ncontemporary philosophy, perception roughly means what is conveyed to the subject by her perceptual experience, i.e.,\nthe \u003Ca href=\"https://en.wikipedia.org/wiki/Phenomenology_(philosophy)\">phenomenology\u003C/a> of an experience is what it is like for\nthe subject to have it. At any given point in time, healthy humans typically have experiences in all of the five sensing\nmodalities, along with \u003Ca href=\"https://en.wikipedia.org/wiki/Proprioception\">proprioceptive\u003C/a> experience. The boundaries between\nour sensing modalities can be hard to draw, which is probably a hint.\u003C/p>\n\u003Cp>People have thought about \u003Cstrong>how we transform our perceptual experiences into mental states\u003C/strong> since the days of\nAristotle. There is, for example, The Representational Theory of Mind (RTM) (or Computational Theory of Mind). RTM takes\nas its starting point commonsense mental states, such as thoughts, beliefs, desires, and perceptions. Such states are\nsaid to have â€œintentionalityâ€ â€“ they are \u003Cem>about\u003C/em> or \u003Cem>refer\u003C/em> \u003Cem>to\u003C/em> things and may be evaluated with respect to properties\nlike consistency, truth, appropriateness, and accuracy. â€œA ripe strawberry is red is accurate,â€ or â€œGeorge Washington\nwith dreadlocks is inaccurate.â€ RTM understands mental processes such as thinking and reasoning as sequences of\nintentional mental states. To infer a proposition \u003Cem>q\u003C/em> from the propositions \u003Cem>p\u003C/em> and \u003Cem>if p then q\u003C/em> is to have a sequence\nof thoughts of the form \u003Cem>p, if p then q, q.\u003C/em> Recent debates about mental representation have centered around\npropositional attitudes (beliefs, desires, etc.), the determination of their contents, and the existence of phenomenal\nproperties and their relation to the content of thought and perceptual experience. Or put more simply: how is what we\nare experiencing and thinking interacting with our beliefs and desires?\u003C/p>\n\u003Cp>Some assume that mental representations come in two primary varieties. There are those, such as thoughts, that are\ncomposed of concepts and have no â€œqualiaâ€ (â€œwhat-itâ€™s-likeâ€), and those, such as sensations, that reversely have\nphenomenal features but no concepts. Famous thinkers like Aristotle, Locke, and Hume seem to assume that non-conceptual\nrepresentations are the only mental representations. Others, like Wittgenstein, argue that lack of generality,\nambiguity, and their unsuitability to function as logical or mathematical concepts means no theory of mind can work\nwith only non-conceptual representations.\u003C/p>\n\u003Cp>Regardless of what theory of mental representation you subscribe to, I know from my subjective conscious experience that\nI see things that cause updates to my world model. This ability, and the efficiency by which humans incorporate new\ninformation into our world model, is central to our versatile intelligence. Iâ€™m personally mainly focused on \u003Cstrong>Embodied\nAI\u003C/strong> (as opposed to, e.g., virtual, text-based language models). To quote the\nMIT \u003Ca href=\"https://ei.csail.mit.edu\">CSAIL Embodied Intelligence lab\u003C/a>, Embodied AI is focused on \u003Cem>â€œunderstanding the nature of\nintelligent behavior in the physical world through studying human intelligence and designing and implementing\nintelligent robots. [This requires] expertise in perception, sensing, language, learning, and planning, and [we] aim to\nintegrate these disciplines to make physical agents with human-like intelligence.â€\u003C/em> Most of todayâ€™s autonomous agents (\nrobots, AVs, etc.) have a technology stack that consists of three main parts: \u003Cstrong>perception\u003C/strong> , \u003Cstrong>prediction,\u003C/strong> and *\n\u003Cem>planning\u003C/em>*. For each of these layers, scientists and engineers are working on using machine learning techniques like\nsupervised learning (SL), self-supervised learning (SSL), and reinforcement learning (RL) to teach algorithms to behave\nwell.\u003C/p>\n\u003Cp>I imagine two interacting processes: 1) \u003Cstrong>Forming concepts\u003C/strong> and 2) \u003Cstrong>Predicting the future\u003C/strong>. Human success comes down\nto our ability to predict the future based on our actions. The more intelligent, the better humans predict the future,\neven when faced with novel situations or limited data.\u003C/p>\n\u003Cp>\u003Cimg src=\"https://storage.googleapis.com/langkilde-se-images/0141fb0d-b64e-44ca-91b2-037a82793bfc.jpeg\" alt=\"\">\u003C/p>\n\u003Cp>So far, engineers designing autonomous systems have \u003Cstrong>isolated perception\u003C/strong> into a specific step. Engineers have focused\non training systems to see where everything is located and assign objects properties like â€œthis is a car.â€ Supervised\nlearning is the most prevalent method, and some companies spend millions of dollars on labeling tens of millions of\nimages to train neural networks to make predictions consistent with said labels. This approach has several \u003Cstrong>severe\nlimitations\u003C/strong> , a critical one being the \u003Cstrong>need for an agreed-upon ontology of the world\u003C/strong> by which you label\ninformation. Even if we can somehow agree on an ontology, that ontology also needs to result in labels that carry enough\ninformation such that later stages of the pipeline can predict the future based on the labels. As it turns out, \u003Cstrong>humans\nare not good at describing\u003C/strong> \u003Cstrong>the world explicitly\u003C/strong> \u003Cstrong>in ways that allow predictions of the future\u003C/strong>. Whatever\nrepresentation we hack together leaves out too many relevant things. Most of the â€œdistillation of perceptionâ€ happens\nunconsciously. When we are forced to try and make it explicit we underestimate how much subtlety we take into account\nwhen viewing the world. Hinton has observed that:\u003C/p>\n\u003Cblockquote>\n\u003Cp>\u003Cem>The brain has about 10^14 synapses and we only live for about 10^9 seconds. So we have a lot more parameters than\ndata. This motivates the idea that we most do a lot of unsupervised learning since the perceptual input is the only\nplace we can get 10^5 dimensions of constraints per second.\u003C/em>\u003C/p>\n\u003C/blockquote>\n\u003Cp>The biological body is so complex and has 10,000 to 100,000 sensors distributed throughout that this alone makes every\nsingle millisecond of our lives a potentially unique experience. Combine that with the fact that we have on the order of\n100.000s or more muscle fiber units with a massive number of possible mechanical configurations. This means the brain is\ndesigned to handle unexpected events constantly. There is very little repetition if details are considered. Besides,\nthere is also the problem that the world is only partially observable and partially predictable. Even if we assume the\nworld is deterministic, there is still the issue that small perturbations of initial states of nonlinear systems can\ncause massive differences in later states. As a result, \u003Cstrong>whatever world model we create needs to be built around the\nassumption that almost nothing ever happens. At least not twice.\u003C/strong>\u003C/p>\n\u003Cp>\u003Cstrong>Every aspect of a robust world model needs to be learned from experience and interaction to solve this.\u003C/strong> Put\ndifferently, our world model must be a fully differentiable end-to-end model. The world model is optimized to allow the\nbest possible prediction of the future as measured by our ability to maximize some reward function. This would mean\nmerging the perception, prediction, and planning steps into an end-to-end differentiable model. When the development of\nautomated mobility took off about 15 years ago, this was impossible. As a result, a â€œdivide-and-conquerâ€ method was\napplied. Also, many people insist an explicit intermediate representation is required to validate systems. Thatâ€™s a poor\nexcuse not to pursue an end-to-end differentiable approach. There will always be ways to decode a latent model into\nsomething that can be inspected, and unit tests can be designed to test safety-critical aspects of the model.\u003C/p>\n\u003Ch3 id=\"a-possible-architecture-for-robust-embodied-ai\">A Possible Architecture for Robust Embodied AI\u003C/h3>\n\u003Cp>LeCun outlines an end-to-end approach in his position\npaper, â€œ\u003Ca href=\"https://openreview.net/pdf?id=BZ5a1r-kVsf\">A Path Towards Autonomous Machine Intelligence\u003C/a>. He proposes a\nfoundational architecture for achieving this form of efficient learning with six components: Configurator, Perception,\nWorld Model, Cost, Memory, and Actor.\u003C/p>\n\u003Cp>\u003Cimg src=\"https://storage.googleapis.com/langkilde-se-images/a50357bb-ad01-483a-b785-5a14ba186f41.jpeg\" alt=\"\">\u003C/p>\n\u003Cp>The idea is that a \u003Cstrong>Configurator\u003C/strong> interacts with all modules by modulating their parameters and attention circuits,\ni.e., priming them for a particular goal. The \u003Cstrong>Perception\u003C/strong> module receives signals from sensors and estimates the\ncurrent state of the world. Since only a small subset of the perceived state of the world is relevant and valuable, the\nconfigurator will prime the perception system to extract the relevant information from the percept for the task at hand.\nThe \u003Cstrong>World Model module then has two roles: (1) estimate the missing information about the state of the world not\nprovided by perception, (2) predict plausible future states of the world.\u003C/strong> This world model needs to be learned\nentirely, i.e., completely differentiable. It needs to consider both the untouched evolution of the world and future\nstates resulting from a sequence of actions proposed by the actor module. Predictions are performed within an abstract\nrepresentation space**** containing information relevant to the task. A key issue is that the world model needs to be\nable to represent multiple possible predictions of the world state. The natural world is only partially predictable.\nToday, it is not clear how to (1) allow a world model to make multiple plausible predictions and represent uncertainty\nin those predictions and (2) how to train a world model like this. The \u003Cstrong>Cost\u003C/strong> module measures the level of\nâ€œdiscomfortâ€ of the agent. There are probably two types of cost: \u003Cem>Intrinsic Cost\u003C/em> , i.e., hard-wired discomfort (think\npain, pleasure, hunger, etc.), and \u003Cem>Trainable Cost,\u003C/em> which predicts an estimate of future intrinsic energies. Both have\nsimilar purposes: to minimize the cost over the long run. The intrinsic cost determines the nature of the agentâ€™s\nbehavior. The \u003Cstrong>Memory\u003C/strong> module stores relevant information about the worldâ€™s past, current and future states. Other\nsystems can query and modify stored states and costs. The \u003Cstrong>Actor\u003C/strong> module computes proposals for sequences of actions\nand outputs actions to the effectors. The proposed sequence of actions is sent to the world model, which then predicts\nfuture world states from the action sequence and feeds it to the cost module. The actor may comprise two components: (1)\na policy module that directly produces an action from the world state estimate produced by the perception module and\nretrieved from short-term memory, and (2) the action optimizer described above. This would be similar\nto \u003Ca href=\"https://thedecisionlab.com/reference-guide/philosophy/system-1-and-system-2-thinking\">Kahnemanâ€™s â€œSystem 1â€ and â€œSystem 2â€\u003C/a>\nthinking. Hereâ€™s an example of a â€œSystem 2â€ thinking process based on this architecture:\u003C/p>\n\u003Col>\n\u003Cli>\n\u003Cp>\u003Cstrong>Perception:\u003C/strong> the perception system extracts a representation of the current state of the world. The cost module\ncomputes and stores the immediate cost associated with that state.\u003C/p>\n\u003C/li>\n\u003Cli>\n\u003Cp>\u003Cstrong>Actorâ€™s first proposal\u003C/strong> : the actor proposes an initial sequence of actions to be fed to the world model for\nevaluation.\u003C/p>\n\u003C/li>\n\u003Cli>\n\u003Cp>\u003Cstrong>World Model prediction\u003C/strong> : the world model predicts one or several likely sequences of world state representations\nresulting from the proposed action sequence.\u003C/p>\n\u003C/li>\n\u003Cli>\n\u003Cp>\u003Cstrong>Cost evaluation\u003C/strong> : the cost module estimates a total cost from the predicted state sequence, generally as a sum\nover time steps.\u003C/p>\n\u003C/li>\n\u003Cli>\n\u003Cp>\u003Cstrong>Actorâ€™s new proposal\u003C/strong> : the actor proposes a new action sequence with a lower cost. This can be done through a\ngradient-based procedure in which gradients of the cost are back-propagated through the compute graph to the action\nvariables. Complete optimization may require iterating steps 2-5.\u003C/p>\n\u003C/li>\n\u003Cli>\n\u003Cp>\u003Cstrong>Actor sends actions:\u003C/strong> after converging on a low-cost action sequence, the actor sends the first action (or first\nfew actions) in the low-cost sequence to the effectors. The entire process is repeated for the next perception-action\nepisode.\u003C/p>\n\u003C/li>\n\u003Cli>\n\u003Cp>\u003Cstrong>Memory\u003C/strong> : after every action, the states and associated costs from the intrinsic cost and the critic are stored in\nthe short-term memory. These pairs can be used later to train or adapt the critic.\u003C/p>\n\u003C/li>\n\u003C/ol>\n\u003Ch3 id=\"predictions-in-latent-spaces\">Predictions in Latent Spaces\u003C/h3>\n\u003Cp>LeCun is famous for his â€œcake analogy,â€ i.e., \u003Cem>â€œIf intelligence is a cake, the bulk of the cake is self-supervised\nlearning, the icing on the cake is supervised learning, and the cherry on the cake is reinforcement learning (RL).â€\u003C/em> The\nidea is that humans leverage capabilities such as predicting and reasoning to infer the future from available\ninformation. We do not just learn from explicit labels. â€œ \u003Cem>Prediction is the essence of intelligence\u003C/em>.â€\u003C/p>\n\u003Cp>The centerpiece of the architecture laid out by LeCun is the predictive world model. A challenge with constructing it is\nenabling it to represent multiple plausible predictions. The proposed \u003Cstrong>Joint Embedding Predictive Architecture (JEPA)\u003C/strong>\nis part of solving this. JEPA is\nan \u003Ca href=\"https://en.wikipedia.org/wiki/Energy_based_model#:~:text=An%20energy%2Dbased%20model%20(EBM,also%20match%20the%20data%20distribution.\">energy-based\u003C/a>\nself-supervised learning model that captures the dependencies between two given inputs, say \u003Cem>x\u003C/em> and \u003Cem>y\u003C/em>. The specific\nbenefit of this approach is that instead of predicting \u003Cem>y\u003C/em> from \u003Cem>x\u003C/em> directly, we are predicting the latent\nrepresentation of \u003Cem>y\u003C/em> that is most likely to follow \u003Cem>x\u003C/em>. This makes the approach different from generative AI models\nthat directly predict \u003Cem>y,\u003C/em> and it is what unlocks the ability to represent multiple plausible futures.\u003C/p>\n\u003Cp>\u003Cimg src=\"https://storage.googleapis.com/langkilde-se-images/4e57f718-1f4d-466e-9119-e54e21656dd8.jpeg\" alt=\"\">\u003C/p>\n\u003Cp>By predicting in \u003Cstrong>latent space,\u003C/strong> we can minimize the information content leveraged. This is desirable since the world\nis only partially predictable. A direct prediction of future data, e.g., frames in a long video sequence, would be\nenormously resource-consuming. Humans do not predict every â€œpixel,â€ i.e., every tree leaf, the exact texture of the\nfloor, or how clouds will move. Itâ€™s more realistic to assume that we predict some lower-content representation that\nignores certain irrelevant aspects of reality. This would be the world model. Four things are important to this\napproach:\u003C/p>\n\u003Cul>\n\u003Cli>\n\u003Cp>Make the representation of x maximally informative about x\u003C/p>\n\u003C/li>\n\u003Cli>\n\u003Cp>Make the representation of y maximally informative about y\u003C/p>\n\u003C/li>\n\u003Cli>\n\u003Cp>Make the representation of y maximally predictable from the representation of x\u003C/p>\n\u003C/li>\n\u003Cli>\n\u003Cp>Make the predictor use as little information as possible from the latent variable to represent uncertainty in the\nprediction.\u003C/p>\n\u003C/li>\n\u003C/ul>\n\u003Cp>LeCun has, for example,\nproposed \u003Ca href=\"https://arxiv.org/abs/2105.04906?fbclid=IwAR2jCTVpqrK8XCoQ1AXZue33NenZUoEhk7VVp6P8qpx4fpezuHvFV6jJUmg\">VICReg\u003C/a>\nas a method to do this.\u003C/p>\n\u003Cp>\u003Cimg src=\"https://storage.googleapis.com/langkilde-se-images/1afd2c38-0d73-4616-85ed-c45f487f5c49.jpeg\" alt=\"\">\u003C/p>\n\u003Ch3 id=\"latent-spaces-and-reward-functions\">Latent Spaces and Reward Functions\u003C/h3>\n\u003Cp>The future belongs to self-supervised methods that observe large quantities of recordings to derive the most informative\nlatent representations for some reward function that requires you to predict the future. This means:\u003C/p>\n\u003Cp>\u003Cstrong>The control problem is in the latent space interacting with the reward function.\u003C/strong> If we want to understand and\ncontrol a system, we must understand the connection between the embeddings and the predictions of the future those\nembeddings lead to. If we want to ensure a specific type of behavior in a specific situation, we must ensure that the\nreward function causes the desired decision for a particular learned representation. As of today, there are no such\nprogramming tools.\u003C/p>\n\u003Cp>They will inevitably be created.\u003C/p>",{"headings":351,"localImagePaths":367,"remoteImagePaths":368,"frontmatter":369,"imagePaths":370},[352,355,358,361,364],{"depth":24,"slug":353,"text":354},"learning-world-models","Learning World Models",{"depth":24,"slug":356,"text":357},"representing-reality","Representing Reality",{"depth":24,"slug":359,"text":360},"a-possible-architecture-for-robust-embodied-ai","A Possible Architecture for Robust Embodied AI",{"depth":24,"slug":362,"text":363},"predictions-in-latent-spaces","Predictions in Latent Spaces",{"depth":24,"slug":365,"text":366},"latent-spaces-and-reward-functions","Latent Spaces and Reward Functions",[],[],{"pubDate":344,"title":343},[],"learning-world-models-for-robust-ai.md","lets-start-a-vc-fund-and-make-money",{"id":372,"data":374,"body":377,"filePath":378,"digest":379,"rendered":380,"legacyId":412},{"title":375,"pubDate":376},"Let's start a VC fund and make money!","2024-01-02","A few days ago, I asked myself â€œ[Should you raise VC money](https://langkilde.se/post/2023-11-22-the-force-of-money)?â€\nMy conclusion was: Yes if you can imagine delivering 100x returns in 10 years. But itâ€™s not obvious why such a huge\noutcome is required. To understand a challenge that includes other people (which is most of them) I try to enter _their_\nmind and view the world from _their_ perspective. If I can figure out what _they want_ and how _they see the world_ ,\nitâ€™s much easier for me to, letâ€™s be honest, _get what I want_.\n\n### Building Our Imaginary VC Fund\n\n**So, letâ€™s start an imaginary venture capital fund and do some investing.** What do we need? Well, first of all, we\nneed money. We want to run a professional venture capital fund, so we will want to raise money from others, such as\npension funds and high net-worth individuals (HNWIs). They are known as Limited Partners (LPs) because they will assume\nboth a limited risk and consequently a limited share of potential profits. We call ourselves General Partners (GPs)\nsince we have full responsibility for our investments. To start a venture fund, we need to decide on the following\nthings:\n\n* **Fund start date:** Letâ€™s start Jan 1, 2025.\n\n* **Total committed capital:** This is our first one, so letâ€™s make it a tiny 20MSEK. We will check what the impact of\n  size is later. But this will be a pre-seed fund, so we start small.\n\n* **General Partner commitment:** Make it 10%, or 2MSEK. Iâ€™m feeling lucky.\n\n* **Fees and Expenses:** 2% annually of committed LP capital is a pretty normal rate.\n\n* **Waterfall type:** Letâ€™s do it the American way with â€œdeal by deal carryâ€. This means we will get a % of returns once\n  LP returns exceed some multiple. Like 20% beyond 1x returns, or similar. The European way would be to base it on all\n  deals, rather than deal by deal. There are many possible quirks here, like LP Preferred returns, GP Catch-up, etc.\n  Letâ€™s investigate this more later.\n\n* **Exit recycling:** This means â€œCan you re-invest proceeds from exits during the fund period?â€ Letâ€™s make the math\n  simpler and just say no. Once a company sells, that money is done.\n\nThere can be more exotic configurations but these are the important basics. Now, the hard part begins. How do we plan to\nallocate this money?\n\n### Setting Investment Assumptions\n\nWe have to make assumptions about round sizes, valuations, graduation probabilities, and exit\nvaluations. To mock our venture fund, Iâ€™ve used a tool called [Tactyc](https://tactyc.io). We will need to configure:\n\n1. **Round Size:** The size of the round.\n\n2. **Valuation:** Pre or Post-Money Valuation.\n\n3. **Valuation (SEK):** Valuation in amount.\n\n4. **ESOP(%):** Minimum amount of total employee stock options as a percentage of fully diluted shares outstanding at\n   the end of this round.\n\n5. **Graduation Rate:** Likelihood of graduation _from_ this stage to the next stage.\n\n6. **Exit Rate:** Likelihood of exiting _at this stage._\n\n7. **Failure Rate:** Calculated automatically as 100% - graduation rate - exit rate.\n\n8. **Exit Valuation:** Average value of a company that is exiting at this stage.\n\n9. **Months to Graduate:** How many months will it take for a company to graduate from this stage?\n\n10. **Months to Exit:** _If a company is exiting at this stage,_ how many months will it take for a company to exit\n    after it enters this stage?\n\nIt is in this list of variables that the future of our little venture fund is hidden. Depending on how we configure\nthese variables, we get wildly different outcomes. Letâ€™s create our first set of assumptions:\n\n![](https://storage.googleapis.com/langkilde-se-images/46297486-56ea-43ef-a0ac-4d2075c3f377.jpeg)\n\n**In this example, we dream big.** At the last stage, we assume a 10BSEK ($1B) valuation at IPO. Spotify IPOed at ~$29B.\nKlarna has yet to IPO but is worth maybe $10B. iZettle was acquired for ~$2.2B. Tink was acquired for â‚¬1.8B. There are a\nfew more Swedish examples in the last 10 years, but they are rare. On the Swedish Large Cap list there are 155 companies\nworth between 8 BSEK (Intrum) and 2100 BSEK (AstraZeneca). Spotify would be in the top 20, around the same value as H&M.\nMost major companies in Sweden have been around for a long, long time.\n\n**Letâ€™s assume we write 250kSEK ($25k) pre-seed round checks from our fund at a post-money valuation of 10MSEK, giving\nus 2.5% equity.** Thatâ€™s a very small, first check but with low dilution. I could imagine taking such a check to explore\nan idea, and if the idea shows promise, then raise a larger seed round of 5MSEK at a 20MSEK (25% dilution) valuation to\nput together a team and get the first version of the product launched. If the product gets traction and shows promising\nmetrics, you would target a 50MSEK Series A at 200 MSEK (25% dilution). We expect 50% of our pre-seed checks to be\ncomplete write-offs (i.e. company never returns any money). The other 50% are expected to graduate to a seed round\nwithin 12 months. For simplicity, we assume a constant 50% graduation rate per stage. Letâ€™s assume we reserve 50% for\nfollow-on investments, putting 500kSEK into the seed round and another 1MSEK into Series A. That way, we can â€œdouble\ndownâ€ on the companies that turn out to be most promising. Ultimately, we will see that what matters the most is the\npossible exit valuation in the case of a homerun.\n\n![](https://storage.googleapis.com/langkilde-se-images/0b5dd75a-afe2-4a40-888d-5ec925d96692.jpeg)\n\n### Allocation and Outcomes\n\nSo, in summary, weâ€™d make 32 pre-seed investments, 8 follow-on seed investments and 4 follow-on Series A investments.\n\n![](https://storage.googleapis.com/langkilde-se-images/5b5b8ddb-4297-4cb9-96b5-457a82121e33.jpeg)\n\nDue to management fees and expenses, we have 16.1 MSEK in investable capital. Regardless of performance, we as GPs, will\nget our 3.6 MSEK in fees.\n\n**So, how would our fund do?** If we in fact delivered on these assumptions, weâ€™d have a very successful fund. If we\nachieved the valuations, graduation probabilities, and exit probabilities assumed, we would provide 62.3 MSEK in net\nproceeds to LPs, and we would distribute 4.46x what LPs paid in. But, note that itâ€™d take a **long** time. We plan to\nstart Jan 1, 2025, and still LPs will not break even until mid-2035.\n\n![](https://storage.googleapis.com/langkilde-se-images/e2faba98-2096-4f71-bb14-1547d56c5a9e.jpeg)\n\n![](https://storage.googleapis.com/langkilde-se-images/2d4ddf60-19f4-4a8e-9c34-35d3eea93643.jpeg)\n\n### The Power Law of Venture Capital\n\n**Where would our proceeds come from?** Letâ€™s take a look.\n\n![](https://storage.googleapis.com/langkilde-se-images/54c1fee6-7bdf-443c-b01a-daf956436076.jpeg)\n\n**This is known as â€œthe power law of venture capitalâ€.** We expect 2 exits from 32 pre-seed investments and the vast\nmajority of proceeds is from the 0.5 companies that survive to a post-Series E exit at 10BSEK. 94% of our investments\nwill return \u003C1x. It turns out that increasing the probability of graduating or exiting at earlier rounds, does not make\nup for a homerun outcome. It also turns out you have to move fast for the math to work. If we increase the time\ncompanies spend in each round, the time to reach that glorious 10BSEK exit increases. If we double the time per stage\nfrom 24 to 48 months, then our net IRR drops down to ~11%. Nasdaq 100 has historically given you ~10% annual return,\nwith a much, much lower variance. So, if you canâ€™t get**huge fast,** you wonâ€™t provide a very compelling investing\nopportunity for VCs. The best of the best, like Sequoia, have historically been providing 20%+ net IRR on funds. Thatâ€™s\nwhat makes you a Tier 1 VC. LPs will throw money at you if you can show that sort of performance consistently.\n\n### What VCs Look for in Companies\n\n**The most money-making VCs tell me they are looking for the T2D3** , i.e. the triple, triple, double, double, double in\nrevenue. If a founder has a credible plan to deliver a T2D3 5-year sprint, they have a much better chance at being a\ngood fit for a VC than almost everyone else. Most companies are not close to this. You need to be able to go\nfrom $1M to $10M ARR fast, and then keep going. The best public SaaS companies are still growing 50% even though they\npassed $200-300M ARR. Meritech has a great comparison\ntable [on the site](https://www.meritechcapital.com/benchmarking/comps-table). If we sort by EV / Implied ARR we see\nwhat it takes to get a 10x plus valuation. Hint: A lot.\n\n![](https://storage.googleapis.com/langkilde-se-images/58ec3f79-d683-4ea1-a771-1275c8d6c816.jpeg)\n\nSince VCs want to add your company to the top of this list, they will look for extraordinary numbers. Thatâ€™s because\nthey know things inevitably slow down. You have to show something like:\n\n* **$1m-$5m ARR:** 300%+\n\n* **$5m-$15m ARR:** 200%+\n\n* **$15m-$30m ARR:** 150%+\n\n* **$50m ARR:** 80%+\n\n* **$100m ARR:** 50%+\n\nYou can derive these numbers by working your way backward from the imaginary exit. Battery Venture recently released a\nreport that indicates what sort of metrics they are looking for (they set the bar even higher than I did above):\n\n![](https://storage.googleapis.com/langkilde-se-images/fa5dfc2e-a244-4849-b863-a0a3dc129b35.jpeg)\n\nTo imagine an â€œunlimited upsideâ€ on a â€œventure timelineâ€ VCs will want to see very strong growth. They need such an\nextraordinary outcome every 20-40 investments, and the best way to make it happen is to only bet on companies that have\na good chance of making it. If itâ€™s clear from the start that the goal is not to reach $1B+ they will turn you down no\nmatter how good you are. A high chance of a medium outcome does not fit with the fund structure of a VC.\n\n### Why is Venture Capital So Difficult?\n\nThe combination of **low liquidity** (i.e. once you invest in a startup your money is locked up for a long time), **low\nprobability of survival** (most startups blow up for one reason or another), **the startup valley of death** (the period\nafter launch until you find product-sales-fit), **random macro-economic circumstances (** high-interest rates, wars, and\npandemics), **unexpected technology disruptions** (LLMs) and many other things make the outcome outlined above very hard\nto achieve. And even then, itâ€™s not _that_ much more effective than just putting your money in the Nasdaq index.\n\n### Why Are Some Funds Successful?\n\nWell, some of it is luck. They may or may not admit it, but you only need to get lucky once in a while to get that\nsuper-high-performance outcome. That can then fuel your funds for years. It will boost your reputation which gives you\nbetter investment opportunities, and it will make it easier to raise money from LPs. This is known as the â€œThe Virtuous\nCycleâ€, and it applies to entrepreneurs as well. I wrote about\nthis [in the past](https://langkilde.se/post/2023-02-27-breakthroughness-and-the-virtuous-cycle):\n\n> It turns out one of the statistically most important advantages you can have is being a â€œsecond-time founder.â€\n> Entrepreneurs with experience in scaling a business, even to a modest size, are significantly more likely to start a\n> billion-dollar business. The book argues that a large part of this advantage is a result of preferential access.\n> Second-time founders already have a network of potential early-stage employees, investors, and advisors to lean on.\n> Thatâ€™s a game changer for a nascent company. Another conclusion in the book is that successful founders usually have\n> been creating organizations and networks from a very early age. That likely contributes to an accumulated network. Of\n> course, there are lots of other traits that improve your odds, too, like: intelligence, adaptability, vision, risk\n> tolerance, and operational efficiency.\n\n**All of the above is true for great VCs as well.** Having raised and deployed a fund that delivered great returns to\nLPs significantly increases the probability that you will do it again.\n\n### Conclusions and Reflections\n\n**So, what are my conclusions?** Well, I guess I sympathize more with VCs now. I understand why they are so picky. I\nwould be picky too, now that I know the math behind it. To fit into a top-performing venture capital fundâ€™s portfolio\nyou need to:\n\n* Have a plan that makes your company worth $1B+ within 10 years (fast)\n\n* Aim for a $10B market capitalization eventually (unlimited upside)\n\nAnd thatâ€™s besides also having great credentials, impressing them as a person, having a great team, etc. Letâ€™s just say\nthe bar is pretty high. Personally, I think it sounds like an awesome challenge. But Iâ€™m starting to realize most\nfounders I meet have no fucking clue what they are getting into. I had no idea what I was doing 6-7 years ago. And I\nsuspect many of the angel investors and seed investors I meet also have no fucking clue what they are doing. Or they do,\nbut they donâ€™t care about money. Investing can also be a fun way to meet interesting people. But so is throwing a dinner\nparty, and the latter is cheaper.\n\nAnyway, hope this was useful to someone. The more we learn, the more we win.","src/content/blog/let's-start-a-vc-fund-and-make-money.md","9c6684ec3a6cd7b5",{"html":381,"metadata":382},"\u003Cp>A few days ago, I asked myself â€œ\u003Ca href=\"https://langkilde.se/post/2023-11-22-the-force-of-money\">Should you raise VC money\u003C/a>?â€\nMy conclusion was: Yes if you can imagine delivering 100x returns in 10 years. But itâ€™s not obvious why such a huge\noutcome is required. To understand a challenge that includes other people (which is most of them) I try to enter \u003Cem>their\u003C/em>\nmind and view the world from \u003Cem>their\u003C/em> perspective. If I can figure out what \u003Cem>they want\u003C/em> and how \u003Cem>they see the world\u003C/em> ,\nitâ€™s much easier for me to, letâ€™s be honest, \u003Cem>get what I want\u003C/em>.\u003C/p>\n\u003Ch3 id=\"building-our-imaginary-vc-fund\">Building Our Imaginary VC Fund\u003C/h3>\n\u003Cp>\u003Cstrong>So, letâ€™s start an imaginary venture capital fund and do some investing.\u003C/strong> What do we need? Well, first of all, we\nneed money. We want to run a professional venture capital fund, so we will want to raise money from others, such as\npension funds and high net-worth individuals (HNWIs). They are known as Limited Partners (LPs) because they will assume\nboth a limited risk and consequently a limited share of potential profits. We call ourselves General Partners (GPs)\nsince we have full responsibility for our investments. To start a venture fund, we need to decide on the following\nthings:\u003C/p>\n\u003Cul>\n\u003Cli>\n\u003Cp>\u003Cstrong>Fund start date:\u003C/strong> Letâ€™s start Jan 1, 2025.\u003C/p>\n\u003C/li>\n\u003Cli>\n\u003Cp>\u003Cstrong>Total committed capital:\u003C/strong> This is our first one, so letâ€™s make it a tiny 20MSEK. We will check what the impact of\nsize is later. But this will be a pre-seed fund, so we start small.\u003C/p>\n\u003C/li>\n\u003Cli>\n\u003Cp>\u003Cstrong>General Partner commitment:\u003C/strong> Make it 10%, or 2MSEK. Iâ€™m feeling lucky.\u003C/p>\n\u003C/li>\n\u003Cli>\n\u003Cp>\u003Cstrong>Fees and Expenses:\u003C/strong> 2% annually of committed LP capital is a pretty normal rate.\u003C/p>\n\u003C/li>\n\u003Cli>\n\u003Cp>\u003Cstrong>Waterfall type:\u003C/strong> Letâ€™s do it the American way with â€œdeal by deal carryâ€. This means we will get a % of returns once\nLP returns exceed some multiple. Like 20% beyond 1x returns, or similar. The European way would be to base it on all\ndeals, rather than deal by deal. There are many possible quirks here, like LP Preferred returns, GP Catch-up, etc.\nLetâ€™s investigate this more later.\u003C/p>\n\u003C/li>\n\u003Cli>\n\u003Cp>\u003Cstrong>Exit recycling:\u003C/strong> This means â€œCan you re-invest proceeds from exits during the fund period?â€ Letâ€™s make the math\nsimpler and just say no. Once a company sells, that money is done.\u003C/p>\n\u003C/li>\n\u003C/ul>\n\u003Cp>There can be more exotic configurations but these are the important basics. Now, the hard part begins. How do we plan to\nallocate this money?\u003C/p>\n\u003Ch3 id=\"setting-investment-assumptions\">Setting Investment Assumptions\u003C/h3>\n\u003Cp>We have to make assumptions about round sizes, valuations, graduation probabilities, and exit\nvaluations. To mock our venture fund, Iâ€™ve used a tool called \u003Ca href=\"https://tactyc.io\">Tactyc\u003C/a>. We will need to configure:\u003C/p>\n\u003Col>\n\u003Cli>\n\u003Cp>\u003Cstrong>Round Size:\u003C/strong> The size of the round.\u003C/p>\n\u003C/li>\n\u003Cli>\n\u003Cp>\u003Cstrong>Valuation:\u003C/strong> Pre or Post-Money Valuation.\u003C/p>\n\u003C/li>\n\u003Cli>\n\u003Cp>\u003Cstrong>Valuation (SEK):\u003C/strong> Valuation in amount.\u003C/p>\n\u003C/li>\n\u003Cli>\n\u003Cp>\u003Cstrong>ESOP(%):\u003C/strong> Minimum amount of total employee stock options as a percentage of fully diluted shares outstanding at\nthe end of this round.\u003C/p>\n\u003C/li>\n\u003Cli>\n\u003Cp>\u003Cstrong>Graduation Rate:\u003C/strong> Likelihood of graduation \u003Cem>from\u003C/em> this stage to the next stage.\u003C/p>\n\u003C/li>\n\u003Cli>\n\u003Cp>\u003Cstrong>Exit Rate:\u003C/strong> Likelihood of exiting \u003Cem>at this stage.\u003C/em>\u003C/p>\n\u003C/li>\n\u003Cli>\n\u003Cp>\u003Cstrong>Failure Rate:\u003C/strong> Calculated automatically as 100% - graduation rate - exit rate.\u003C/p>\n\u003C/li>\n\u003Cli>\n\u003Cp>\u003Cstrong>Exit Valuation:\u003C/strong> Average value of a company that is exiting at this stage.\u003C/p>\n\u003C/li>\n\u003Cli>\n\u003Cp>\u003Cstrong>Months to Graduate:\u003C/strong> How many months will it take for a company to graduate from this stage?\u003C/p>\n\u003C/li>\n\u003Cli>\n\u003Cp>\u003Cstrong>Months to Exit:\u003C/strong> \u003Cem>If a company is exiting at this stage,\u003C/em> how many months will it take for a company to exit\nafter it enters this stage?\u003C/p>\n\u003C/li>\n\u003C/ol>\n\u003Cp>It is in this list of variables that the future of our little venture fund is hidden. Depending on how we configure\nthese variables, we get wildly different outcomes. Letâ€™s create our first set of assumptions:\u003C/p>\n\u003Cp>\u003Cimg src=\"https://storage.googleapis.com/langkilde-se-images/46297486-56ea-43ef-a0ac-4d2075c3f377.jpeg\" alt=\"\">\u003C/p>\n\u003Cp>\u003Cstrong>In this example, we dream big.\u003C/strong> At the last stage, we assume a 10BSEK ($1B) valuation at IPO. Spotify IPOed at ~$29B.\nKlarna has yet to IPO but is worth maybe $10B. iZettle was acquired for ~$2.2B. Tink was acquired for â‚¬1.8B. There are a\nfew more Swedish examples in the last 10 years, but they are rare. On the Swedish Large Cap list there are 155 companies\nworth between 8 BSEK (Intrum) and 2100 BSEK (AstraZeneca). Spotify would be in the top 20, around the same value as H&#x26;M.\nMost major companies in Sweden have been around for a long, long time.\u003C/p>\n\u003Cp>\u003Cstrong>Letâ€™s assume we write 250kSEK ($25k) pre-seed round checks from our fund at a post-money valuation of 10MSEK, giving\nus 2.5% equity.\u003C/strong> Thatâ€™s a very small, first check but with low dilution. I could imagine taking such a check to explore\nan idea, and if the idea shows promise, then raise a larger seed round of 5MSEK at a 20MSEK (25% dilution) valuation to\nput together a team and get the first version of the product launched. If the product gets traction and shows promising\nmetrics, you would target a 50MSEK Series A at 200 MSEK (25% dilution). We expect 50% of our pre-seed checks to be\ncomplete write-offs (i.e. company never returns any money). The other 50% are expected to graduate to a seed round\nwithin 12 months. For simplicity, we assume a constant 50% graduation rate per stage. Letâ€™s assume we reserve 50% for\nfollow-on investments, putting 500kSEK into the seed round and another 1MSEK into Series A. That way, we can â€œdouble\ndownâ€ on the companies that turn out to be most promising. Ultimately, we will see that what matters the most is the\npossible exit valuation in the case of a homerun.\u003C/p>\n\u003Cp>\u003Cimg src=\"https://storage.googleapis.com/langkilde-se-images/0b5dd75a-afe2-4a40-888d-5ec925d96692.jpeg\" alt=\"\">\u003C/p>\n\u003Ch3 id=\"allocation-and-outcomes\">Allocation and Outcomes\u003C/h3>\n\u003Cp>So, in summary, weâ€™d make 32 pre-seed investments, 8 follow-on seed investments and 4 follow-on Series A investments.\u003C/p>\n\u003Cp>\u003Cimg src=\"https://storage.googleapis.com/langkilde-se-images/5b5b8ddb-4297-4cb9-96b5-457a82121e33.jpeg\" alt=\"\">\u003C/p>\n\u003Cp>Due to management fees and expenses, we have 16.1 MSEK in investable capital. Regardless of performance, we as GPs, will\nget our 3.6 MSEK in fees.\u003C/p>\n\u003Cp>\u003Cstrong>So, how would our fund do?\u003C/strong> If we in fact delivered on these assumptions, weâ€™d have a very successful fund. If we\nachieved the valuations, graduation probabilities, and exit probabilities assumed, we would provide 62.3 MSEK in net\nproceeds to LPs, and we would distribute 4.46x what LPs paid in. But, note that itâ€™d take a \u003Cstrong>long\u003C/strong> time. We plan to\nstart Jan 1, 2025, and still LPs will not break even until mid-2035.\u003C/p>\n\u003Cp>\u003Cimg src=\"https://storage.googleapis.com/langkilde-se-images/e2faba98-2096-4f71-bb14-1547d56c5a9e.jpeg\" alt=\"\">\u003C/p>\n\u003Cp>\u003Cimg src=\"https://storage.googleapis.com/langkilde-se-images/2d4ddf60-19f4-4a8e-9c34-35d3eea93643.jpeg\" alt=\"\">\u003C/p>\n\u003Ch3 id=\"the-power-law-of-venture-capital\">The Power Law of Venture Capital\u003C/h3>\n\u003Cp>\u003Cstrong>Where would our proceeds come from?\u003C/strong> Letâ€™s take a look.\u003C/p>\n\u003Cp>\u003Cimg src=\"https://storage.googleapis.com/langkilde-se-images/54c1fee6-7bdf-443c-b01a-daf956436076.jpeg\" alt=\"\">\u003C/p>\n\u003Cp>\u003Cstrong>This is known as â€œthe power law of venture capitalâ€.\u003C/strong> We expect 2 exits from 32 pre-seed investments and the vast\nmajority of proceeds is from the 0.5 companies that survive to a post-Series E exit at 10BSEK. 94% of our investments\nwill return &#x3C;1x. It turns out that increasing the probability of graduating or exiting at earlier rounds, does not make\nup for a homerun outcome. It also turns out you have to move fast for the math to work. If we increase the time\ncompanies spend in each round, the time to reach that glorious 10BSEK exit increases. If we double the time per stage\nfrom 24 to 48 months, then our net IRR drops down to ~11%. Nasdaq 100 has historically given you ~10% annual return,\nwith a much, much lower variance. So, if you canâ€™t get\u003Cstrong>huge fast,\u003C/strong> you wonâ€™t provide a very compelling investing\nopportunity for VCs. The best of the best, like Sequoia, have historically been providing 20%+ net IRR on funds. Thatâ€™s\nwhat makes you a Tier 1 VC. LPs will throw money at you if you can show that sort of performance consistently.\u003C/p>\n\u003Ch3 id=\"what-vcs-look-for-in-companies\">What VCs Look for in Companies\u003C/h3>\n\u003Cp>\u003Cstrong>The most money-making VCs tell me they are looking for the T2D3\u003C/strong> , i.e. the triple, triple, double, double, double in\nrevenue. If a founder has a credible plan to deliver a T2D3 5-year sprint, they have a much better chance at being a\ngood fit for a VC than almost everyone else. Most companies are not close to this. You need to be able to go\nfrom $1M to $10M ARR fast, and then keep going. The best public SaaS companies are still growing 50% even though they\npassed $200-300M ARR. Meritech has a great comparison\ntable \u003Ca href=\"https://www.meritechcapital.com/benchmarking/comps-table\">on the site\u003C/a>. If we sort by EV / Implied ARR we see\nwhat it takes to get a 10x plus valuation. Hint: A lot.\u003C/p>\n\u003Cp>\u003Cimg src=\"https://storage.googleapis.com/langkilde-se-images/58ec3f79-d683-4ea1-a771-1275c8d6c816.jpeg\" alt=\"\">\u003C/p>\n\u003Cp>Since VCs want to add your company to the top of this list, they will look for extraordinary numbers. Thatâ€™s because\nthey know things inevitably slow down. You have to show something like:\u003C/p>\n\u003Cul>\n\u003Cli>\n\u003Cp>\u003Cstrong>$1m-$5m ARR:\u003C/strong> 300%+\u003C/p>\n\u003C/li>\n\u003Cli>\n\u003Cp>\u003Cstrong>$5m-$15m ARR:\u003C/strong> 200%+\u003C/p>\n\u003C/li>\n\u003Cli>\n\u003Cp>\u003Cstrong>$15m-$30m ARR:\u003C/strong> 150%+\u003C/p>\n\u003C/li>\n\u003Cli>\n\u003Cp>\u003Cstrong>$50m ARR:\u003C/strong> 80%+\u003C/p>\n\u003C/li>\n\u003Cli>\n\u003Cp>\u003Cstrong>$100m ARR:\u003C/strong> 50%+\u003C/p>\n\u003C/li>\n\u003C/ul>\n\u003Cp>You can derive these numbers by working your way backward from the imaginary exit. Battery Venture recently released a\nreport that indicates what sort of metrics they are looking for (they set the bar even higher than I did above):\u003C/p>\n\u003Cp>\u003Cimg src=\"https://storage.googleapis.com/langkilde-se-images/fa5dfc2e-a244-4849-b863-a0a3dc129b35.jpeg\" alt=\"\">\u003C/p>\n\u003Cp>To imagine an â€œunlimited upsideâ€ on a â€œventure timelineâ€ VCs will want to see very strong growth. They need such an\nextraordinary outcome every 20-40 investments, and the best way to make it happen is to only bet on companies that have\na good chance of making it. If itâ€™s clear from the start that the goal is not to reach $1B+ they will turn you down no\nmatter how good you are. A high chance of a medium outcome does not fit with the fund structure of a VC.\u003C/p>\n\u003Ch3 id=\"why-is-venture-capital-so-difficult\">Why is Venture Capital So Difficult?\u003C/h3>\n\u003Cp>The combination of \u003Cstrong>low liquidity\u003C/strong> (i.e. once you invest in a startup your money is locked up for a long time), \u003Cstrong>low\nprobability of survival\u003C/strong> (most startups blow up for one reason or another), \u003Cstrong>the startup valley of death\u003C/strong> (the period\nafter launch until you find product-sales-fit), \u003Cstrong>random macro-economic circumstances (\u003C/strong> high-interest rates, wars, and\npandemics), \u003Cstrong>unexpected technology disruptions\u003C/strong> (LLMs) and many other things make the outcome outlined above very hard\nto achieve. And even then, itâ€™s not \u003Cem>that\u003C/em> much more effective than just putting your money in the Nasdaq index.\u003C/p>\n\u003Ch3 id=\"why-are-some-funds-successful\">Why Are Some Funds Successful?\u003C/h3>\n\u003Cp>Well, some of it is luck. They may or may not admit it, but you only need to get lucky once in a while to get that\nsuper-high-performance outcome. That can then fuel your funds for years. It will boost your reputation which gives you\nbetter investment opportunities, and it will make it easier to raise money from LPs. This is known as the â€œThe Virtuous\nCycleâ€, and it applies to entrepreneurs as well. I wrote about\nthis \u003Ca href=\"https://langkilde.se/post/2023-02-27-breakthroughness-and-the-virtuous-cycle\">in the past\u003C/a>:\u003C/p>\n\u003Cblockquote>\n\u003Cp>It turns out one of the statistically most important advantages you can have is being a â€œsecond-time founder.â€\nEntrepreneurs with experience in scaling a business, even to a modest size, are significantly more likely to start a\nbillion-dollar business. The book argues that a large part of this advantage is a result of preferential access.\nSecond-time founders already have a network of potential early-stage employees, investors, and advisors to lean on.\nThatâ€™s a game changer for a nascent company. Another conclusion in the book is that successful founders usually have\nbeen creating organizations and networks from a very early age. That likely contributes to an accumulated network. Of\ncourse, there are lots of other traits that improve your odds, too, like: intelligence, adaptability, vision, risk\ntolerance, and operational efficiency.\u003C/p>\n\u003C/blockquote>\n\u003Cp>\u003Cstrong>All of the above is true for great VCs as well.\u003C/strong> Having raised and deployed a fund that delivered great returns to\nLPs significantly increases the probability that you will do it again.\u003C/p>\n\u003Ch3 id=\"conclusions-and-reflections\">Conclusions and Reflections\u003C/h3>\n\u003Cp>\u003Cstrong>So, what are my conclusions?\u003C/strong> Well, I guess I sympathize more with VCs now. I understand why they are so picky. I\nwould be picky too, now that I know the math behind it. To fit into a top-performing venture capital fundâ€™s portfolio\nyou need to:\u003C/p>\n\u003Cul>\n\u003Cli>\n\u003Cp>Have a plan that makes your company worth $1B+ within 10 years (fast)\u003C/p>\n\u003C/li>\n\u003Cli>\n\u003Cp>Aim for a $10B market capitalization eventually (unlimited upside)\u003C/p>\n\u003C/li>\n\u003C/ul>\n\u003Cp>And thatâ€™s besides also having great credentials, impressing them as a person, having a great team, etc. Letâ€™s just say\nthe bar is pretty high. Personally, I think it sounds like an awesome challenge. But Iâ€™m starting to realize most\nfounders I meet have no fucking clue what they are getting into. I had no idea what I was doing 6-7 years ago. And I\nsuspect many of the angel investors and seed investors I meet also have no fucking clue what they are doing. Or they do,\nbut they donâ€™t care about money. Investing can also be a fun way to meet interesting people. But so is throwing a dinner\nparty, and the latter is cheaper.\u003C/p>\n\u003Cp>Anyway, hope this was useful to someone. The more we learn, the more we win.\u003C/p>",{"headings":383,"localImagePaths":408,"remoteImagePaths":409,"frontmatter":410,"imagePaths":411},[384,387,390,393,396,399,402,405],{"depth":24,"slug":385,"text":386},"building-our-imaginary-vc-fund","Building Our Imaginary VC Fund",{"depth":24,"slug":388,"text":389},"setting-investment-assumptions","Setting Investment Assumptions",{"depth":24,"slug":391,"text":392},"allocation-and-outcomes","Allocation and Outcomes",{"depth":24,"slug":394,"text":395},"the-power-law-of-venture-capital","The Power Law of Venture Capital",{"depth":24,"slug":397,"text":398},"what-vcs-look-for-in-companies","What VCs Look for in Companies",{"depth":24,"slug":400,"text":401},"why-is-venture-capital-so-difficult","Why is Venture Capital So Difficult?",{"depth":24,"slug":403,"text":404},"why-are-some-funds-successful","Why Are Some Funds Successful?",{"depth":24,"slug":406,"text":407},"conclusions-and-reflections","Conclusions and Reflections",[],[],{"pubDate":376,"title":375},[],"let's-start-a-vc-fund-and-make-money.md","management-under-uncertainty",{"id":413,"data":415,"body":418,"filePath":419,"digest":420,"rendered":421,"legacyId":441},{"title":416,"pubDate":417},"Management Under Uncertainty","2021-01-12","We live in a high-pressure world. This is true both in a macro and micro sense. Countries and companies are faced with\never-faster shifts in technology and public opinion. Work is getting more and more creative, and less and less\nwell-defined. Most predictable work is automated as soon as there is enough data.\n\nWhat is then the long-term defensible competitive advantage in such an environment? **Constantly adapting to new,\ncomplex situations.** This is true as much on a personal level, as on an organizational level.\n\n### Stability vs. Uncertainty\n\nThe automotive industry for most of its existence has been the epitome of rational efficiency. Everything is optimized,\nprice pressured, planned, and predicted. And due to the sheer size of the market, and capital expenditure required, it\nhas been a generally stable environment. There has been a limited pressure to reinvent yourself.\n\nOne consequence of this stability is a comparatively low spend on R&D. I think there is a strong link between the\npredictability of a domain, and the propensity to spend on R&D. Pharmaceutical companies for example are designed to\ndeal with uncertainty and risk. Their main activity is triaging potential drugs, evaluating them in a sequence of\nincreasingly large trials, and then proving their efficacy through statistics. This is a high-risk, high-reward way of\nworking that requires state-of-the-art research and a very dynamic mindset. Imagine if an automotive company had ten\nmodels in its product development pipeline, expecting only one or two to make it to the market?\n\nAs can be seen from the table below, automotive companies spend 3-8% of their revenue on R&D. Most of their activities\nare related to the manufacturing and distribution of vehicles, not the development of novel technologies. Pharma on the\nother hand spends 17-25%.\n\nAt the top of the list in absolute spending is a former book store. Who could have imagined 20 years ago that the\nworldâ€™s biggest spender on research would be a retail company?\n\n![](https://storage.googleapis.com/langkilde-se-images/5a0c9298-4074-43e5-8687-850b6d57c535.jpeg)\n\nOne consequence of the perceived stability in automotive has been that most vehicle production projects are planned in\nminute detail. Automotive companies love planning. There is a â€œStart of Productionâ€ date that engineers and managers\nlive by. All activities need to be time-boxed and put in a sequence all the way up to the SoP. Thousands of engineerings\nand hundreds of companies need to deliver according to plan, or the vehicle will be delayed.\n\nAs you might have noticed, Tesla (mostly) does not follow the traditional model year tradition. The value of a Tesla is\ndetermined by its features, not the date it was manufactured. With hardware and software updates being released\ncontinuously, the manufacturing year is not significant other than as a proxy for wear and tear.\n\nItâ€™s much more demanding to operate in an environment where everything is uncertain. Uncertainty is not, by the way, the\nsame as â€œdisorderâ€. You can work in a very structured way with plenty of uncertainty.\n\n### Three Forces that Push Toward Detailed Planning\n\nAs a founder, I understand more and more why a completely incremental approach is so hard to maintain. There are three\nforces that contribute to a tendency towards detailed planning.\n\n**Budgets and capital expenditure.** Companies by definition only fail for one reason: they run out of money. It takes\ncourage and deep pockets to deal with risky and expensive product development. Chances are it takes much longer than\nexpected, and the risk is that you run out of cash. But thatâ€™s also why innovation is rewarded by the market. Profit is\nthe reward for risk-taking.\n\n**Fear of failure.** Fear is the [mind-killer](https://dune.fandom.com/wiki/Litany_Against_Fear). Humans are programmed\nto avoid discomfort and danger. Itâ€™s deeply rooted in our subconscious. The deeper your fear of failing, the lower the\nprobability that you will create something truly unique and great. Organizations can easily end up preventing all\npossible negative outcomes and thereby completely eliminating any chance of novel thinking. (Of course, the ability to\ntake risks in life is also determined by other things, like the safety net of your country, social class, etc.)\n\n**Intellectual Laziness.** High-performing people are typically explorers. But most people are, by definition, average.\nThe average person doesnâ€™t want to go to work every day without knowing what to expect. If they have to do that, they\nwill get exhausted and complain. A lot. So organizations, as they grow, slowly adapt to comfort those seeking\npredictability. I try and avoid hiring people who seek â€œan easy jobâ€.\n\nIronically the risks associated with systematically avoiding risks are larger than suffering the occasional negative\nexperience. Personally, I think this is what causes larger companies to lose their edge. The challenge of navigating the\nrisk-reward nexus can be found all the way from starting a company, to funding it, to setting the vision and scope for\nthe company and maintaining its edge as it grows. Itâ€™s really hard to think really big. It takes a tremendous amount of\ncourage and a gigantic risk appetite. You have to be comfortable with the risk of failure.\n\n### How to Run a Company Amidst Uncertainty\n\nSo, what to do then? How do you run a company when you have no idea what to expect?\n\n**Empower your team**\n\nHire amazing people and give them the resources and the mandate to solve hard problems. Put everyone close to the issue\nthey are solving. Allow everyone to talk to each other without being forced to go through layers of management. My\nmentor has always told me: â€œ _smart people with the same information and the same goals usually come to the same\nconclusion. You just need to ensure they have the same information and the same goals.â€_ I firmly believe in this.\n\nIt takes a lot of patience and trust to let your team solve audacious problems without detailed supervision. But it\nusually pays off fairly quickly.\n\n**Strive for greatness**\n\nFreedom is powerful. But it also requires a mission. You need to be motivated to perform to capture the benefits of\nfreedom. There are many ways to find motivation; making a client happy, saving the day, learning new things, meeting\ninteresting people, getting rich, traveling the world, getting recognition from your peers. Whatever your source of\nmotivation, there needs to be urgency. Time is always of the essence.\n\nDare to demand outstanding results from yourself, and those around you.\n\n**Focus**\n\nThe hardest thing in life is saying no. To friends, to family, to colleagues, to customers. To yourself. The inability\nto cut away the noise often dilutes strategies. We cannot consider every option and every alternative all the time. Weâ€™d\nget nowhere. Just as a person cannot be good at everything. The curse of endless opportunities is limited time. We need\nto choose and learn to ignore that which we are missing out on. I sometimes err on the side of simplifying too much, but\nIâ€™d rather do that than get stuck thinking about all options. I pick something, try it, learn, and move on. This\napproach isnâ€™t just personal, I incorporate this mentality at Annotell too. That takes courage and leadership. And a\nfair amount of tolerance for conflict, since saying no means disappointing others.\n\n### Seems simple, right? Itâ€™s not.\n\nItâ€™s a ton of hard work. It requires very strict hiring, thoughtful work from\neveryone involved, patience, and perseverance. And itâ€™s fragile. A few bad apples easily spoil the bunch.\n\n> The best way to operate in a fast-paced environment that requires solving complex problems is to empower your team,\n> strive for greatness, and focus. By setting huge goals, allowing time to explore, having the patience to spend on R&D,\n> and the courage to trust your team to solve audacious problems - you will create a ton of value. Basically: Enormous\n> expectations but also deep trust. Sometimes you will fail miserably, but thatâ€™s part of life. **No risk, no reward.**","src/content/blog/management-under-uncertainty.md","a269173c91c7c680",{"html":422,"metadata":423},"\u003Cp>We live in a high-pressure world. This is true both in a macro and micro sense. Countries and companies are faced with\never-faster shifts in technology and public opinion. Work is getting more and more creative, and less and less\nwell-defined. Most predictable work is automated as soon as there is enough data.\u003C/p>\n\u003Cp>What is then the long-term defensible competitive advantage in such an environment? \u003Cstrong>Constantly adapting to new,\ncomplex situations.\u003C/strong> This is true as much on a personal level, as on an organizational level.\u003C/p>\n\u003Ch3 id=\"stability-vs-uncertainty\">Stability vs. Uncertainty\u003C/h3>\n\u003Cp>The automotive industry for most of its existence has been the epitome of rational efficiency. Everything is optimized,\nprice pressured, planned, and predicted. And due to the sheer size of the market, and capital expenditure required, it\nhas been a generally stable environment. There has been a limited pressure to reinvent yourself.\u003C/p>\n\u003Cp>One consequence of this stability is a comparatively low spend on R&#x26;D. I think there is a strong link between the\npredictability of a domain, and the propensity to spend on R&#x26;D. Pharmaceutical companies for example are designed to\ndeal with uncertainty and risk. Their main activity is triaging potential drugs, evaluating them in a sequence of\nincreasingly large trials, and then proving their efficacy through statistics. This is a high-risk, high-reward way of\nworking that requires state-of-the-art research and a very dynamic mindset. Imagine if an automotive company had ten\nmodels in its product development pipeline, expecting only one or two to make it to the market?\u003C/p>\n\u003Cp>As can be seen from the table below, automotive companies spend 3-8% of their revenue on R&#x26;D. Most of their activities\nare related to the manufacturing and distribution of vehicles, not the development of novel technologies. Pharma on the\nother hand spends 17-25%.\u003C/p>\n\u003Cp>At the top of the list in absolute spending is a former book store. Who could have imagined 20 years ago that the\nworldâ€™s biggest spender on research would be a retail company?\u003C/p>\n\u003Cp>\u003Cimg src=\"https://storage.googleapis.com/langkilde-se-images/5a0c9298-4074-43e5-8687-850b6d57c535.jpeg\" alt=\"\">\u003C/p>\n\u003Cp>One consequence of the perceived stability in automotive has been that most vehicle production projects are planned in\nminute detail. Automotive companies love planning. There is a â€œStart of Productionâ€ date that engineers and managers\nlive by. All activities need to be time-boxed and put in a sequence all the way up to the SoP. Thousands of engineerings\nand hundreds of companies need to deliver according to plan, or the vehicle will be delayed.\u003C/p>\n\u003Cp>As you might have noticed, Tesla (mostly) does not follow the traditional model year tradition. The value of a Tesla is\ndetermined by its features, not the date it was manufactured. With hardware and software updates being released\ncontinuously, the manufacturing year is not significant other than as a proxy for wear and tear.\u003C/p>\n\u003Cp>Itâ€™s much more demanding to operate in an environment where everything is uncertain. Uncertainty is not, by the way, the\nsame as â€œdisorderâ€. You can work in a very structured way with plenty of uncertainty.\u003C/p>\n\u003Ch3 id=\"three-forces-that-push-toward-detailed-planning\">Three Forces that Push Toward Detailed Planning\u003C/h3>\n\u003Cp>As a founder, I understand more and more why a completely incremental approach is so hard to maintain. There are three\nforces that contribute to a tendency towards detailed planning.\u003C/p>\n\u003Cp>\u003Cstrong>Budgets and capital expenditure.\u003C/strong> Companies by definition only fail for one reason: they run out of money. It takes\ncourage and deep pockets to deal with risky and expensive product development. Chances are it takes much longer than\nexpected, and the risk is that you run out of cash. But thatâ€™s also why innovation is rewarded by the market. Profit is\nthe reward for risk-taking.\u003C/p>\n\u003Cp>\u003Cstrong>Fear of failure.\u003C/strong> Fear is the \u003Ca href=\"https://dune.fandom.com/wiki/Litany_Against_Fear\">mind-killer\u003C/a>. Humans are programmed\nto avoid discomfort and danger. Itâ€™s deeply rooted in our subconscious. The deeper your fear of failing, the lower the\nprobability that you will create something truly unique and great. Organizations can easily end up preventing all\npossible negative outcomes and thereby completely eliminating any chance of novel thinking. (Of course, the ability to\ntake risks in life is also determined by other things, like the safety net of your country, social class, etc.)\u003C/p>\n\u003Cp>\u003Cstrong>Intellectual Laziness.\u003C/strong> High-performing people are typically explorers. But most people are, by definition, average.\nThe average person doesnâ€™t want to go to work every day without knowing what to expect. If they have to do that, they\nwill get exhausted and complain. A lot. So organizations, as they grow, slowly adapt to comfort those seeking\npredictability. I try and avoid hiring people who seek â€œan easy jobâ€.\u003C/p>\n\u003Cp>Ironically the risks associated with systematically avoiding risks are larger than suffering the occasional negative\nexperience. Personally, I think this is what causes larger companies to lose their edge. The challenge of navigating the\nrisk-reward nexus can be found all the way from starting a company, to funding it, to setting the vision and scope for\nthe company and maintaining its edge as it grows. Itâ€™s really hard to think really big. It takes a tremendous amount of\ncourage and a gigantic risk appetite. You have to be comfortable with the risk of failure.\u003C/p>\n\u003Ch3 id=\"how-to-run-a-company-amidst-uncertainty\">How to Run a Company Amidst Uncertainty\u003C/h3>\n\u003Cp>So, what to do then? How do you run a company when you have no idea what to expect?\u003C/p>\n\u003Cp>\u003Cstrong>Empower your team\u003C/strong>\u003C/p>\n\u003Cp>Hire amazing people and give them the resources and the mandate to solve hard problems. Put everyone close to the issue\nthey are solving. Allow everyone to talk to each other without being forced to go through layers of management. My\nmentor has always told me: â€œ \u003Cem>smart people with the same information and the same goals usually come to the same\nconclusion. You just need to ensure they have the same information and the same goals.â€\u003C/em> I firmly believe in this.\u003C/p>\n\u003Cp>It takes a lot of patience and trust to let your team solve audacious problems without detailed supervision. But it\nusually pays off fairly quickly.\u003C/p>\n\u003Cp>\u003Cstrong>Strive for greatness\u003C/strong>\u003C/p>\n\u003Cp>Freedom is powerful. But it also requires a mission. You need to be motivated to perform to capture the benefits of\nfreedom. There are many ways to find motivation; making a client happy, saving the day, learning new things, meeting\ninteresting people, getting rich, traveling the world, getting recognition from your peers. Whatever your source of\nmotivation, there needs to be urgency. Time is always of the essence.\u003C/p>\n\u003Cp>Dare to demand outstanding results from yourself, and those around you.\u003C/p>\n\u003Cp>\u003Cstrong>Focus\u003C/strong>\u003C/p>\n\u003Cp>The hardest thing in life is saying no. To friends, to family, to colleagues, to customers. To yourself. The inability\nto cut away the noise often dilutes strategies. We cannot consider every option and every alternative all the time. Weâ€™d\nget nowhere. Just as a person cannot be good at everything. The curse of endless opportunities is limited time. We need\nto choose and learn to ignore that which we are missing out on. I sometimes err on the side of simplifying too much, but\nIâ€™d rather do that than get stuck thinking about all options. I pick something, try it, learn, and move on. This\napproach isnâ€™t just personal, I incorporate this mentality at Annotell too. That takes courage and leadership. And a\nfair amount of tolerance for conflict, since saying no means disappointing others.\u003C/p>\n\u003Ch3 id=\"seems-simple-right-its-not\">Seems simple, right? Itâ€™s not.\u003C/h3>\n\u003Cp>Itâ€™s a ton of hard work. It requires very strict hiring, thoughtful work from\neveryone involved, patience, and perseverance. And itâ€™s fragile. A few bad apples easily spoil the bunch.\u003C/p>\n\u003Cblockquote>\n\u003Cp>The best way to operate in a fast-paced environment that requires solving complex problems is to empower your team,\nstrive for greatness, and focus. By setting huge goals, allowing time to explore, having the patience to spend on R&#x26;D,\nand the courage to trust your team to solve audacious problems - you will create a ton of value. Basically: Enormous\nexpectations but also deep trust. Sometimes you will fail miserably, but thatâ€™s part of life. \u003Cstrong>No risk, no reward.\u003C/strong>\u003C/p>\n\u003C/blockquote>",{"headings":424,"localImagePaths":437,"remoteImagePaths":438,"frontmatter":439,"imagePaths":440},[425,428,431,434],{"depth":24,"slug":426,"text":427},"stability-vs-uncertainty","Stability vs. Uncertainty",{"depth":24,"slug":429,"text":430},"three-forces-that-push-toward-detailed-planning","Three Forces that Push Toward Detailed Planning",{"depth":24,"slug":432,"text":433},"how-to-run-a-company-amidst-uncertainty","How to Run a Company Amidst Uncertainty",{"depth":24,"slug":435,"text":436},"seems-simple-right-its-not","Seems simple, right? Itâ€™s not.",[],[],{"pubDate":417,"title":416},[],"management-under-uncertainty.md","limits-of-prediction",{"id":442,"data":444,"body":447,"filePath":448,"digest":449,"rendered":450,"legacyId":467},{"title":445,"pubDate":446},"Limits of Prediction","2024-08-11","Communities are what make humans the dominant species on Earth. By gathering in groups and working together, passing\nwisdom between generations, we have created robust societies that long outlive individuals. Community requires a desire\nto belong. The deep desire to belong experienced by humans likely evolved with our \"discovery\" of the power of\ncommunity. But humans also need to feel specialâ€”like we make a difference. It's often the case that successful people\nhave a strong internal locus of control, meaning they believe they have personal agency over their lives and can make a\nsignificant impact.\n\n### How important is intelligence?\n\nA critical question I ask myself when thinking about the impact of Advanced Machine Intelligence (AMI), the term\npreferred by Yann LeCun, is: **How important is intelligence?** And what does that have to do with community and our\nneed to feel special? We all seem to take for granted that being extraordinarily intelligent is a superpower. I think\nthat's because successful people assume their actions are the source of their success, and people like to think they are\nintelligent. But it's possible their success is equally the result of the community they are part of. In my\npost [Untangling Skill and Luck](https://langkilde.se/post/2024-03-27-untangling-luck-and-skill-in-business), I explore\nhow skill and luck influence the outcome of events. Clearly, our actions make a difference, but the degree to which it\nmatters is essential when forecasting the impact of AMI. Let's go unreasonably deep into this question!\n\n### Predicting the future\n\nTo me, the question of intelligence's relevance is one of understanding the relationship between our intelligence and\nour ability to predict the future. I think it's safe to say being more intelligent makes you able to better predict the\nfuture. Your average human can navigate some pretty complex scenarios, making lots of impressive predictions about the\nmovement of objects and their interaction. We can abstract away lots of low-level detail and create models that allow\nsophisticated predictions.\n\n![](https://storage.googleapis.com/langkilde-se-images/4900511f95bf87afa734a73538b62282.png)\n\n**What about the marginal cost of predicting the future?** I recently talked to someone about why the \"exponential\nmindset\" prevalent in Silicon Valley might be tricking people into thinking things like self-driving cars will be\navailable sooner than they actually will. I think the counter-acting force holding self-driving cars back is that the\nworld is extremely sparse. To paraphrase [a classic](https://en.wikipedia.org/wiki/Irresistible_force_paradox): What\nhappens when an exponential improvement meets a combinatorial explosion?\n\n**First of all, I personally do not believe the world is deterministic.** Deciding your position on determinism has\nsignificant downstream consequences. I've decided to subscribe to\nthe [Copenhagen interpretation](https://en.wikipedia.org/wiki/Copenhagen_interpretation) of quantum mechanics, i.e., the\noutcome of every quantum event is probabilistic. The wave function collapse is inherently random, i.e., even with\ncomplete knowledge of the system, it is impossible to predict the exact outcome of a quantum event. In this model, the\nobserver plays a crucial role. The act of measurement is what causes the wave function to collapse.\n\n**Second, sufficiently large complex systems are chaotic**, i.e., the approximate future cannot be predicted using the\napproximate present. Even tiny errors in measuring the current state of a system can lead to vastly different outcomes.\nFor each prediction you make, these errors compound.\n\n**Thirdly, there is only so much energy to be extracted from matter.** Whatever method we use to predict the future,\nthere will be a relationship between the value of the prediction and the energy cost. The cost of a prediction increases\nexponentially with how far into the future we want to look.\n\n### Diminishing returns of intelligence\n**This indicates that there is an exponential increase in cost when predicting the future.** Even if intelligence\nimproves our ability exponentially, our net ability to predict the future could exhibit diminishing returns, i.e., the\nvalue of intelligence has diminishing returns. My personal intuition makes me feel this is true: I think the value of\nintelligence has diminishing returns.\n\n**What consequences does this have?** That's a matter of whether differential intelligence in species matters. Even if\nintelligence has diminishing value, it's possible that a persistent 20% prediction advantage is enough to replace\nanother system. Even if a 1000x higher IQ only yields a 20% prediction advantage, it could eventually displace humans.\nIn business, differentials are critical. If you can compound at a higher rate and survive, you will become the center of\ngravity. It's possible the same is true for intelligent organisms. I wrote about that\nin \"[The problem with AI will not be IQ, it will be immortality](https://langkilde.se/post/2024-04-07-the-problem-with-ai-will-not-be-iq-it-will-be-immortality)\".\n\nPerhaps this is an unexpected example, but does intelligence matter when playing Yatzy? I've asked myself that question,\nand couldn't resist going deep down the rabbit hole and finding out. You can improve your average score in Yatzy with an\noptimal strategy, but the one-sigma variance in outcome for the optimal strategy exceeds the difference in expected\noutcome between optimal and decent. That means a great yatzy player will frequently lose against a decent one.\n\nIt's crazy expensive to compute the optimal strategy, and the value isn't that big.\n\n**Maybe the same is true for intelligence?**","src/content/blog/limits-of-prediction.md","4d0cffde8fbdb519",{"html":451,"metadata":452},"\u003Cp>Communities are what make humans the dominant species on Earth. By gathering in groups and working together, passing\nwisdom between generations, we have created robust societies that long outlive individuals. Community requires a desire\nto belong. The deep desire to belong experienced by humans likely evolved with our â€œdiscoveryâ€ of the power of\ncommunity. But humans also need to feel specialâ€”like we make a difference. Itâ€™s often the case that successful people\nhave a strong internal locus of control, meaning they believe they have personal agency over their lives and can make a\nsignificant impact.\u003C/p>\n\u003Ch3 id=\"how-important-is-intelligence\">How important is intelligence?\u003C/h3>\n\u003Cp>A critical question I ask myself when thinking about the impact of Advanced Machine Intelligence (AMI), the term\npreferred by Yann LeCun, is: \u003Cstrong>How important is intelligence?\u003C/strong> And what does that have to do with community and our\nneed to feel special? We all seem to take for granted that being extraordinarily intelligent is a superpower. I think\nthatâ€™s because successful people assume their actions are the source of their success, and people like to think they are\nintelligent. But itâ€™s possible their success is equally the result of the community they are part of. In my\npost \u003Ca href=\"https://langkilde.se/post/2024-03-27-untangling-luck-and-skill-in-business\">Untangling Skill and Luck\u003C/a>, I explore\nhow skill and luck influence the outcome of events. Clearly, our actions make a difference, but the degree to which it\nmatters is essential when forecasting the impact of AMI. Letâ€™s go unreasonably deep into this question!\u003C/p>\n\u003Ch3 id=\"predicting-the-future\">Predicting the future\u003C/h3>\n\u003Cp>To me, the question of intelligenceâ€™s relevance is one of understanding the relationship between our intelligence and\nour ability to predict the future. I think itâ€™s safe to say being more intelligent makes you able to better predict the\nfuture. Your average human can navigate some pretty complex scenarios, making lots of impressive predictions about the\nmovement of objects and their interaction. We can abstract away lots of low-level detail and create models that allow\nsophisticated predictions.\u003C/p>\n\u003Cp>\u003Cimg src=\"https://storage.googleapis.com/langkilde-se-images/4900511f95bf87afa734a73538b62282.png\" alt=\"\">\u003C/p>\n\u003Cp>\u003Cstrong>What about the marginal cost of predicting the future?\u003C/strong> I recently talked to someone about why the â€œexponential\nmindsetâ€ prevalent in Silicon Valley might be tricking people into thinking things like self-driving cars will be\navailable sooner than they actually will. I think the counter-acting force holding self-driving cars back is that the\nworld is extremely sparse. To paraphrase \u003Ca href=\"https://en.wikipedia.org/wiki/Irresistible_force_paradox\">a classic\u003C/a>: What\nhappens when an exponential improvement meets a combinatorial explosion?\u003C/p>\n\u003Cp>\u003Cstrong>First of all, I personally do not believe the world is deterministic.\u003C/strong> Deciding your position on determinism has\nsignificant downstream consequences. Iâ€™ve decided to subscribe to\nthe \u003Ca href=\"https://en.wikipedia.org/wiki/Copenhagen_interpretation\">Copenhagen interpretation\u003C/a> of quantum mechanics, i.e., the\noutcome of every quantum event is probabilistic. The wave function collapse is inherently random, i.e., even with\ncomplete knowledge of the system, it is impossible to predict the exact outcome of a quantum event. In this model, the\nobserver plays a crucial role. The act of measurement is what causes the wave function to collapse.\u003C/p>\n\u003Cp>\u003Cstrong>Second, sufficiently large complex systems are chaotic\u003C/strong>, i.e., the approximate future cannot be predicted using the\napproximate present. Even tiny errors in measuring the current state of a system can lead to vastly different outcomes.\nFor each prediction you make, these errors compound.\u003C/p>\n\u003Cp>\u003Cstrong>Thirdly, there is only so much energy to be extracted from matter.\u003C/strong> Whatever method we use to predict the future,\nthere will be a relationship between the value of the prediction and the energy cost. The cost of a prediction increases\nexponentially with how far into the future we want to look.\u003C/p>\n\u003Ch3 id=\"diminishing-returns-of-intelligence\">Diminishing returns of intelligence\u003C/h3>\n\u003Cp>\u003Cstrong>This indicates that there is an exponential increase in cost when predicting the future.\u003C/strong> Even if intelligence\nimproves our ability exponentially, our net ability to predict the future could exhibit diminishing returns, i.e., the\nvalue of intelligence has diminishing returns. My personal intuition makes me feel this is true: I think the value of\nintelligence has diminishing returns.\u003C/p>\n\u003Cp>\u003Cstrong>What consequences does this have?\u003C/strong> Thatâ€™s a matter of whether differential intelligence in species matters. Even if\nintelligence has diminishing value, itâ€™s possible that a persistent 20% prediction advantage is enough to replace\nanother system. Even if a 1000x higher IQ only yields a 20% prediction advantage, it could eventually displace humans.\nIn business, differentials are critical. If you can compound at a higher rate and survive, you will become the center of\ngravity. Itâ€™s possible the same is true for intelligent organisms. I wrote about that\nin â€œ\u003Ca href=\"https://langkilde.se/post/2024-04-07-the-problem-with-ai-will-not-be-iq-it-will-be-immortality\">The problem with AI will not be IQ, it will be immortality\u003C/a>â€.\u003C/p>\n\u003Cp>Perhaps this is an unexpected example, but does intelligence matter when playing Yatzy? Iâ€™ve asked myself that question,\nand couldnâ€™t resist going deep down the rabbit hole and finding out. You can improve your average score in Yatzy with an\noptimal strategy, but the one-sigma variance in outcome for the optimal strategy exceeds the difference in expected\noutcome between optimal and decent. That means a great yatzy player will frequently lose against a decent one.\u003C/p>\n\u003Cp>Itâ€™s crazy expensive to compute the optimal strategy, and the value isnâ€™t that big.\u003C/p>\n\u003Cp>\u003Cstrong>Maybe the same is true for intelligence?\u003C/strong>\u003C/p>",{"headings":453,"localImagePaths":463,"remoteImagePaths":464,"frontmatter":465,"imagePaths":466},[454,457,460],{"depth":24,"slug":455,"text":456},"how-important-is-intelligence","How important is intelligence?",{"depth":24,"slug":458,"text":459},"predicting-the-future","Predicting the future",{"depth":24,"slug":461,"text":462},"diminishing-returns-of-intelligence","Diminishing returns of intelligence",[],[],{"pubDate":446,"title":445},[],"limits-of-prediction.md","many-small-bets-with-outlier-potential",{"id":468,"data":470,"body":473,"filePath":474,"digest":475,"rendered":476,"legacyId":502},{"title":471,"pubDate":472},"Many small bets with outlier potential","2024-01-14","Most of my writing is about the balance between risk and reward. I canâ€™t stop thinking about it. My whole life revolves\naround identifying opportunities, estimating the risk involved in capturing value, and then deciding on what to do. All\nunder significant uncertainty. I constantly work on improving my thinking around risk and reward.\n\n### Your Risk Baseline\n\n**What levels of risk am I comfortable with?** When placed in an organization or situation that requires or assumes a\nhigher or lower risk baseline than your preference, you will struggle. You will feel others are either reckless or\ncowards.\n\nMy approach to evolving my reasoning about risk is to read as much as I can, talk to as many people as possible, and\nthen write. By writing in public I force myself to think carefully. My most recent read\nwas [The Power Law](https://www.amazon.com/Power-Law-Venture-Capital-Making/dp/052555999X) by Sebastian Mallaby. It has\nquickly become one of the canonical texts on venture capital. A sentence appears early in the book, without specific\nattribution, but in a section about Vinod Khosla. I think it captures the Silicon Valley mindset in a single sentence:\n\n> There is no glory in projects that will probably succeed, for these by definition wonâ€™t transform the human\n> predicament.\n>\n> -- Sebastian Mallaby, The Power Law, 2022\n\n### Context Matters in Risk-Taking\n\n**Risk can only be understood in the context of what you might lose.** All financially successful entrepreneurs and\nventure capitalists have taken risks. Usually an extraordinary amount of it. â€œNo risk, no rewardâ€, after all. But what\nmight seem like a big risk to one person, may be a rounding error to someone else. Many famous people who celebrate\ntaking risks are financially independent. Just like people who tell you to â€œfollow your heart and have funâ€ often toiled\nthrough extreme pains to get rich. Advice can only be understood in context. What does a person have to lose by saying\nâ€œYou should take risksâ€? What do they gain? I think about that when I read the sentence above. And I think about that\nwhen I read writings by Sam Altman, Marc Andreessen, Peter Thiel, Elon Musk, Roelof Botha, and other promoters of risk.\nA common denominator between these people is that they all had major success early in life. They have been financially\nindependent for most of their adult life. Another important factor is that they were not born rich. Even if they did bet\nbig, they would always have a few tens of millions of dollars stoved away for a rainy day. For someone not born with\nmoney, thatâ€™s essentially an endless amount. If you are born into wealth, having less will feel like a failure, so then\nyou might experience risk differently. Risk becomes a matter of social status and comparative achievement. Generational\nwealth seems to mess with peopleâ€™s perspectives.\n\nSome might say â€œBut what about Elon Musk, he has bet everything a few timesâ€. Well, I donâ€™t think thatâ€™s true actually.\nIâ€™m sure he always kept a few million dollars off the table. Either way, for every Elon Musk, there are at least\nten [Henrik Fisker](https://www.theinformation.com/articles/how-kleiner-perkins-missed-out-on-tesla-and-why-thats-ok-in-the-long-run)\nwho go\nbust. [Survival bias](https://en.wikipedia.org/wiki/Survivorship_bias#:~:text=Survivorship%20bias%20or%20survival%20bias,conclusions%20because%20of%20incomplete%20data.)\nis real. I strongly recommend reading \"[Speed & Scale](https://speedandscale.com/book/)\" by investor John Doerr where he\ndescribes betting on Fisker instead of Tesla. Random events had a major impact on the outcome.\n\n### Luck, Timing, Talent\n\n**A wise man I know always says â€œLuck, Timing, Talent. In that order.â€** I think about that a lot. There is a deep, and\nhumbling, truth to it - especially in the context of outlier outcomes. Up to a certain point, I maintain that you can\ninfluence rewards through hard work and talent. But eventually, effort and rewards are decoupled. At least in a\nfinancial sense. Founders who build billion-dollar companies do not work a billion times harder than other talented\nfounders.\n\n**People with high intrinsic motivation, who see themselves as the agents of their success, will claim they â€œmanufacture\nluckâ€.** They feel that while they may not work a billion times harder, they are responsible for creating the _leverage_\nthat produced their outlier outcome. The media isnâ€™t interested in actual causality, instead, they will immediately\nprint articles about â€œthe genius X who foresaw Yâ€. The best people I know acknowledge the significant amount of luck\ninvolved.\n\nAll that said, there is no doubt prolific and hard-working people are positioned to have more luck. A legendary Swedish\nskier once said:\n\n> I donâ€™t know much about luck, but I do know I have more of it the more I practice.\n>\n> -- Ingemar Stenmark\n\nIf you work hard and seek high-risk, high-reward situations, you are likely to get lucky more than others. The better\nyou are at skewing the odds through strategic positioning, the further you can increase your odds of being lucky.\nReversely, those who consistently avoid risk also reduce their chances of being lucky.\n\n### Applying Venture Capital Thinking to Life\n\n**Venture capitalists make a living by exposing themselves to many small-ish bets, each with the potential to create\noutlier outcomes.** I think the same strategy can be applied in almost any context: business leadership, personal life,\netc. Position yourself so that you can make small, highly leveraged bets with fast feedback, i.e. bets with a small\ndownside and a large upside within about a year. If you can create a flow of such opportunities, and work hard to\nmaximize the odds of each bet, then you are in a good position to get a few great outcomes.\n\n### Founder vs. Investor Alignment\n\n**An interesting consequence of this strategy is that investors and founders are not aligned.** Most founders only have\none company. Most likely, the vast majority of their net worth is concentrated in that one entity. They probably have\nlittle or no optionality. If their company fails, they get nothing. And they may struggle to ever get close to what they\nhad again. Most investors can afford to write off a few of their investments. Venture capitalists _expect_ to write off\nmost of them. This becomes particularly clear right now when raising money is hard. Founders have been encouraged to\ntake risks and burn money in their pursuit of growth. Venture capital investors hunt outlier outcomes. But if commercial\nprogress is not consistent with the outlier model, and there is a contraction in the funding ecosystem, then investors\nmight suddenly consider your company â€œsunken costâ€. I guess each generation needs to relearn this by going through a\nboom-bust cycle.\n\n### My Risk-Reward Strategy\n\n**So, whatâ€™s my conclusion from all this?** My goal is to make it easy to make many small bets, in proportion to\navailable capital, each with potentially extraordinary rewards.\n\nThis can be done in all situations in life. Everything from hiring someone, trying a new product idea, or starting a\nconversation with a stranger. Each action can be a small bet with potentially extraordinary returns. You might find an\nexcellent performing team member or make a valuable connection. If we apply this idea specifically to investing and\npersonal wealth, Iâ€™ve arrived at the following algorithm:\n\n**1\\. Secure a financial foundation and set boundaries.** To invest and take risks, I want to have 10x more\ncash-equivalent assets than Iâ€™m betting. The reason is that I want to make decisions unburdened by fear of losing my\nmoney. To invest $100k, I want to have $1M of liquid assets. For similar reasons, Iâ€™ve set an assets floor I wonâ€™t go\nunder. If I have less than $X, I wonâ€™t place any bets, no matter how small. Iâ€™ve set my assets floor to ensure we can\nkeep our house for a few years even if I lose everything (i.e. enough time to regroup without harming my family). Those\nfunds are off-limits, and Iâ€™ve firewalled investing from my household finances. To bootstrap my foundation, I did two\nthings: I joined a startup with a high probability of an excellent\noutcome ([Recorded Future](https://www.prnewswire.com/news-releases/insight-partners-acquires-recorded-future-for-780-million-300858805.html))\nand then I started my own\ncompany ([Kognic](https://techcrunch.com/2022/02/02/annotell-raises-24m-for-tech-that-tests-autonomous-vehicle-perception-systems-to-improve-how-they-work/)).\nI think a major reason some people achieve extraordinary wealth late in life is they start early and then compound. I\nwas **lucky** to become founder and CEO the year I turned 30, and experienced my first exit when I was 32.\n\n**2\\. Have the discipline to partially exit successful bets.** If you have a successful outcome in one of your bets, you\neventually want to exit part of your position to diversify. Rather than have your entire net worth locked into one\nasset, you want to get cash out and redeploy it. Remember, we want to place many small bets, not just keep one big one\ngoing. So, depending on the trajectory, you want to make a partial exit at some point. The option is to start\ndiversifying what your company does, but thatâ€™s not always possible.\n\n**3\\. Develop access to a flow of bets with great odds of outlier outcomes.** Get to know great, insanely driven people,\nand then help them with whatever they need. Provide tangible assistance without any strings attached. If you can figure\nout how to help great founders and investors you respect, then good investment opportunities will come your way. This is\ntrue for other things as well, not just investing. Being a prolific helper is a great way to build relationships and\ntrust. Plus, it feels good and makes life meaningful. Being active and curious is the best way to find interesting\nproblems, interesting people, and thereby interesting opportunities.\n\n**4\\. Decouple sizing your bets from your emotions.** Iâ€™m inherently too optimistic to size bets appropriately. As a\npassionate person who easily gets excited, I tend to think â€œWow, this is a great opportunity, letâ€™s go all inâ€. Resist\nthat temptation. Instead, apply a rigid and systematic approach when placing bets. When I seed invest, for example, I\nnowadays always invest the same amount. Iâ€™ve decided I only place a bet if there is a chance of an extraordinary\noutcome, so all opportunities should be approximately equally promising. If an opportunity feels _less_ promising, I\npass instead. Iâ€™ve started to think about business decisions this way too. Evaluate the upside, if itâ€™s huge, place a\ndefault-sized bet (ticket size, number of FTEs, number of sprints, amount of money, hours, or whatever unit is\napplicable). Then just trust the process.\n\n**5\\. Remember that the strongest force in the universe is compound interest.** My goal is to achieve a 20% annual\nincrease in assets by placing many small bets. Based on top-performing venture funds, that should be possible. Over 5\nyears, thatâ€™s a ~2.5x increase. Over 10 years, ~6.2x, and over 20 years itâ€™s a whopping 38x. I donâ€™t need blowout years,\nI aim for consistently high returns.\n\nInterestingly, the strategy of making many small bets is very similar to agile product development. Rather than make\ncomplex, long-term plans, you form a hypothesis, build a minimum viable solution, and test it on users. By placing a\nsmall bet, and evaluating the outcome, you learn quickly and can double down on bets that show promise. If early\nfeedback isnâ€™t great, you havenâ€™t wasted too much time considering all the consequences.\n\nExecuting this strategy over the next twenty years will likely increase my odds of being lucky. It will require insanely\nhard work, and itâ€™s far from certain I will reach my goal. But it sure feels like a fun challenge! ðŸ¤©","src/content/blog/many-small-bets-with-outlier-potential.md","b658a5a33e409eb6",{"html":477,"metadata":478},"\u003Cp>Most of my writing is about the balance between risk and reward. I canâ€™t stop thinking about it. My whole life revolves\naround identifying opportunities, estimating the risk involved in capturing value, and then deciding on what to do. All\nunder significant uncertainty. I constantly work on improving my thinking around risk and reward.\u003C/p>\n\u003Ch3 id=\"your-risk-baseline\">Your Risk Baseline\u003C/h3>\n\u003Cp>\u003Cstrong>What levels of risk am I comfortable with?\u003C/strong> When placed in an organization or situation that requires or assumes a\nhigher or lower risk baseline than your preference, you will struggle. You will feel others are either reckless or\ncowards.\u003C/p>\n\u003Cp>My approach to evolving my reasoning about risk is to read as much as I can, talk to as many people as possible, and\nthen write. By writing in public I force myself to think carefully. My most recent read\nwas \u003Ca href=\"https://www.amazon.com/Power-Law-Venture-Capital-Making/dp/052555999X\">The Power Law\u003C/a> by Sebastian Mallaby. It has\nquickly become one of the canonical texts on venture capital. A sentence appears early in the book, without specific\nattribution, but in a section about Vinod Khosla. I think it captures the Silicon Valley mindset in a single sentence:\u003C/p>\n\u003Cblockquote>\n\u003Cp>There is no glory in projects that will probably succeed, for these by definition wonâ€™t transform the human\npredicament.\u003C/p>\n\u003Cp>â€” Sebastian Mallaby, The Power Law, 2022\u003C/p>\n\u003C/blockquote>\n\u003Ch3 id=\"context-matters-in-risk-taking\">Context Matters in Risk-Taking\u003C/h3>\n\u003Cp>\u003Cstrong>Risk can only be understood in the context of what you might lose.\u003C/strong> All financially successful entrepreneurs and\nventure capitalists have taken risks. Usually an extraordinary amount of it. â€œNo risk, no rewardâ€, after all. But what\nmight seem like a big risk to one person, may be a rounding error to someone else. Many famous people who celebrate\ntaking risks are financially independent. Just like people who tell you to â€œfollow your heart and have funâ€ often toiled\nthrough extreme pains to get rich. Advice can only be understood in context. What does a person have to lose by saying\nâ€œYou should take risksâ€? What do they gain? I think about that when I read the sentence above. And I think about that\nwhen I read writings by Sam Altman, Marc Andreessen, Peter Thiel, Elon Musk, Roelof Botha, and other promoters of risk.\nA common denominator between these people is that they all had major success early in life. They have been financially\nindependent for most of their adult life. Another important factor is that they were not born rich. Even if they did bet\nbig, they would always have a few tens of millions of dollars stoved away for a rainy day. For someone not born with\nmoney, thatâ€™s essentially an endless amount. If you are born into wealth, having less will feel like a failure, so then\nyou might experience risk differently. Risk becomes a matter of social status and comparative achievement. Generational\nwealth seems to mess with peopleâ€™s perspectives.\u003C/p>\n\u003Cp>Some might say â€œBut what about Elon Musk, he has bet everything a few timesâ€. Well, I donâ€™t think thatâ€™s true actually.\nIâ€™m sure he always kept a few million dollars off the table. Either way, for every Elon Musk, there are at least\nten \u003Ca href=\"https://www.theinformation.com/articles/how-kleiner-perkins-missed-out-on-tesla-and-why-thats-ok-in-the-long-run\">Henrik Fisker\u003C/a>\nwho go\nbust. \u003Ca href=\"https://en.wikipedia.org/wiki/Survivorship_bias#:~:text=Survivorship%20bias%20or%20survival%20bias,conclusions%20because%20of%20incomplete%20data.\">Survival bias\u003C/a>\nis real. I strongly recommend reading â€œ\u003Ca href=\"https://speedandscale.com/book/\">Speed &#x26; Scale\u003C/a>â€ by investor John Doerr where he\ndescribes betting on Fisker instead of Tesla. Random events had a major impact on the outcome.\u003C/p>\n\u003Ch3 id=\"luck-timing-talent\">Luck, Timing, Talent\u003C/h3>\n\u003Cp>\u003Cstrong>A wise man I know always says â€œLuck, Timing, Talent. In that order.â€\u003C/strong> I think about that a lot. There is a deep, and\nhumbling, truth to it - especially in the context of outlier outcomes. Up to a certain point, I maintain that you can\ninfluence rewards through hard work and talent. But eventually, effort and rewards are decoupled. At least in a\nfinancial sense. Founders who build billion-dollar companies do not work a billion times harder than other talented\nfounders.\u003C/p>\n\u003Cp>\u003Cstrong>People with high intrinsic motivation, who see themselves as the agents of their success, will claim they â€œmanufacture\nluckâ€.\u003C/strong> They feel that while they may not work a billion times harder, they are responsible for creating the \u003Cem>leverage\u003C/em>\nthat produced their outlier outcome. The media isnâ€™t interested in actual causality, instead, they will immediately\nprint articles about â€œthe genius X who foresaw Yâ€. The best people I know acknowledge the significant amount of luck\ninvolved.\u003C/p>\n\u003Cp>All that said, there is no doubt prolific and hard-working people are positioned to have more luck. A legendary Swedish\nskier once said:\u003C/p>\n\u003Cblockquote>\n\u003Cp>I donâ€™t know much about luck, but I do know I have more of it the more I practice.\u003C/p>\n\u003Cp>â€” Ingemar Stenmark\u003C/p>\n\u003C/blockquote>\n\u003Cp>If you work hard and seek high-risk, high-reward situations, you are likely to get lucky more than others. The better\nyou are at skewing the odds through strategic positioning, the further you can increase your odds of being lucky.\nReversely, those who consistently avoid risk also reduce their chances of being lucky.\u003C/p>\n\u003Ch3 id=\"applying-venture-capital-thinking-to-life\">Applying Venture Capital Thinking to Life\u003C/h3>\n\u003Cp>\u003Cstrong>Venture capitalists make a living by exposing themselves to many small-ish bets, each with the potential to create\noutlier outcomes.\u003C/strong> I think the same strategy can be applied in almost any context: business leadership, personal life,\netc. Position yourself so that you can make small, highly leveraged bets with fast feedback, i.e. bets with a small\ndownside and a large upside within about a year. If you can create a flow of such opportunities, and work hard to\nmaximize the odds of each bet, then you are in a good position to get a few great outcomes.\u003C/p>\n\u003Ch3 id=\"founder-vs-investor-alignment\">Founder vs. Investor Alignment\u003C/h3>\n\u003Cp>\u003Cstrong>An interesting consequence of this strategy is that investors and founders are not aligned.\u003C/strong> Most founders only have\none company. Most likely, the vast majority of their net worth is concentrated in that one entity. They probably have\nlittle or no optionality. If their company fails, they get nothing. And they may struggle to ever get close to what they\nhad again. Most investors can afford to write off a few of their investments. Venture capitalists \u003Cem>expect\u003C/em> to write off\nmost of them. This becomes particularly clear right now when raising money is hard. Founders have been encouraged to\ntake risks and burn money in their pursuit of growth. Venture capital investors hunt outlier outcomes. But if commercial\nprogress is not consistent with the outlier model, and there is a contraction in the funding ecosystem, then investors\nmight suddenly consider your company â€œsunken costâ€. I guess each generation needs to relearn this by going through a\nboom-bust cycle.\u003C/p>\n\u003Ch3 id=\"my-risk-reward-strategy\">My Risk-Reward Strategy\u003C/h3>\n\u003Cp>\u003Cstrong>So, whatâ€™s my conclusion from all this?\u003C/strong> My goal is to make it easy to make many small bets, in proportion to\navailable capital, each with potentially extraordinary rewards.\u003C/p>\n\u003Cp>This can be done in all situations in life. Everything from hiring someone, trying a new product idea, or starting a\nconversation with a stranger. Each action can be a small bet with potentially extraordinary returns. You might find an\nexcellent performing team member or make a valuable connection. If we apply this idea specifically to investing and\npersonal wealth, Iâ€™ve arrived at the following algorithm:\u003C/p>\n\u003Cp>\u003Cstrong>1. Secure a financial foundation and set boundaries.\u003C/strong> To invest and take risks, I want to have 10x more\ncash-equivalent assets than Iâ€™m betting. The reason is that I want to make decisions unburdened by fear of losing my\nmoney. To invest $100k, I want to have $1M of liquid assets. For similar reasons, Iâ€™ve set an assets floor I wonâ€™t go\nunder. If I have less than $X, I wonâ€™t place any bets, no matter how small. Iâ€™ve set my assets floor to ensure we can\nkeep our house for a few years even if I lose everything (i.e. enough time to regroup without harming my family). Those\nfunds are off-limits, and Iâ€™ve firewalled investing from my household finances. To bootstrap my foundation, I did two\nthings: I joined a startup with a high probability of an excellent\noutcome (\u003Ca href=\"https://www.prnewswire.com/news-releases/insight-partners-acquires-recorded-future-for-780-million-300858805.html\">Recorded Future\u003C/a>)\nand then I started my own\ncompany (\u003Ca href=\"https://techcrunch.com/2022/02/02/annotell-raises-24m-for-tech-that-tests-autonomous-vehicle-perception-systems-to-improve-how-they-work/\">Kognic\u003C/a>).\nI think a major reason some people achieve extraordinary wealth late in life is they start early and then compound. I\nwas \u003Cstrong>lucky\u003C/strong> to become founder and CEO the year I turned 30, and experienced my first exit when I was 32.\u003C/p>\n\u003Cp>\u003Cstrong>2. Have the discipline to partially exit successful bets.\u003C/strong> If you have a successful outcome in one of your bets, you\neventually want to exit part of your position to diversify. Rather than have your entire net worth locked into one\nasset, you want to get cash out and redeploy it. Remember, we want to place many small bets, not just keep one big one\ngoing. So, depending on the trajectory, you want to make a partial exit at some point. The option is to start\ndiversifying what your company does, but thatâ€™s not always possible.\u003C/p>\n\u003Cp>\u003Cstrong>3. Develop access to a flow of bets with great odds of outlier outcomes.\u003C/strong> Get to know great, insanely driven people,\nand then help them with whatever they need. Provide tangible assistance without any strings attached. If you can figure\nout how to help great founders and investors you respect, then good investment opportunities will come your way. This is\ntrue for other things as well, not just investing. Being a prolific helper is a great way to build relationships and\ntrust. Plus, it feels good and makes life meaningful. Being active and curious is the best way to find interesting\nproblems, interesting people, and thereby interesting opportunities.\u003C/p>\n\u003Cp>\u003Cstrong>4. Decouple sizing your bets from your emotions.\u003C/strong> Iâ€™m inherently too optimistic to size bets appropriately. As a\npassionate person who easily gets excited, I tend to think â€œWow, this is a great opportunity, letâ€™s go all inâ€. Resist\nthat temptation. Instead, apply a rigid and systematic approach when placing bets. When I seed invest, for example, I\nnowadays always invest the same amount. Iâ€™ve decided I only place a bet if there is a chance of an extraordinary\noutcome, so all opportunities should be approximately equally promising. If an opportunity feels \u003Cem>less\u003C/em> promising, I\npass instead. Iâ€™ve started to think about business decisions this way too. Evaluate the upside, if itâ€™s huge, place a\ndefault-sized bet (ticket size, number of FTEs, number of sprints, amount of money, hours, or whatever unit is\napplicable). Then just trust the process.\u003C/p>\n\u003Cp>\u003Cstrong>5. Remember that the strongest force in the universe is compound interest.\u003C/strong> My goal is to achieve a 20% annual\nincrease in assets by placing many small bets. Based on top-performing venture funds, that should be possible. Over 5\nyears, thatâ€™s a ~2.5x increase. Over 10 years, ~6.2x, and over 20 years itâ€™s a whopping 38x. I donâ€™t need blowout years,\nI aim for consistently high returns.\u003C/p>\n\u003Cp>Interestingly, the strategy of making many small bets is very similar to agile product development. Rather than make\ncomplex, long-term plans, you form a hypothesis, build a minimum viable solution, and test it on users. By placing a\nsmall bet, and evaluating the outcome, you learn quickly and can double down on bets that show promise. If early\nfeedback isnâ€™t great, you havenâ€™t wasted too much time considering all the consequences.\u003C/p>\n\u003Cp>Executing this strategy over the next twenty years will likely increase my odds of being lucky. It will require insanely\nhard work, and itâ€™s far from certain I will reach my goal. But it sure feels like a fun challenge! ðŸ¤©\u003C/p>",{"headings":479,"localImagePaths":498,"remoteImagePaths":499,"frontmatter":500,"imagePaths":501},[480,483,486,489,492,495],{"depth":24,"slug":481,"text":482},"your-risk-baseline","Your Risk Baseline",{"depth":24,"slug":484,"text":485},"context-matters-in-risk-taking","Context Matters in Risk-Taking",{"depth":24,"slug":487,"text":488},"luck-timing-talent","Luck, Timing, Talent",{"depth":24,"slug":490,"text":491},"applying-venture-capital-thinking-to-life","Applying Venture Capital Thinking to Life",{"depth":24,"slug":493,"text":494},"founder-vs-investor-alignment","Founder vs. Investor Alignment",{"depth":24,"slug":496,"text":497},"my-risk-reward-strategy","My Risk-Reward Strategy",[],[],{"pubDate":472,"title":471},[],"many-small-bets-with-outlier-potential.md","risk-and-reward-when-turning-tech-into-business",{"id":503,"data":505,"body":508,"filePath":509,"digest":510,"rendered":511,"legacyId":535},{"title":506,"pubDate":507},"Risk and reward when turning tech into business","2021-11-07","Technology and entrepreneurship are lifelong passions of mine. Most things have not been invented yet, and imagining all\nthe cool stuff we will enjoy in the future is a favorite past-time. But how do you turn new technology into valuable\nproducts, and how is that related to risk and reward?\n\n### Prelude\n\nInsight comes from reflecting on our experiences. To understand my views on technology, entrepreneurship, risk, and\nreward, a brief bio is probably in order. I knew already in high school that I wanted to be an entrepreneur (how that\nhappened is another story ðŸ˜…). My strategy for how to contribute to innovation started with pursuing a degree with a\nheavy focus on mathematics. The reason for picking mathematics was that I was _so_ interested in programming and\nleadership that I figured I could learn those anyway. Mathematics, on the other hand, was something I needed help\nlearning. While studying, I made sure to be very active in various student organizations and non-profits. That gave me\nan understanding of what it takes to inspire people to get things done, even without a salary (just like in a startup!).\n\nThanks to a great mentor I decided to learn a craft in my first job. In my case, I choose software engineering. Generic\ncareers like strategy or management consulting disconnect you from the reality of execution. Talking is easy, doing is\nharder, and early-stage innovation management is largely defined by execution. Sure, you are likely to become a solid\nearner if you pick consulting, but you are unlikely to learn or do anything game-changing. All you learn is to optimize\nspreadsheets and ask questions. Not inspire people and provide answers. The only caveat maybe is that consultants make\ngood investors, so there is that at least. ðŸ˜‰\n\nAfter graduating, I was fortunate enough to get recruited by an early-stage technology startup that allowed me to\ncombine my interest in mathematics, programming, and leadership, but that also introduced a product and commercial\naspect to technology. Almost 15 years after deciding to start a business, it was finally time in 2018. Building a\ncompany means my experiences in mathematics, programming, leadership, and commercial strategy are finally converging. So\nwhat have I learned?\n\n### Setting a Strong Foundation\n\nSuccessfully turning technology into a business is incredibly complex, and involves balancing a very large number of\naspects. In my particular choice of entrepreneurship, i.e. enterprise deep tech, combining an intimate understanding of\nemerging technology with a deep understanding of user needs is the starting point. I think whatever your vertical, you\nhave to be immersed in it to be able to succeed. You have to live and breathe the subject matter. Why? Because there are\nso many opinions, and so much information, that the only way to find a path is to have enough intuition and integrity to\npick a path yourself. And picking a successful path means you will have to know what information to listen to, and what\nto ignore.\n\nPersonally, I believe in the following playbook:\n\n**Step 1. Look at the world and ask yourself â€œwhat is inevitable?â€.** I think for example that increasingly intelligent\nmachines are inevitable. I also think a radical shift away from oil is inevitable. There are lots of large shifts going\non in the world, and as long as you align yourself with one of them, you will be fine. If your company succeeds, you\nwill have to ride this wave for many, many years so make sure you like the wave.\n\n**Step 2. Learn everything about the low-level details of your space and tech.** The key to early-stage success is being\nextremely concrete. This is where most generalists fail. They have too casual an understanding of their domain. Learning\neverything takes time. In my case, maybe 10 years. I worked patiently with the nitty-gritty details, trying to solve\nproblems, talking to smart people, and testing things. Rapid success is usually the result of very, very thorough\npreparations.\n\n**Step 3. Find something everyone is wrong about but that is necessary to get right.** True value comes from scarcity.\nYou will never make much difference if all you do is repeat what everyone already knows. Finding something that a large\ngroup of people is wrong about is key to building a valuable company. For example, Tesla is built on the conviction that\na rapid shift to EVs did not have to take decades. Incumbents said, â€œwe cannot move fasterâ€. Elon Musk said, â€œhold my\nbeerâ€. When we started Annotell, everyone said â€œComputers are going to replace humansâ€. I said, â€œNo, but with great\ndatasets, we can make computers a little less stupidâ€.\n\n**Step 4. Provide a super-concrete solution that helps users get it right.** There is a huge difference between\ninteresting and valuable. There is only one way to really figure out if something is valuable: getting others to pay for\nit. For some businesses, the first invoice takes a decade. For others, it takes two days. Sooner or later, revenue is\nthe way we define value. How much your margins matter depends on volume and position in the market, but revenue is not\noptional. The only way to get top-line growth is to close the gap between a userâ€™s need, your product, and their wallet.\n\n**Step 5. Inspire a world-class team to rally behind your idea.** Without a great team, you are not going to make it.\nThe massive shift you are part of, what you point out is wrong, the solution you offer, and your passion as a founder -\nall these factors have to inspire a large enough group of talented people to fight for your company.\n\n**Step 6. Ensure excellent execution.** For all the big-picture questions you have to ask yourself up to this point, you\nalso need to ensure that execution is world-class. This becomes much easier with a world-class team, but even then you\nneed to ensure great management, clear expectations, well-defined processes, etc. Many entrepreneurs I know dismiss\nprocesses as a â€œbig corp thingâ€. Those people are unlikely to build a large and successful business. Growth requires\nprocesses.\n\n**Step 7. Map out your growth journey.** By now, you have the basics of a company. It probably took you many years to\nget here. You might even have a few customers. It is time to estimate â€œHow large can this get?â€ and â€œWhat is the right\npath from here?â€. Weirdly enough, some entrepreneurs start with these questions before steps 1-6. Few such entrepreneurs\nsucceed in my experience. If all you care about is raising a huge round from a famous VC, then of course you need to\nmake very deliberate choices up to this point. But thatâ€™s not the only way to succeed, and it is not the only sort of\ncompany you can build. This is where the risk-reward nexus comes into play. If you nail points 1-6 you will have a\ncompany, and it is likely to make money. As an entrepreneur, you now need to ask yourself â€œHow much risk am I willing to\ntake when balancing the future value of my company, and my probability of survival?â€\n\n### Balancing Risk and Reward\n\nThe more audacious the proposed product, the larger the risk typically. Letâ€™s say we _think_ we have found a radical new\nway to generate energy, but that the capital expenditure required is multiple billions. Then we need to convince enough\npeople that our solution is in fact likely to succeed and that investing in you and your team is the best way to make it\nreal. The nice thing about expensive startups is that they are less likely to get a lot of competition. The bad thing is\nthat they are expensive, and hence financially risky.\n\nAll investors know this, but I wonder if all entrepreneurs know this? My point is that entrepreneurs need to understand\nthe balance between risk and reward when deciding to turn technology into products. Letâ€™s look at a few scenarios:\n\nLetâ€™s say you have a great idea for a consumer mobile app, and it requires $5M to build a sufficiently good first\nversion to launch it, what are the risks? Of course, the largest risk is that you fail to convert the $5M into a\nsufficiently good first version to attract users. Without strong usage metrics, you will likely fail to raise follow-up\nrounds. So investors will evaluate you personally, and your potential. Usually, with these cases, the risk is mostly on\nthe execution side. Consumer markets are large, but the probability of successfully capturing a large part of consumers\nis low. Smart, hardworking teams with the right pedigree are more likely to figure out what works, so they get more\nfunding.\n\nIf instead you have found a promising technology that might be able to change the way companies solve a big problem, but\nyou need $50M to make it _real_ _enough_ for a proof-of-concept, then what are the risks? Now the risks include both\nexecution, i.e. will you be able to turn the $50M into something good, and market size, i.e. is it worth putting $50M\ninto solving this problem?\n\nAs a founder, you have to ask yourself: what risks am I comfortable with? Typically, the larger the upside, the larger\nthe risk. A capital expensive start-up can weaponize money to dominate a market, assuming size translates into an\nobvious advantage. The more scalable your business model, i.e. the lower the service fraction and the higher the overlap\nbetween customers, the more money you need to defend yourself, but the larger you can get. Think search and social\nmedia. Low-touch products that require huge amounts of capital, but where success lands you a money printing monopoly.\n\nOn the other hand, if your business model involves more service and more expertise, you are less likely to get\ndisrupted, but you limit your own growth. A smart, hardworking team can always make a specific customer happy. Thatâ€™s\nwhat consulting is about. Itâ€™s lower risk but also a much lower reward. Building a large company is about figuring out\nwhere on the risk-reward curve you want to operate, and what you want to achieve - while still not compromising with the\nplaybook above.\n\n### The World is not Fair\n\nThis risk-reward operating curve is also a big source of unfairness. Since so much of building a business is\nspeculation, trust and patience play a big part in overcoming challenges. If you have the right pedigree and network,\nthere is funding available that gives you time and freedom, or power, that others cannot afford. If you are not of the\nâ€œrightâ€ background, and cannot get access to such networks, the magnitude of your idea might not overcome the hurdles in\nyour way. Likely, this is changing as more money is available to startups and competition among venture firms increases.\nBut itâ€™s worth reminding everyone that getting access to the unfair advantages that come with premium funding can be\nsignificant. If you truly want to change the world, relationships and access are _as_ important as hard work and smarts.\nHopefully, if you work hard and build a strong track record, you will gradually be able to get access. If not for your\nfirst company so maybe your second, or your third. So be patient.\n\n### Living is also part of Life\n\nI love working. I work more than almost everyone else around me. Iâ€™ve built a lifestyle that makes that possible. Iâ€™ve\nsimplified all aspects of my life to the extreme. It means I donâ€™t socialize as much or have major personal projects. I\nbuy services for everything (cleaning, renovation, etc). I have a few hobbies (cooking, photography, chess, music) but\nall are compatible with my workload.\n\nMy wife and I have found a balance after many years living together where we enjoy life. Balancing risk and reward in\nentrepreneurship impacts your life in more ways than most people appreciate. So when navigating the risk-reward curve,\nmake sure to also ask yourself: are my choices compatible with my â€œotherâ€ life choices? Many extremely â€œsuccessfulâ€ (\nread: rich and famous) entrepreneurs have rather disastrous personal life stories. Divorce, mental health issues, heart\nfailure, frequent conflicts with loved ones. You name it. This is part of the equation, and those that dismiss this part\nlikely get a brutal awakening sooner or later.\n\n### Conclusion\n\nWhat is my point? My point is that you have to know yourself and know what you want, in order to make the right choices\nfor yourself and your company. There are so many variations possible, and there is no universal truth to what is â€œbestâ€.\nIs it more important for you to become a multi-billionaire than anything else? Well, then you need to accept a lower\nprobability of success, much more work, and a more narrow set of possible choices. If you prefer a higher probability of\nsuccess, then likely you are giving away some potential upside. It starts already when deciding to quit your job to\nstart a company. The choice with the highest probability of success is to not quit. But deciding to quit is just the\n_first_ choice. Balancing risk with reward is part of the journey for entrepreneurs every single day.\n\nPersonally, despite all these challenges, building a tech company is the most fun Iâ€™ve ever had!","src/content/blog/risk-and-reward-when-turning-tech-into-business.md","367832147775abf9",{"html":512,"metadata":513},"\u003Cp>Technology and entrepreneurship are lifelong passions of mine. Most things have not been invented yet, and imagining all\nthe cool stuff we will enjoy in the future is a favorite past-time. But how do you turn new technology into valuable\nproducts, and how is that related to risk and reward?\u003C/p>\n\u003Ch3 id=\"prelude\">Prelude\u003C/h3>\n\u003Cp>Insight comes from reflecting on our experiences. To understand my views on technology, entrepreneurship, risk, and\nreward, a brief bio is probably in order. I knew already in high school that I wanted to be an entrepreneur (how that\nhappened is another story ðŸ˜…). My strategy for how to contribute to innovation started with pursuing a degree with a\nheavy focus on mathematics. The reason for picking mathematics was that I was \u003Cem>so\u003C/em> interested in programming and\nleadership that I figured I could learn those anyway. Mathematics, on the other hand, was something I needed help\nlearning. While studying, I made sure to be very active in various student organizations and non-profits. That gave me\nan understanding of what it takes to inspire people to get things done, even without a salary (just like in a startup!).\u003C/p>\n\u003Cp>Thanks to a great mentor I decided to learn a craft in my first job. In my case, I choose software engineering. Generic\ncareers like strategy or management consulting disconnect you from the reality of execution. Talking is easy, doing is\nharder, and early-stage innovation management is largely defined by execution. Sure, you are likely to become a solid\nearner if you pick consulting, but you are unlikely to learn or do anything game-changing. All you learn is to optimize\nspreadsheets and ask questions. Not inspire people and provide answers. The only caveat maybe is that consultants make\ngood investors, so there is that at least. ðŸ˜‰\u003C/p>\n\u003Cp>After graduating, I was fortunate enough to get recruited by an early-stage technology startup that allowed me to\ncombine my interest in mathematics, programming, and leadership, but that also introduced a product and commercial\naspect to technology. Almost 15 years after deciding to start a business, it was finally time in 2018. Building a\ncompany means my experiences in mathematics, programming, leadership, and commercial strategy are finally converging. So\nwhat have I learned?\u003C/p>\n\u003Ch3 id=\"setting-a-strong-foundation\">Setting a Strong Foundation\u003C/h3>\n\u003Cp>Successfully turning technology into a business is incredibly complex, and involves balancing a very large number of\naspects. In my particular choice of entrepreneurship, i.e. enterprise deep tech, combining an intimate understanding of\nemerging technology with a deep understanding of user needs is the starting point. I think whatever your vertical, you\nhave to be immersed in it to be able to succeed. You have to live and breathe the subject matter. Why? Because there are\nso many opinions, and so much information, that the only way to find a path is to have enough intuition and integrity to\npick a path yourself. And picking a successful path means you will have to know what information to listen to, and what\nto ignore.\u003C/p>\n\u003Cp>Personally, I believe in the following playbook:\u003C/p>\n\u003Cp>\u003Cstrong>Step 1. Look at the world and ask yourself â€œwhat is inevitable?â€.\u003C/strong> I think for example that increasingly intelligent\nmachines are inevitable. I also think a radical shift away from oil is inevitable. There are lots of large shifts going\non in the world, and as long as you align yourself with one of them, you will be fine. If your company succeeds, you\nwill have to ride this wave for many, many years so make sure you like the wave.\u003C/p>\n\u003Cp>\u003Cstrong>Step 2. Learn everything about the low-level details of your space and tech.\u003C/strong> The key to early-stage success is being\nextremely concrete. This is where most generalists fail. They have too casual an understanding of their domain. Learning\neverything takes time. In my case, maybe 10 years. I worked patiently with the nitty-gritty details, trying to solve\nproblems, talking to smart people, and testing things. Rapid success is usually the result of very, very thorough\npreparations.\u003C/p>\n\u003Cp>\u003Cstrong>Step 3. Find something everyone is wrong about but that is necessary to get right.\u003C/strong> True value comes from scarcity.\nYou will never make much difference if all you do is repeat what everyone already knows. Finding something that a large\ngroup of people is wrong about is key to building a valuable company. For example, Tesla is built on the conviction that\na rapid shift to EVs did not have to take decades. Incumbents said, â€œwe cannot move fasterâ€. Elon Musk said, â€œhold my\nbeerâ€. When we started Annotell, everyone said â€œComputers are going to replace humansâ€. I said, â€œNo, but with great\ndatasets, we can make computers a little less stupidâ€.\u003C/p>\n\u003Cp>\u003Cstrong>Step 4. Provide a super-concrete solution that helps users get it right.\u003C/strong> There is a huge difference between\ninteresting and valuable. There is only one way to really figure out if something is valuable: getting others to pay for\nit. For some businesses, the first invoice takes a decade. For others, it takes two days. Sooner or later, revenue is\nthe way we define value. How much your margins matter depends on volume and position in the market, but revenue is not\noptional. The only way to get top-line growth is to close the gap between a userâ€™s need, your product, and their wallet.\u003C/p>\n\u003Cp>\u003Cstrong>Step 5. Inspire a world-class team to rally behind your idea.\u003C/strong> Without a great team, you are not going to make it.\nThe massive shift you are part of, what you point out is wrong, the solution you offer, and your passion as a founder -\nall these factors have to inspire a large enough group of talented people to fight for your company.\u003C/p>\n\u003Cp>\u003Cstrong>Step 6. Ensure excellent execution.\u003C/strong> For all the big-picture questions you have to ask yourself up to this point, you\nalso need to ensure that execution is world-class. This becomes much easier with a world-class team, but even then you\nneed to ensure great management, clear expectations, well-defined processes, etc. Many entrepreneurs I know dismiss\nprocesses as a â€œbig corp thingâ€. Those people are unlikely to build a large and successful business. Growth requires\nprocesses.\u003C/p>\n\u003Cp>\u003Cstrong>Step 7. Map out your growth journey.\u003C/strong> By now, you have the basics of a company. It probably took you many years to\nget here. You might even have a few customers. It is time to estimate â€œHow large can this get?â€ and â€œWhat is the right\npath from here?â€. Weirdly enough, some entrepreneurs start with these questions before steps 1-6. Few such entrepreneurs\nsucceed in my experience. If all you care about is raising a huge round from a famous VC, then of course you need to\nmake very deliberate choices up to this point. But thatâ€™s not the only way to succeed, and it is not the only sort of\ncompany you can build. This is where the risk-reward nexus comes into play. If you nail points 1-6 you will have a\ncompany, and it is likely to make money. As an entrepreneur, you now need to ask yourself â€œHow much risk am I willing to\ntake when balancing the future value of my company, and my probability of survival?â€\u003C/p>\n\u003Ch3 id=\"balancing-risk-and-reward\">Balancing Risk and Reward\u003C/h3>\n\u003Cp>The more audacious the proposed product, the larger the risk typically. Letâ€™s say we \u003Cem>think\u003C/em> we have found a radical new\nway to generate energy, but that the capital expenditure required is multiple billions. Then we need to convince enough\npeople that our solution is in fact likely to succeed and that investing in you and your team is the best way to make it\nreal. The nice thing about expensive startups is that they are less likely to get a lot of competition. The bad thing is\nthat they are expensive, and hence financially risky.\u003C/p>\n\u003Cp>All investors know this, but I wonder if all entrepreneurs know this? My point is that entrepreneurs need to understand\nthe balance between risk and reward when deciding to turn technology into products. Letâ€™s look at a few scenarios:\u003C/p>\n\u003Cp>Letâ€™s say you have a great idea for a consumer mobile app, and it requires $5M to build a sufficiently good first\nversion to launch it, what are the risks? Of course, the largest risk is that you fail to convert the $5M into a\nsufficiently good first version to attract users. Without strong usage metrics, you will likely fail to raise follow-up\nrounds. So investors will evaluate you personally, and your potential. Usually, with these cases, the risk is mostly on\nthe execution side. Consumer markets are large, but the probability of successfully capturing a large part of consumers\nis low. Smart, hardworking teams with the right pedigree are more likely to figure out what works, so they get more\nfunding.\u003C/p>\n\u003Cp>If instead you have found a promising technology that might be able to change the way companies solve a big problem, but\nyou need $50M to make it \u003Cem>real\u003C/em> \u003Cem>enough\u003C/em> for a proof-of-concept, then what are the risks? Now the risks include both\nexecution, i.e. will you be able to turn the $50M into something good, and market size, i.e. is it worth putting $50M\ninto solving this problem?\u003C/p>\n\u003Cp>As a founder, you have to ask yourself: what risks am I comfortable with? Typically, the larger the upside, the larger\nthe risk. A capital expensive start-up can weaponize money to dominate a market, assuming size translates into an\nobvious advantage. The more scalable your business model, i.e. the lower the service fraction and the higher the overlap\nbetween customers, the more money you need to defend yourself, but the larger you can get. Think search and social\nmedia. Low-touch products that require huge amounts of capital, but where success lands you a money printing monopoly.\u003C/p>\n\u003Cp>On the other hand, if your business model involves more service and more expertise, you are less likely to get\ndisrupted, but you limit your own growth. A smart, hardworking team can always make a specific customer happy. Thatâ€™s\nwhat consulting is about. Itâ€™s lower risk but also a much lower reward. Building a large company is about figuring out\nwhere on the risk-reward curve you want to operate, and what you want to achieve - while still not compromising with the\nplaybook above.\u003C/p>\n\u003Ch3 id=\"the-world-is-not-fair\">The World is not Fair\u003C/h3>\n\u003Cp>This risk-reward operating curve is also a big source of unfairness. Since so much of building a business is\nspeculation, trust and patience play a big part in overcoming challenges. If you have the right pedigree and network,\nthere is funding available that gives you time and freedom, or power, that others cannot afford. If you are not of the\nâ€œrightâ€ background, and cannot get access to such networks, the magnitude of your idea might not overcome the hurdles in\nyour way. Likely, this is changing as more money is available to startups and competition among venture firms increases.\nBut itâ€™s worth reminding everyone that getting access to the unfair advantages that come with premium funding can be\nsignificant. If you truly want to change the world, relationships and access are \u003Cem>as\u003C/em> important as hard work and smarts.\nHopefully, if you work hard and build a strong track record, you will gradually be able to get access. If not for your\nfirst company so maybe your second, or your third. So be patient.\u003C/p>\n\u003Ch3 id=\"living-is-also-part-of-life\">Living is also part of Life\u003C/h3>\n\u003Cp>I love working. I work more than almost everyone else around me. Iâ€™ve built a lifestyle that makes that possible. Iâ€™ve\nsimplified all aspects of my life to the extreme. It means I donâ€™t socialize as much or have major personal projects. I\nbuy services for everything (cleaning, renovation, etc). I have a few hobbies (cooking, photography, chess, music) but\nall are compatible with my workload.\u003C/p>\n\u003Cp>My wife and I have found a balance after many years living together where we enjoy life. Balancing risk and reward in\nentrepreneurship impacts your life in more ways than most people appreciate. So when navigating the risk-reward curve,\nmake sure to also ask yourself: are my choices compatible with my â€œotherâ€ life choices? Many extremely â€œsuccessfulâ€ (\nread: rich and famous) entrepreneurs have rather disastrous personal life stories. Divorce, mental health issues, heart\nfailure, frequent conflicts with loved ones. You name it. This is part of the equation, and those that dismiss this part\nlikely get a brutal awakening sooner or later.\u003C/p>\n\u003Ch3 id=\"conclusion\">Conclusion\u003C/h3>\n\u003Cp>What is my point? My point is that you have to know yourself and know what you want, in order to make the right choices\nfor yourself and your company. There are so many variations possible, and there is no universal truth to what is â€œbestâ€.\nIs it more important for you to become a multi-billionaire than anything else? Well, then you need to accept a lower\nprobability of success, much more work, and a more narrow set of possible choices. If you prefer a higher probability of\nsuccess, then likely you are giving away some potential upside. It starts already when deciding to quit your job to\nstart a company. The choice with the highest probability of success is to not quit. But deciding to quit is just the\n\u003Cem>first\u003C/em> choice. Balancing risk with reward is part of the journey for entrepreneurs every single day.\u003C/p>\n\u003Cp>Personally, despite all these challenges, building a tech company is the most fun Iâ€™ve ever had!\u003C/p>",{"headings":514,"localImagePaths":531,"remoteImagePaths":532,"frontmatter":533,"imagePaths":534},[515,518,521,524,527,530],{"depth":24,"slug":516,"text":517},"prelude","Prelude",{"depth":24,"slug":519,"text":520},"setting-a-strong-foundation","Setting a Strong Foundation",{"depth":24,"slug":522,"text":523},"balancing-risk-and-reward","Balancing Risk and Reward",{"depth":24,"slug":525,"text":526},"the-world-is-not-fair","The World is not Fair",{"depth":24,"slug":528,"text":529},"living-is-also-part-of-life","Living is also part of Life",{"depth":24,"slug":223,"text":224},[],[],{"pubDate":507,"title":506},[],"risk-and-reward-when-turning-tech-into-business.md","reflections-on-life-and-entrepreneurship",{"id":536,"data":538,"body":541,"filePath":542,"digest":543,"rendered":544,"legacyId":579},{"title":539,"pubDate":540},"Reflections on Life and Entrepreneurship","2023-01-04","I regularly reflect on what I have experienced to extract patterns and ideas to guide my next steps. I have two goals:\n\n1) enjoy life with loved ones and 2) build extraordinary things. Balancing these two things is hard, so most of my\n   reflections are about the tension between them. Year by year, my thinking evolves. This could probably be ten posts,\n   but\n   Iâ€™m writing for myself more than anyone else, so there is no need to optimize for engagement ðŸ˜‰ This is my latest\n   iteration:\n\n### Play the Long Game\n\n**Always play the long gameâ™Ÿï¸** Or: â€œBe stubborn on vision, but flexible on details,â€ as Jeff Besoz put it. If you\ncombine this with â€œbuild with leverage,â€ you quickly realize that you should hire for all non-strategic activities if\nyou want to create something huge. I avoid ever finding myself doing repetitive manual work. I still think you need to\nlearn by doing many things yourself. You cannot build a business around something you do not understand. Get your hands\ndirty. Just do not get stuck doing the same thing over and over. It accumulates no value and comes with zero leverage.\nHire for such tasks. I _\"squint\"_ a lot. What I mean by that is I deliberately do not see most of the details. A\npractical example: I do not always pay my bills on time if I'm busy with something more substantial. Sure, I might get\nslapped with a late fee, but if the leverage on what I'm doing exceeds that late fee, I'm happy to pay it. I even did\nthis when I had much less money than today. There are long periods when I let nothing distract me from the high-leverage\nactivity I'm engaged in. I will postpone everything else until I'm done. I should add that I'm not judging, i.e., there\ncan be great pleasure in craftsmanship. If you get joy from perfecting a task, you should do it. All Iâ€™m saying is that\nit is pretty unlikely it will lead to an extraordinary impact.\n\n* **Donâ€™t play too long of a game â˜ ï¸** Imagine postponing everything of short-term value in life, and then BAM: you get\n  diagnosed with terminal cancer and have six months to live. Will you regret what you've done with your life if that\n  happens? Then you should probably change things. Treat yourselfâ€”balance in all things. If you do not celebrate\n  success, reward yourself with time off, eat good food, exercise, and all the other things that make life worth living,\n  you will soon regret many decisions.\n\n### Prioritize Emotional Health\n\nAlmost all situations have an emotional component, so itâ€™s helpful to express\nyour feelings. Share them with loved ones, coworkers, and friends. Doing so helps to build trust, understanding, and\nconnection. And it makes you much more resilient.\n\n* **See a therapist ðŸ›‹ï¸** At least try it if you havenâ€™t. Work through your issues. We all have them. Confront them and\n  process them. â€œFixingâ€ them isnâ€™t the goal; it is more about learning to live with them. While the stigma around\n  mental health issues is weakened, I think too many people avoid dealing with them.\n\n### Money, Time, and Leverage\n\n**There is never enough money ðŸ’¸** I've set new goals for myself every year for as long as I can remember. Some of them\nhave been related to money. Get a salary of a minimum of $X/month. Buy a house for $Y million. Pay off all my student\ndebt before turning 30. Not so humble but relevant context: I was a millionaire without student debt by 30. As you\nprogress, I promise you that you will always find a new level you haven't reached that becomes your new desire. I have\nlearned that you have to balance such goals with goals for quality of life. As much as I want to reach specific\nfinancial goals, I also want to make sure I am taking time to appreciate the people in my life.\n\n* **There is never enough time â³** Time and money are non-fungible combatants in a lifelong trade-off. If you want more\n  money, you will get less time. If you want more time, you will get less money. Always ask yourself: \"What is the price\n  of an hour, and is what I am doing generating value that exceeds the value of spending this hour with loved ones?\"\n  Also, remember that the marginal value of money is rapidly diminishing, so while your answer might favor making money\n  initially, it usually tilts the other way quickly. I recommend\n  reading â€œ[Life is Short](http://paulgraham.com/vb.html)â€ by Paul Graham.\n\n* **Build with leverage ðŸ”§** The best way to get _both_ _time and money_ is to focus on activities with leverage. Is the\n  work I am putting in generating more value than the price of an hour of work? Am I accumulating wealth long-term as a\n  consequence of my actions? Equity in a product company is the ultimate way to leverage your time. Whatever\n  improvements you provide to the company generate more value in your equity, assuming the product is resold with low\n  direct cost (e.g., software). This is why consulting is the worst job in the world. It comes with higher short-term\n  salary and no responsibility, but without long-term value. It is the fast food of work.\n\n### Uniqueness and Competition\n\n**Value comes from scarcity 1ï¸âƒ£** I know, I know, everyone knows about supply and demand. But I still regularly fail to\nremember this simple thing. To create something extraordinarily valuable, you have to be unique. You have to constantly\nwork on your positioning to find a \"blue ocean\"â€ Relentless experimentation is required since new things aren't found by\nlooking at what others do. It can only be found by independently trying new things. Ask your customers as often as you\ncan, \"What do you think of our offering? Is it similar to something else? What is it most similar to?\" Virtually all\ncompanies are similar to someone else, so be paranoid and persistent when asking. Then work on your positioning in\nrelation to others until you look like nothing else. Some might say, \"we care too much about the competition.\" Only\nlisten to those people if you are accused of copying the competition. Copying has very low returns. Care about the\ncompetition by way of being different. If your offering overlaps, move in a new direction.\n\n* **Higher quality is a weak form of uniqueness ðŸª¨** Once there are alternatives in the market, and unless quality is\n  objectively measurable and better to the point of being a different product, buying will trend to the cheapest option.\n  You might think your version is 10x better, but I haven't seen many examples of when that can be proven so that\n  customers will pay 10x more. Most people overestimate their differentiation. Be careful not to underestimate the power\n  of pricing, or cheaper competitors will crush you. Innovate to the point of uniqueness, or make sure you win the price\n  race. To quote Peter Thiel: \"Competition is for losers.\"\n\n### Luck, Betting, and Outcomes\n\n**A one-in-a-million outcom [**requires betting**](https://langkilde.\nse/post/2022-07-20-extraordinary-success-requires-betting) and luck ðŸ€**\nSuccessful people usually have a powerful internal locus of control, i.e., they believe that their actions and decisions\ndirectly and significantly influence their behavior, choices, and outcomes. While that is true for most of the area\nunder the curve, outliers are primarily random. Serendipitous timing and coincidence play a considerable part. Of\ncourse, luck in the hands of a passive person will not make much of a difference. You can manufacture some amount of\nluck by seeking the right circumstances. But excellent performance may not be enough to reach the one-in-a-million\noutcome you dream about. You also need a fair amount of luck, and acknowledging that will make you happier.\n\n* **Focus on the quality of your efforts, not the outcome of your bets ðŸ’ªðŸ¼** Since extraordinary outcomes require luck,\n  you cannot get sad if you do not experience a one-in-a-million outcome. I suspect a large number of people work very\n  hard but are never lucky enough to attain what they think is their full potential. Recognizing this fact does not take\n  away from the extraordinary effort it takes to capitalize on luck. It simply means you must be kind to yourself and\n  focus on your work. The part that is up to chance isn't worth worrying about.\n\n* **Learn to improve your odds when exploring the unknown to find unique value first ðŸ”­** One of the most valuable life\n  skills is improving your ability to systematically explore the unknown in search of value. While striking proverbial\n  gold takes luck, you can improve your odds. Find ways to do minimum lovable products that you can get feedback on. Ask\n  for feedback early. Learn to ask for the right sort of feedback. Learn the difference between interesting and\n  valuable. People will only pay for that which is valuable. Problem identification, problem validation, solutions\n  prototyping, and customer feedback. Learning a great loop for this that you feed with a lot of crazy experimentation\n  will eventually lead you to something valuable and unexploited.\n\n**Products are not scientific breakthroughs; products wrap new technology in a layer of usability targeting a specific\ngroup of users ðŸ”¬** Doing research means having the persistence and mental power to push the bleeding edge of human\nknowledge a tiny bit forward. This image tells you what that is like:\n\n![](https://storage.googleapis.com/langkilde-se-images/8939fd90-7b6d-4097-a555-e21d8fc032a1.jpeg)\n\nCompanies rarely invent new things but frequently retrofit scientific results for commercial use. There is a transition\nfrom research to product that usually takes years. The first scientific results are meh. If you squint, you can sort of\nsee a future unicorn. But mostly, it just looks like a very unstable donkey. Year by year, progress is made. At some\npoint, you hit an inflection point where the technology is ready for commercial use. Timing that inflection requires\nluck. If you find yourself in the right place at the right time, then be prepared to put in an extraordinary amount of\nwork. What you will be doing at this point isn't inventing something new but instead connecting new technology to users\nin a way that brings them value. Doing that in a scalable way, with strong marketing, sales, and customer success, is\nthe lion's share of building a business. The science part is usually done long before then. Sure, if your company has\nplenty of cash flow, you can invest in research, but that's very different from product development. Product development\nis about wrapping new technology in a layer of usability that makes it possible to distribute it scalably.\n\n### Think Globally, Scale Quickly\n\n**Build for massive size and a global footprint quickly when you find something promising.** Building a global footprint\nwill be necessary to survive, no matter how strong your idea or team is. Competition is ruthless, so you must weaponize\nmoney and size to stay ahead. That means seeking places where money and talent come at higher concentration. While the\nplaying field is increasingly leveled as more and more companies adopt remote working policies, networks are still best\nmade on the ground and in person. So start setting up hubs around the world quickly.\n\n**Be a prolific creator.** Practice expressing your ideas constantly. Write, talk, paint, or record music. Whichever is\nyour preferred medium, create constantly. Do you think a device should be built? Make a prototype and inspire people. Do\nyou think your company should adopt a new strategy? Write it down and pitch it. Do you think a piece of software should\nexist? Write it and put it into production.\n\n* **Be the sort of person that suggests solutions rather than points out problems.** You might feel entitled to\n  complain, but it is rarely helpful without also being part of fixing the situation. Feedback is one thing: \"When you\n  say that, I feel this way.\" But just saying, \"I am missing this in the strategy,\" without suggesting what to add, is a\n  waste of time. If you feel something is missing, nudge in a direction. Say, \"I've been thinking, and I feel our\n  strategy needs more X. Here is a draft I've made that captures that. Can we iterate on it together?\" Waaaaay more\n  powerful. It is about creating rather than just analyzing.\n\n* **Creating means committing long enough.** It takes time and effort to create something. You have to pick an option\n  and work on it for long enough so that something comes out. There is always the risk you bet on the wrong horse. But\n  if you constantly switch from one thing to the next without actually following through, you will not create anything.\n  Learn to live with the risk of wasting time and instead make things constantly. If what you make isn't appreciated,\n  make something else.\n\n### Sacrifice and Hard Work\n\n**Achievement requires sacrifices.** Each individual has to decide what they are willing to sacrifice to achieve their\ngoals. I've realized that while I'm prepared to sacrifice more than most people I've met, there are limits. Deep down, I\nthink moving to San Fransisco would increase my chances of building a global business. But doing that is not more\nimportant than my family. I want to be close to my relatives. I want to raise my child in Sweden. When you pick role\nmodels, ask yourself, \"Does this person value what I value? Am I prepared to make the sacrifices this person has made?\".\nRemind yourself constantly when you look at other people's achievements: \"Is the alternative cost of their achievements\nacceptable to me?\".\n\n* **Most people underestimate the power of hard work.** Being persistent, patient, and ready to make sacrifices are some\n  of the most critical traits for achieving success. For all the talk of sustainability and reasonable working hours, I\n  do not think anyone profoundly changed the world working 9-17. All highly successful people I know are obsessed and\n  push themselves to the brink of burning out. I'm not saying everyone should work to exhaustion; I'm just saying that's\n  what it takes to achieve extraordinary things. Again, balancing things is the hard partâ€¦\n\n* **Sometimes all it takes to succeed is to\n  be [**the last one standing**](https://langkilde.se/post/2022-04-09-the-energy-to-keep-going) .** Most people are not\n  prepared to endure the hardship required for success. There are always reasons to give up and stop. Competitors are\n  too strong, your product is not good enough, and you are exhausted. What is even worse is that: sometimes, the right\n  thing is to quit. Maybe you are, like Sisyphus, fighting a futile battle. It is impossible to say in general, but I\n  see more people stopping than not, and most that keep going are eventually successful. Persistence combined with\n  evolution is the way to go.\n\n* **Are you prepared to be ruthless when you have to?** Even if it is indirect, inflicting pain on others is part of\n  building a global business. You will have to fire underperforming people, you need to negotiate hard, you will have to\n  disappoint people, and you will make enemies no matter how nice you try to be. Are you comfortable with this? How far\n  are you willing to go to win?\n\n### Relationships and Influence\n\n**The world runs on relationships.** Forging long-term, strong bonds with other people is one of the most critical\ndifferentiators to innovate and build. The benefits include:\n\n* **Smart friends give the best feedback.** The most valuable thing in life is people telling you what to improve. Or\n  when you are wrong. Getting great feedback requires solid relationships. Most people will not give honest feedback if\n  they don't know you very well. It takes discipline, patience and skill to provide excellent feedback. Mentoring\n  requires a particular form of friendship. Finding excellent mentors is something to cherish.\n\n* **Access to talent.** Every ambitious project requires a group of excellent, hard-working people. While the virtues of\n  the core idea span the potential of a project, your ability to attain the full potential through adjustments and\n  challenges is limited by your team. Building relationships with high-performing individuals you can bring along for\n  the journey is a critical differentiator.\n\n* **Access to capital.** All innovation is risky. The most valuable innovations emerge when someone bets something is\n  inevitable before most people have even heard of it. You will need a lot of money to make something that seems\n  impossible possible. More money will always be better if you want to build something genuinely extraordinary happen,\n  and that requires connections. A big part of early-stage investing is evaluating the character of the founders.\n  Establishing solid relationships and getting strong references will help significantly in this process.\n\n* **Champions for your ideas.** Ideas are ubiquitous, but having influence is not. Sometimes, for something to go from\n  impossible to apparent, all you need are a few key people supporting the idea. Humans are prone to groupthink, and\n  nudging the group onto a new trajectory requires influence. A strong network of influential people will radically\n  improve your chances of establishing an idea.\n\n### The Power of Storytelling\n\n**The world runs on stories.** For millennia we have been telling each other stories. Great leaders have inspired people\nby crafting a narrative that provides purpose. A core human need is a sense of purpose and inspiration. Without it, we\nquickly get depressed. We need to believe in something or someone.\n\n* **Start with why.** In the words of the great Simon Sinek, â€œPeople donâ€™t buy what you do; they buy why you do it.â€\n  Having a â€œwhyâ€ behind what you are doing is essential. People are like bloodhounds that immediately smell bullshit and\n  fake virtue signaling. Corporate words that have no real meaning will not inspire anyone. If your goal is to make\n  money, be honest about it. If your goal is to do social good, then be consistent.\n\n* **Visualize your stories.** I've underestimated the power of visuals for a long time. Symbols are powerful. Images,\n  objects. Hell, even a logo. Things that connect you with others and form your identity. We must be constantly reminded\n  of our community and our shared pursuit to stick together. A prototype, a video, or an image. Make your dream\n  accessible to others.\n\n* **Repeat, repeat, repeat.** Most people underestimate how often you have to say something for others to take it in.\n  The world is noisy, and people are very busy with their thoughts and problems. That means they will only hear a\n  fraction of what you are trying to say. Tell your story until you are tired of hearing your voice.\n\n**Be mindful of what you read.** I have tailored my books, apps, and subscriptions to feed me content that will\npositively shape my thinking. As with food, a healthy diet is varied. Lots of vegetables (business books, technology\nbooks, biographies, etc.) but also things like science fiction adventures and really good blogs. Lately, I've mixed in\nbooks on mindfulness and longevity. Exposure to specific ideas will shape your thinking, so inspire yourself to think\nhealthy, valuable things.\n\n**Pessimists sound smart; optimists make money.** This is one of my all-time favorite sayings, credit to Nat Friedman,\nthe founder of GitHub. There is never a shortage of people telling you why something won't work or why something is a\nbad idea. It takes a special kind of person to focus on the positives, find solutions and make things happen.","src/content/blog/reflections-on-life-and-entrepreneurship.md","4de7f9fc711e3dbf",{"html":545,"metadata":546},"\u003Cp>I regularly reflect on what I have experienced to extract patterns and ideas to guide my next steps. I have two goals:\u003C/p>\n\u003Col>\n\u003Cli>enjoy life with loved ones and 2) build extraordinary things. Balancing these two things is hard, so most of my\nreflections are about the tension between them. Year by year, my thinking evolves. This could probably be ten posts,\nbut\nIâ€™m writing for myself more than anyone else, so there is no need to optimize for engagement ðŸ˜‰ This is my latest\niteration:\u003C/li>\n\u003C/ol>\n\u003Ch3 id=\"play-the-long-game\">Play the Long Game\u003C/h3>\n\u003Cp>\u003Cstrong>Always play the long gameâ™Ÿï¸\u003C/strong> Or: â€œBe stubborn on vision, but flexible on details,â€ as Jeff Besoz put it. If you\ncombine this with â€œbuild with leverage,â€ you quickly realize that you should hire for all non-strategic activities if\nyou want to create something huge. I avoid ever finding myself doing repetitive manual work. I still think you need to\nlearn by doing many things yourself. You cannot build a business around something you do not understand. Get your hands\ndirty. Just do not get stuck doing the same thing over and over. It accumulates no value and comes with zero leverage.\nHire for such tasks. I \u003Cem>â€œsquintâ€\u003C/em> a lot. What I mean by that is I deliberately do not see most of the details. A\npractical example: I do not always pay my bills on time if Iâ€™m busy with something more substantial. Sure, I might get\nslapped with a late fee, but if the leverage on what Iâ€™m doing exceeds that late fee, Iâ€™m happy to pay it. I even did\nthis when I had much less money than today. There are long periods when I let nothing distract me from the high-leverage\nactivity Iâ€™m engaged in. I will postpone everything else until Iâ€™m done. I should add that Iâ€™m not judging, i.e., there\ncan be great pleasure in craftsmanship. If you get joy from perfecting a task, you should do it. All Iâ€™m saying is that\nit is pretty unlikely it will lead to an extraordinary impact.\u003C/p>\n\u003Cul>\n\u003Cli>\u003Cstrong>Donâ€™t play too long of a game â˜ ï¸\u003C/strong> Imagine postponing everything of short-term value in life, and then BAM: you get\ndiagnosed with terminal cancer and have six months to live. Will you regret what youâ€™ve done with your life if that\nhappens? Then you should probably change things. Treat yourselfâ€”balance in all things. If you do not celebrate\nsuccess, reward yourself with time off, eat good food, exercise, and all the other things that make life worth living,\nyou will soon regret many decisions.\u003C/li>\n\u003C/ul>\n\u003Ch3 id=\"prioritize-emotional-health\">Prioritize Emotional Health\u003C/h3>\n\u003Cp>Almost all situations have an emotional component, so itâ€™s helpful to express\nyour feelings. Share them with loved ones, coworkers, and friends. Doing so helps to build trust, understanding, and\nconnection. And it makes you much more resilient.\u003C/p>\n\u003Cul>\n\u003Cli>\u003Cstrong>See a therapist ðŸ›‹ï¸\u003C/strong> At least try it if you havenâ€™t. Work through your issues. We all have them. Confront them and\nprocess them. â€œFixingâ€ them isnâ€™t the goal; it is more about learning to live with them. While the stigma around\nmental health issues is weakened, I think too many people avoid dealing with them.\u003C/li>\n\u003C/ul>\n\u003Ch3 id=\"money-time-and-leverage\">Money, Time, and Leverage\u003C/h3>\n\u003Cp>\u003Cstrong>There is never enough money ðŸ’¸\u003C/strong> Iâ€™ve set new goals for myself every year for as long as I can remember. Some of them\nhave been related to money. Get a salary of a minimum of $X/month. Buy a house for $Y million. Pay off all my student\ndebt before turning 30. Not so humble but relevant context: I was a millionaire without student debt by 30. As you\nprogress, I promise you that you will always find a new level you havenâ€™t reached that becomes your new desire. I have\nlearned that you have to balance such goals with goals for quality of life. As much as I want to reach specific\nfinancial goals, I also want to make sure I am taking time to appreciate the people in my life.\u003C/p>\n\u003Cul>\n\u003Cli>\n\u003Cp>\u003Cstrong>There is never enough time â³\u003C/strong> Time and money are non-fungible combatants in a lifelong trade-off. If you want more\nmoney, you will get less time. If you want more time, you will get less money. Always ask yourself: â€œWhat is the price\nof an hour, and is what I am doing generating value that exceeds the value of spending this hour with loved ones?â€\nAlso, remember that the marginal value of money is rapidly diminishing, so while your answer might favor making money\ninitially, it usually tilts the other way quickly. I recommend\nreading â€œ\u003Ca href=\"http://paulgraham.com/vb.html\">Life is Short\u003C/a>â€ by Paul Graham.\u003C/p>\n\u003C/li>\n\u003Cli>\n\u003Cp>\u003Cstrong>Build with leverage ðŸ”§\u003C/strong> The best way to get \u003Cem>both\u003C/em> \u003Cem>time and money\u003C/em> is to focus on activities with leverage. Is the\nwork I am putting in generating more value than the price of an hour of work? Am I accumulating wealth long-term as a\nconsequence of my actions? Equity in a product company is the ultimate way to leverage your time. Whatever\nimprovements you provide to the company generate more value in your equity, assuming the product is resold with low\ndirect cost (e.g., software). This is why consulting is the worst job in the world. It comes with higher short-term\nsalary and no responsibility, but without long-term value. It is the fast food of work.\u003C/p>\n\u003C/li>\n\u003C/ul>\n\u003Ch3 id=\"uniqueness-and-competition\">Uniqueness and Competition\u003C/h3>\n\u003Cp>\u003Cstrong>Value comes from scarcity 1ï¸âƒ£\u003C/strong> I know, I know, everyone knows about supply and demand. But I still regularly fail to\nremember this simple thing. To create something extraordinarily valuable, you have to be unique. You have to constantly\nwork on your positioning to find a â€œblue oceanâ€â€ Relentless experimentation is required since new things arenâ€™t found by\nlooking at what others do. It can only be found by independently trying new things. Ask your customers as often as you\ncan, â€œWhat do you think of our offering? Is it similar to something else? What is it most similar to?â€ Virtually all\ncompanies are similar to someone else, so be paranoid and persistent when asking. Then work on your positioning in\nrelation to others until you look like nothing else. Some might say, â€œwe care too much about the competition.â€ Only\nlisten to those people if you are accused of copying the competition. Copying has very low returns. Care about the\ncompetition by way of being different. If your offering overlaps, move in a new direction.\u003C/p>\n\u003Cul>\n\u003Cli>\u003Cstrong>Higher quality is a weak form of uniqueness ðŸª¨\u003C/strong> Once there are alternatives in the market, and unless quality is\nobjectively measurable and better to the point of being a different product, buying will trend to the cheapest option.\nYou might think your version is 10x better, but I havenâ€™t seen many examples of when that can be proven so that\ncustomers will pay 10x more. Most people overestimate their differentiation. Be careful not to underestimate the power\nof pricing, or cheaper competitors will crush you. Innovate to the point of uniqueness, or make sure you win the price\nrace. To quote Peter Thiel: â€œCompetition is for losers.â€\u003C/li>\n\u003C/ul>\n\u003Ch3 id=\"luck-betting-and-outcomes\">Luck, Betting, and Outcomes\u003C/h3>\n\u003Cp>\u003Cstrong>A one-in-a-million outcom [\u003Cstrong>requires betting\u003C/strong>](\u003Ca href=\"https://langkilde\">https://langkilde\u003C/a>.\nse/post/2022-07-20-extraordinary-success-requires-betting) and luck ðŸ€\u003C/strong>\nSuccessful people usually have a powerful internal locus of control, i.e., they believe that their actions and decisions\ndirectly and significantly influence their behavior, choices, and outcomes. While that is true for most of the area\nunder the curve, outliers are primarily random. Serendipitous timing and coincidence play a considerable part. Of\ncourse, luck in the hands of a passive person will not make much of a difference. You can manufacture some amount of\nluck by seeking the right circumstances. But excellent performance may not be enough to reach the one-in-a-million\noutcome you dream about. You also need a fair amount of luck, and acknowledging that will make you happier.\u003C/p>\n\u003Cul>\n\u003Cli>\n\u003Cp>\u003Cstrong>Focus on the quality of your efforts, not the outcome of your bets ðŸ’ªðŸ¼\u003C/strong> Since extraordinary outcomes require luck,\nyou cannot get sad if you do not experience a one-in-a-million outcome. I suspect a large number of people work very\nhard but are never lucky enough to attain what they think is their full potential. Recognizing this fact does not take\naway from the extraordinary effort it takes to capitalize on luck. It simply means you must be kind to yourself and\nfocus on your work. The part that is up to chance isnâ€™t worth worrying about.\u003C/p>\n\u003C/li>\n\u003Cli>\n\u003Cp>\u003Cstrong>Learn to improve your odds when exploring the unknown to find unique value first ðŸ”­\u003C/strong> One of the most valuable life\nskills is improving your ability to systematically explore the unknown in search of value. While striking proverbial\ngold takes luck, you can improve your odds. Find ways to do minimum lovable products that you can get feedback on. Ask\nfor feedback early. Learn to ask for the right sort of feedback. Learn the difference between interesting and\nvaluable. People will only pay for that which is valuable. Problem identification, problem validation, solutions\nprototyping, and customer feedback. Learning a great loop for this that you feed with a lot of crazy experimentation\nwill eventually lead you to something valuable and unexploited.\u003C/p>\n\u003C/li>\n\u003C/ul>\n\u003Cp>\u003Cstrong>Products are not scientific breakthroughs; products wrap new technology in a layer of usability targeting a specific\ngroup of users ðŸ”¬\u003C/strong> Doing research means having the persistence and mental power to push the bleeding edge of human\nknowledge a tiny bit forward. This image tells you what that is like:\u003C/p>\n\u003Cp>\u003Cimg src=\"https://storage.googleapis.com/langkilde-se-images/8939fd90-7b6d-4097-a555-e21d8fc032a1.jpeg\" alt=\"\">\u003C/p>\n\u003Cp>Companies rarely invent new things but frequently retrofit scientific results for commercial use. There is a transition\nfrom research to product that usually takes years. The first scientific results are meh. If you squint, you can sort of\nsee a future unicorn. But mostly, it just looks like a very unstable donkey. Year by year, progress is made. At some\npoint, you hit an inflection point where the technology is ready for commercial use. Timing that inflection requires\nluck. If you find yourself in the right place at the right time, then be prepared to put in an extraordinary amount of\nwork. What you will be doing at this point isnâ€™t inventing something new but instead connecting new technology to users\nin a way that brings them value. Doing that in a scalable way, with strong marketing, sales, and customer success, is\nthe lionâ€™s share of building a business. The science part is usually done long before then. Sure, if your company has\nplenty of cash flow, you can invest in research, but thatâ€™s very different from product development. Product development\nis about wrapping new technology in a layer of usability that makes it possible to distribute it scalably.\u003C/p>\n\u003Ch3 id=\"think-globally-scale-quickly\">Think Globally, Scale Quickly\u003C/h3>\n\u003Cp>\u003Cstrong>Build for massive size and a global footprint quickly when you find something promising.\u003C/strong> Building a global footprint\nwill be necessary to survive, no matter how strong your idea or team is. Competition is ruthless, so you must weaponize\nmoney and size to stay ahead. That means seeking places where money and talent come at higher concentration. While the\nplaying field is increasingly leveled as more and more companies adopt remote working policies, networks are still best\nmade on the ground and in person. So start setting up hubs around the world quickly.\u003C/p>\n\u003Cp>\u003Cstrong>Be a prolific creator.\u003C/strong> Practice expressing your ideas constantly. Write, talk, paint, or record music. Whichever is\nyour preferred medium, create constantly. Do you think a device should be built? Make a prototype and inspire people. Do\nyou think your company should adopt a new strategy? Write it down and pitch it. Do you think a piece of software should\nexist? Write it and put it into production.\u003C/p>\n\u003Cul>\n\u003Cli>\n\u003Cp>\u003Cstrong>Be the sort of person that suggests solutions rather than points out problems.\u003C/strong> You might feel entitled to\ncomplain, but it is rarely helpful without also being part of fixing the situation. Feedback is one thing: â€œWhen you\nsay that, I feel this way.â€ But just saying, â€œI am missing this in the strategy,â€ without suggesting what to add, is a\nwaste of time. If you feel something is missing, nudge in a direction. Say, â€œIâ€™ve been thinking, and I feel our\nstrategy needs more X. Here is a draft Iâ€™ve made that captures that. Can we iterate on it together?â€ Waaaaay more\npowerful. It is about creating rather than just analyzing.\u003C/p>\n\u003C/li>\n\u003Cli>\n\u003Cp>\u003Cstrong>Creating means committing long enough.\u003C/strong> It takes time and effort to create something. You have to pick an option\nand work on it for long enough so that something comes out. There is always the risk you bet on the wrong horse. But\nif you constantly switch from one thing to the next without actually following through, you will not create anything.\nLearn to live with the risk of wasting time and instead make things constantly. If what you make isnâ€™t appreciated,\nmake something else.\u003C/p>\n\u003C/li>\n\u003C/ul>\n\u003Ch3 id=\"sacrifice-and-hard-work\">Sacrifice and Hard Work\u003C/h3>\n\u003Cp>\u003Cstrong>Achievement requires sacrifices.\u003C/strong> Each individual has to decide what they are willing to sacrifice to achieve their\ngoals. Iâ€™ve realized that while Iâ€™m prepared to sacrifice more than most people Iâ€™ve met, there are limits. Deep down, I\nthink moving to San Fransisco would increase my chances of building a global business. But doing that is not more\nimportant than my family. I want to be close to my relatives. I want to raise my child in Sweden. When you pick role\nmodels, ask yourself, â€œDoes this person value what I value? Am I prepared to make the sacrifices this person has made?â€.\nRemind yourself constantly when you look at other peopleâ€™s achievements: â€œIs the alternative cost of their achievements\nacceptable to me?â€.\u003C/p>\n\u003Cul>\n\u003Cli>\n\u003Cp>\u003Cstrong>Most people underestimate the power of hard work.\u003C/strong> Being persistent, patient, and ready to make sacrifices are some\nof the most critical traits for achieving success. For all the talk of sustainability and reasonable working hours, I\ndo not think anyone profoundly changed the world working 9-17. All highly successful people I know are obsessed and\npush themselves to the brink of burning out. Iâ€™m not saying everyone should work to exhaustion; Iâ€™m just saying thatâ€™s\nwhat it takes to achieve extraordinary things. Again, balancing things is the hard partâ€¦\u003C/p>\n\u003C/li>\n\u003Cli>\n\u003Cp>\u003Cstrong>Sometimes all it takes to succeed is to\nbe \u003Ca href=\"https://langkilde.se/post/2022-04-09-the-energy-to-keep-going\">\u003Cstrong>the last one standing\u003C/strong>\u003C/a> .\u003C/strong> Most people are not\nprepared to endure the hardship required for success. There are always reasons to give up and stop. Competitors are\ntoo strong, your product is not good enough, and you are exhausted. What is even worse is that: sometimes, the right\nthing is to quit. Maybe you are, like Sisyphus, fighting a futile battle. It is impossible to say in general, but I\nsee more people stopping than not, and most that keep going are eventually successful. Persistence combined with\nevolution is the way to go.\u003C/p>\n\u003C/li>\n\u003Cli>\n\u003Cp>\u003Cstrong>Are you prepared to be ruthless when you have to?\u003C/strong> Even if it is indirect, inflicting pain on others is part of\nbuilding a global business. You will have to fire underperforming people, you need to negotiate hard, you will have to\ndisappoint people, and you will make enemies no matter how nice you try to be. Are you comfortable with this? How far\nare you willing to go to win?\u003C/p>\n\u003C/li>\n\u003C/ul>\n\u003Ch3 id=\"relationships-and-influence\">Relationships and Influence\u003C/h3>\n\u003Cp>\u003Cstrong>The world runs on relationships.\u003C/strong> Forging long-term, strong bonds with other people is one of the most critical\ndifferentiators to innovate and build. The benefits include:\u003C/p>\n\u003Cul>\n\u003Cli>\n\u003Cp>\u003Cstrong>Smart friends give the best feedback.\u003C/strong> The most valuable thing in life is people telling you what to improve. Or\nwhen you are wrong. Getting great feedback requires solid relationships. Most people will not give honest feedback if\nthey donâ€™t know you very well. It takes discipline, patience and skill to provide excellent feedback. Mentoring\nrequires a particular form of friendship. Finding excellent mentors is something to cherish.\u003C/p>\n\u003C/li>\n\u003Cli>\n\u003Cp>\u003Cstrong>Access to talent.\u003C/strong> Every ambitious project requires a group of excellent, hard-working people. While the virtues of\nthe core idea span the potential of a project, your ability to attain the full potential through adjustments and\nchallenges is limited by your team. Building relationships with high-performing individuals you can bring along for\nthe journey is a critical differentiator.\u003C/p>\n\u003C/li>\n\u003Cli>\n\u003Cp>\u003Cstrong>Access to capital.\u003C/strong> All innovation is risky. The most valuable innovations emerge when someone bets something is\ninevitable before most people have even heard of it. You will need a lot of money to make something that seems\nimpossible possible. More money will always be better if you want to build something genuinely extraordinary happen,\nand that requires connections. A big part of early-stage investing is evaluating the character of the founders.\nEstablishing solid relationships and getting strong references will help significantly in this process.\u003C/p>\n\u003C/li>\n\u003Cli>\n\u003Cp>\u003Cstrong>Champions for your ideas.\u003C/strong> Ideas are ubiquitous, but having influence is not. Sometimes, for something to go from\nimpossible to apparent, all you need are a few key people supporting the idea. Humans are prone to groupthink, and\nnudging the group onto a new trajectory requires influence. A strong network of influential people will radically\nimprove your chances of establishing an idea.\u003C/p>\n\u003C/li>\n\u003C/ul>\n\u003Ch3 id=\"the-power-of-storytelling\">The Power of Storytelling\u003C/h3>\n\u003Cp>\u003Cstrong>The world runs on stories.\u003C/strong> For millennia we have been telling each other stories. Great leaders have inspired people\nby crafting a narrative that provides purpose. A core human need is a sense of purpose and inspiration. Without it, we\nquickly get depressed. We need to believe in something or someone.\u003C/p>\n\u003Cul>\n\u003Cli>\n\u003Cp>\u003Cstrong>Start with why.\u003C/strong> In the words of the great Simon Sinek, â€œPeople donâ€™t buy what you do; they buy why you do it.â€\nHaving a â€œwhyâ€ behind what you are doing is essential. People are like bloodhounds that immediately smell bullshit and\nfake virtue signaling. Corporate words that have no real meaning will not inspire anyone. If your goal is to make\nmoney, be honest about it. If your goal is to do social good, then be consistent.\u003C/p>\n\u003C/li>\n\u003Cli>\n\u003Cp>\u003Cstrong>Visualize your stories.\u003C/strong> Iâ€™ve underestimated the power of visuals for a long time. Symbols are powerful. Images,\nobjects. Hell, even a logo. Things that connect you with others and form your identity. We must be constantly reminded\nof our community and our shared pursuit to stick together. A prototype, a video, or an image. Make your dream\naccessible to others.\u003C/p>\n\u003C/li>\n\u003Cli>\n\u003Cp>\u003Cstrong>Repeat, repeat, repeat.\u003C/strong> Most people underestimate how often you have to say something for others to take it in.\nThe world is noisy, and people are very busy with their thoughts and problems. That means they will only hear a\nfraction of what you are trying to say. Tell your story until you are tired of hearing your voice.\u003C/p>\n\u003C/li>\n\u003C/ul>\n\u003Cp>\u003Cstrong>Be mindful of what you read.\u003C/strong> I have tailored my books, apps, and subscriptions to feed me content that will\npositively shape my thinking. As with food, a healthy diet is varied. Lots of vegetables (business books, technology\nbooks, biographies, etc.) but also things like science fiction adventures and really good blogs. Lately, Iâ€™ve mixed in\nbooks on mindfulness and longevity. Exposure to specific ideas will shape your thinking, so inspire yourself to think\nhealthy, valuable things.\u003C/p>\n\u003Cp>\u003Cstrong>Pessimists sound smart; optimists make money.\u003C/strong> This is one of my all-time favorite sayings, credit to Nat Friedman,\nthe founder of GitHub. There is never a shortage of people telling you why something wonâ€™t work or why something is a\nbad idea. It takes a special kind of person to focus on the positives, find solutions and make things happen.\u003C/p>",{"headings":547,"localImagePaths":575,"remoteImagePaths":576,"frontmatter":577,"imagePaths":578},[548,551,554,557,560,563,566,569,572],{"depth":24,"slug":549,"text":550},"play-the-long-game","Play the Long Game",{"depth":24,"slug":552,"text":553},"prioritize-emotional-health","Prioritize Emotional Health",{"depth":24,"slug":555,"text":556},"money-time-and-leverage","Money, Time, and Leverage",{"depth":24,"slug":558,"text":559},"uniqueness-and-competition","Uniqueness and Competition",{"depth":24,"slug":561,"text":562},"luck-betting-and-outcomes","Luck, Betting, and Outcomes",{"depth":24,"slug":564,"text":565},"think-globally-scale-quickly","Think Globally, Scale Quickly",{"depth":24,"slug":567,"text":568},"sacrifice-and-hard-work","Sacrifice and Hard Work",{"depth":24,"slug":570,"text":571},"relationships-and-influence","Relationships and Influence",{"depth":24,"slug":573,"text":574},"the-power-of-storytelling","The Power of Storytelling",[],[],{"pubDate":540,"title":539},[],"reflections-on-life-and-entrepreneurship.md","relationships-and-uncommon-sense-in-a-time-of-ai",{"id":580,"data":582,"body":585,"filePath":586,"digest":587,"rendered":588,"legacyId":605},{"title":583,"pubDate":584},"Relationships and Uncommon Sense in a time of AI","2023-01-02","What is valuable in a world where neural networks can combine and interpolate any information structured by humans?\n\n[Recent results in machine learning](http://langkilde.se/blog/2022/4/18/the-state-of-machine-learning-2022) have\ndemonstrated that if you feed enough text and images structured by humans to a vast neural network, the network can\nassemble combinations of concepts and sample information on the continuum from one concept to another. The machine\noutput is frequently indistinguishable from what human-produced output looks like. If we feed the network enough\nexamples of what ice cream looks like and enough examples of what dragons look like, the network can generate an ice\ncream dragon. This has become known as â€œGenerative AI.â€ The underlying technology has been around for a long time, but\nit is finally good enough to be helpful.\n\n**So what are the consequences of this technology for humans?** What will be valuable skills in a future permeated by\nGenerative AI? To hypothesize about this, we have to start by understanding the strengths and weaknesses of this new\ntechnology:\n\n### Comparative Strengths of Machine Learning\n\n* **Can ingest all available information.** A human couldn't read all available text in a lifetime. Computers can read\n  it in months or weeks, and they get faster and faster every day.\n\n* **Radically lower cost of prediction than humans.** Once a network has learned a concept, you can query it at a very\n  low cost compared to humans. This is the most obvious strength of any machine learning system. It can produce results\n  as long as we power the computer, over and over without any fatigue.\n\n* **Radically faster than humans.** Generating model predictions is much quicker than a human manually completing tasks.\n\n* **Constant availability.** Computers are, assuming there is power, able to stay on forever. More or less. No sick\n  leave. No holidays. None of that pesky nonsense that humans require to function.\n\n* **Able to combine concepts in unrestrained ways.** I find that combining concepts is the most exciting aspect of\n  Generative AI. E.g. \"Show me a dragon made of ice cream in the style of Salvador Dali.\" Humans will always be a bit\n  hesitant to create really crazy combinations. Computers do not suffer from such inhibitions. A lot of science and\n  business is about combining concepts from different domains to create novel solutions. Tesla came about as \"what would\n  a car company look like if it was set up and run like a software company?\". What works in one domain can sometimes be\n  transferred to new domains, unlocking new possibilities.\n\n### Comparative Strengths of Humans\n\n* **Sparse Meta-Reasoning.** I ask myself questions about the meaning of life. The fact that I am aware of the absence\n  of a clear objective function for existence feels significant. The process of finding purpose in a societal context is\n  something humans are, so far, uniquely capable of. Even with perfect reinforcement learning, an objective function\n  will be required. Humans are, in theory, free to pick their own. Most people default to something boring like money or\n  fame, but our limitations are self-imposed. We can also do this based on very few examples, i.e., we do not really\n  know much about all the choices humans make in life, and yet most of us can guide our own life surprisingly well.\n\n* **Deliberately unlikely thinking.** The most exciting humans are the ones that pursue crazy ideas. Taking risks and\n  betting on unlikely things feels very different from the way modern machine-learning models are programmed. The most\n  impactful humans inject noise into the optimization process in a deliberate and measured way that I'm not aware\n  computers can do. I assume we will see a noisy search of latent spaces as part of this new wave of AI, but I haven't\n  seen too much yet.\n\n* **Casual explanations beyond correlation.** A few years ago, I met a researcher working to make machine-learning\n  systems teach humans new things rather than us teaching computers. The idea was that you would feed a network a large\n  quantity of data, let it find the correlations, and then extract the underlying causal explanation. Basically, \"how do\n  we get computers to not just tell us the answer but also explain why the observed correction occurs.\" This is the core\n  challenge for human researchers, but I haven't seen computers be able to really do it yet. At least not in a similar\n  way.\n\n* **Relationships.** While AIs can be used to analyze data and make decisions, humans excel at forming relationships and\n  understanding people's emotions. The more I learn about the world, the more I realize that most super-successful\n  people are actually primarily great at building relationships. When trying to make something seemingly impossible\n  possible, you have to have friends who believe in you.\n\n* **Physical-world context.** The human experience is, after all, about coping with the human condition. Finding food,\n  building relationships, procreating, and so on. I doubt we will see human-like intelligence without imposing the human\n  condition on the system.\n\n* **Dynamically appending experience.** Humans start building a world model when we are born. Every day we add more\n  information to it with _just_ the right amount of \"forgetting.\" Due to some balance of \"cost of storage\" and \"\n  usefulness of data,\" humans retain information with a beneficial amount of detail for a reasonable amount of time.\n  Evolution is good at finding balance. While I think this aspect can be solved with time and money, constantly evolving\n  the right balance between remembering and forgetting seems very complex.\n\n* **Constant, recursive computations.** Human brains constantly run, with inputs and outputs weaving into each other.\n  This allows us to make complex decisions and judgments in real time and adapt quickly to changes. I suspect modern\n  machine-learning systems will spiral out of control if they can endlessly consume their output. While one could argue\n  humanity is slowly spiraling out of control, too, we are relatively stable, all things considered.\n\nBefore I conclude, I want to mention something I recently came across. There is a field of cognitive psychology called \"\nMeta-Reasoning.\" Research in this domain is guided by questions like:\n\n* How are reasoning and problem-solving processes that extend over time monitored in the brain? When are we \"done\n  thinking\"? How do we track what thought processes are ongoing in the brain? Are we even keeping track, or is it just\n  running all the time randomly?\n\n* What determines whether to continue, switch strategies, or terminate thinking about a problem? Do we systematically do\n  this? Or is it all random?\n\nThese questions give a clue to what yet-to-be-understood human abilities we still haven't transferred to computers. That\nmeans that while recent breakthroughs are extraordinary, we are far from done.\n\n### Conclusion: Dream weird things with friends\n\n**If you want an edge on computers, you must build many global, solid relationships and make deliberate but risky bets.\n**\n\nThroughout history, humans could gain status and influence by having a great memory or excellent arithmetic skills.\nReading large quantities of information, and passing logical tests, is still the cornerstone of education. Those with\nthe best memory and ability to pattern match get the highest grades, jobs, and salaries. At least in general. I think\nthat is about to change.\n\nMemory and pattern-matching are becoming commoditized. Generative AI is to pattern matching what calculators are to\nmath. We will inevitably have conversational agents that instantly generate text and images drawing on all human\nknowledge. Whether this constitutes human intelligence or not, it will be extremely useful. Prompting a knowledge base\nwill augment memory and move the competitive edge from processing power to \"uncommon sense.\" Or put differently: Make\nsure to dream about weird things that should be real, and then convince your friends to help you make them real. So far,\ncomputers are bad at that.","src/content/blog/relationships-and-uncommon-sense-in-a-time-of-ai.md","f5eca25398f63ddd",{"html":589,"metadata":590},"\u003Cp>What is valuable in a world where neural networks can combine and interpolate any information structured by humans?\u003C/p>\n\u003Cp>\u003Ca href=\"http://langkilde.se/blog/2022/4/18/the-state-of-machine-learning-2022\">Recent results in machine learning\u003C/a> have\ndemonstrated that if you feed enough text and images structured by humans to a vast neural network, the network can\nassemble combinations of concepts and sample information on the continuum from one concept to another. The machine\noutput is frequently indistinguishable from what human-produced output looks like. If we feed the network enough\nexamples of what ice cream looks like and enough examples of what dragons look like, the network can generate an ice\ncream dragon. This has become known as â€œGenerative AI.â€ The underlying technology has been around for a long time, but\nit is finally good enough to be helpful.\u003C/p>\n\u003Cp>\u003Cstrong>So what are the consequences of this technology for humans?\u003C/strong> What will be valuable skills in a future permeated by\nGenerative AI? To hypothesize about this, we have to start by understanding the strengths and weaknesses of this new\ntechnology:\u003C/p>\n\u003Ch3 id=\"comparative-strengths-of-machine-learning\">Comparative Strengths of Machine Learning\u003C/h3>\n\u003Cul>\n\u003Cli>\n\u003Cp>\u003Cstrong>Can ingest all available information.\u003C/strong> A human couldnâ€™t read all available text in a lifetime. Computers can read\nit in months or weeks, and they get faster and faster every day.\u003C/p>\n\u003C/li>\n\u003Cli>\n\u003Cp>\u003Cstrong>Radically lower cost of prediction than humans.\u003C/strong> Once a network has learned a concept, you can query it at a very\nlow cost compared to humans. This is the most obvious strength of any machine learning system. It can produce results\nas long as we power the computer, over and over without any fatigue.\u003C/p>\n\u003C/li>\n\u003Cli>\n\u003Cp>\u003Cstrong>Radically faster than humans.\u003C/strong> Generating model predictions is much quicker than a human manually completing tasks.\u003C/p>\n\u003C/li>\n\u003Cli>\n\u003Cp>\u003Cstrong>Constant availability.\u003C/strong> Computers are, assuming there is power, able to stay on forever. More or less. No sick\nleave. No holidays. None of that pesky nonsense that humans require to function.\u003C/p>\n\u003C/li>\n\u003Cli>\n\u003Cp>\u003Cstrong>Able to combine concepts in unrestrained ways.\u003C/strong> I find that combining concepts is the most exciting aspect of\nGenerative AI. E.g. â€œShow me a dragon made of ice cream in the style of Salvador Dali.â€ Humans will always be a bit\nhesitant to create really crazy combinations. Computers do not suffer from such inhibitions. A lot of science and\nbusiness is about combining concepts from different domains to create novel solutions. Tesla came about as â€œwhat would\na car company look like if it was set up and run like a software company?â€. What works in one domain can sometimes be\ntransferred to new domains, unlocking new possibilities.\u003C/p>\n\u003C/li>\n\u003C/ul>\n\u003Ch3 id=\"comparative-strengths-of-humans\">Comparative Strengths of Humans\u003C/h3>\n\u003Cul>\n\u003Cli>\n\u003Cp>\u003Cstrong>Sparse Meta-Reasoning.\u003C/strong> I ask myself questions about the meaning of life. The fact that I am aware of the absence\nof a clear objective function for existence feels significant. The process of finding purpose in a societal context is\nsomething humans are, so far, uniquely capable of. Even with perfect reinforcement learning, an objective function\nwill be required. Humans are, in theory, free to pick their own. Most people default to something boring like money or\nfame, but our limitations are self-imposed. We can also do this based on very few examples, i.e., we do not really\nknow much about all the choices humans make in life, and yet most of us can guide our own life surprisingly well.\u003C/p>\n\u003C/li>\n\u003Cli>\n\u003Cp>\u003Cstrong>Deliberately unlikely thinking.\u003C/strong> The most exciting humans are the ones that pursue crazy ideas. Taking risks and\nbetting on unlikely things feels very different from the way modern machine-learning models are programmed. The most\nimpactful humans inject noise into the optimization process in a deliberate and measured way that Iâ€™m not aware\ncomputers can do. I assume we will see a noisy search of latent spaces as part of this new wave of AI, but I havenâ€™t\nseen too much yet.\u003C/p>\n\u003C/li>\n\u003Cli>\n\u003Cp>\u003Cstrong>Casual explanations beyond correlation.\u003C/strong> A few years ago, I met a researcher working to make machine-learning\nsystems teach humans new things rather than us teaching computers. The idea was that you would feed a network a large\nquantity of data, let it find the correlations, and then extract the underlying causal explanation. Basically, â€œhow do\nwe get computers to not just tell us the answer but also explain why the observed correction occurs.â€ This is the core\nchallenge for human researchers, but I havenâ€™t seen computers be able to really do it yet. At least not in a similar\nway.\u003C/p>\n\u003C/li>\n\u003Cli>\n\u003Cp>\u003Cstrong>Relationships.\u003C/strong> While AIs can be used to analyze data and make decisions, humans excel at forming relationships and\nunderstanding peopleâ€™s emotions. The more I learn about the world, the more I realize that most super-successful\npeople are actually primarily great at building relationships. When trying to make something seemingly impossible\npossible, you have to have friends who believe in you.\u003C/p>\n\u003C/li>\n\u003Cli>\n\u003Cp>\u003Cstrong>Physical-world context.\u003C/strong> The human experience is, after all, about coping with the human condition. Finding food,\nbuilding relationships, procreating, and so on. I doubt we will see human-like intelligence without imposing the human\ncondition on the system.\u003C/p>\n\u003C/li>\n\u003Cli>\n\u003Cp>\u003Cstrong>Dynamically appending experience.\u003C/strong> Humans start building a world model when we are born. Every day we add more\ninformation to it with \u003Cem>just\u003C/em> the right amount of â€œforgetting.â€ Due to some balance of â€œcost of storageâ€ and â€\nusefulness of data,â€ humans retain information with a beneficial amount of detail for a reasonable amount of time.\nEvolution is good at finding balance. While I think this aspect can be solved with time and money, constantly evolving\nthe right balance between remembering and forgetting seems very complex.\u003C/p>\n\u003C/li>\n\u003Cli>\n\u003Cp>\u003Cstrong>Constant, recursive computations.\u003C/strong> Human brains constantly run, with inputs and outputs weaving into each other.\nThis allows us to make complex decisions and judgments in real time and adapt quickly to changes. I suspect modern\nmachine-learning systems will spiral out of control if they can endlessly consume their output. While one could argue\nhumanity is slowly spiraling out of control, too, we are relatively stable, all things considered.\u003C/p>\n\u003C/li>\n\u003C/ul>\n\u003Cp>Before I conclude, I want to mention something I recently came across. There is a field of cognitive psychology called â€\nMeta-Reasoning.â€ Research in this domain is guided by questions like:\u003C/p>\n\u003Cul>\n\u003Cli>\n\u003Cp>How are reasoning and problem-solving processes that extend over time monitored in the brain? When are we â€œdone\nthinkingâ€? How do we track what thought processes are ongoing in the brain? Are we even keeping track, or is it just\nrunning all the time randomly?\u003C/p>\n\u003C/li>\n\u003Cli>\n\u003Cp>What determines whether to continue, switch strategies, or terminate thinking about a problem? Do we systematically do\nthis? Or is it all random?\u003C/p>\n\u003C/li>\n\u003C/ul>\n\u003Cp>These questions give a clue to what yet-to-be-understood human abilities we still havenâ€™t transferred to computers. That\nmeans that while recent breakthroughs are extraordinary, we are far from done.\u003C/p>\n\u003Ch3 id=\"conclusion-dream-weird-things-with-friends\">Conclusion: Dream weird things with friends\u003C/h3>\n\u003Cp>**If you want an edge on computers, you must build many global, solid relationships and make deliberate but risky bets.\n**\u003C/p>\n\u003Cp>Throughout history, humans could gain status and influence by having a great memory or excellent arithmetic skills.\nReading large quantities of information, and passing logical tests, is still the cornerstone of education. Those with\nthe best memory and ability to pattern match get the highest grades, jobs, and salaries. At least in general. I think\nthat is about to change.\u003C/p>\n\u003Cp>Memory and pattern-matching are becoming commoditized. Generative AI is to pattern matching what calculators are to\nmath. We will inevitably have conversational agents that instantly generate text and images drawing on all human\nknowledge. Whether this constitutes human intelligence or not, it will be extremely useful. Prompting a knowledge base\nwill augment memory and move the competitive edge from processing power to â€œuncommon sense.â€ Or put differently: Make\nsure to dream about weird things that should be real, and then convince your friends to help you make them real. So far,\ncomputers are bad at that.\u003C/p>",{"headings":591,"localImagePaths":601,"remoteImagePaths":602,"frontmatter":603,"imagePaths":604},[592,595,598],{"depth":24,"slug":593,"text":594},"comparative-strengths-of-machine-learning","Comparative Strengths of Machine Learning",{"depth":24,"slug":596,"text":597},"comparative-strengths-of-humans","Comparative Strengths of Humans",{"depth":24,"slug":599,"text":600},"conclusion-dream-weird-things-with-friends","Conclusion: Dream weird things with friends",[],[],{"pubDate":584,"title":583},[],"relationships-and-uncommon-sense-in-a-time-of-ai.md","sampling-reality",{"id":606,"data":608,"body":611,"filePath":612,"digest":613,"rendered":614,"legacyId":627},{"title":609,"pubDate":610},"Sampling Reality","2024-05-20","I'm exploring three related questions right now:\n\n- Can large language models create knowledge?\n- How do you correctly sample reality?\n- Are we getting better at predicting the future?\n\nLanguage models are useful to compress and interact with knowledge using natural language. It's like talking to \"an\ninternet that can generalize\". Rather than reply with what is explicitly written online, transformer-based LLMs can\nreason abstractly based on patterns. The way I think about it is inspired\nby [dependency parsing](https://en.wikipedia.org/wiki/Parse_tree) (something NLP people busied themselves with before\nLLMs). Parse trees are a visually accessible way to explain why two sentences can be very similar structurally and still\nrefer to completely different things. Let's look at two examples:\n\n**\"How did Albert Einstein describe his methods for scientific discovery?\"**\n**\"What approach did Richard Feynman have to the scientific process?\"**\n\n![](https://storage.googleapis.com/langkilde-se-images/parse1.png)\n![](https://storage.googleapis.com/langkilde-se-images/parse2.png)\n\nAlbert Einstein and Richard Feynman will both be recognized as Named Entities (i.e. people). If we compare how each of\nthese entities are described in the text their context will likely be very similar, at least compared to most other\npossible entity pairs. Einstein and Feynman will be much closer than e.g. Einstein and Trump. As a result, Einstein and\nFeynman will be represented by similar embeddings.\n\nIf we turn to the dependency parse, we can see the subject-verb-object structure. There is a verb connecting a subject\nand an object. Without going too far into the details, a transformer basically learns to represent both the tokens and\nthe sentence structure as context-dependent embeddings. That way, two superficially different sentences can be \"\nunderstood\" as similar. As a result, text that mentions how a scientist thinks about their scientific process will be\nleveraged when replying to the prompts above, but it will be fine-tuned to structures and words that appear together\nwith the named entity. LLMs sort of \"bend\" embeddings based on context.\n\n### Creating knowledge by writing\n\n**The process of \"creating knowledge\" for an LLM turns into writing about things.** The more we write about Einstein and\nFeynman, the better our language models will get at describing them. And if two entities are described in similar ways,\nlanguage models can infer properties. This is very powerful. A major source of scientific discovery today comes from\nmoving between domains. Discoveries in one field inspire progress in other fields. Take fractals for example. Mandelbrot\ndeveloped the concept of fractals in the 1970s. Fractal geometry is today used to analyze and diagnose diseases by\nexamining patterns in medical images, such as MRI scans, where abnormal fractal dimensions may indicate pathology. I\nthink language models can be used to identify patterns in observations that humans would overlook. Once enough is\nwritten about the world, I'm sure LLMs will find very subtle patterns in how things are described. This, in my opinion,\nwould constitute knowledge creation. Making connections between concepts is discovery.\n\n**But writing about a natural phenomenon does not mean what we write is necessarily true in the scientific sense.** We\nhave developed the scientific process for a reason. Scientists are trained to make observations, form questions, test\nhypotheses, collect data, analyze and report. A hypothesis needs to be falsifiable to be scientifically valid. \"God made\nthe universe\" is not a falsifiable hypothesis. By putting falsifiable hypotheses at the center of scientific discovery,\nscience remains flexible and self-correcting. A scientific theory, i.e. an explanation of the natural world based on\nrepeated evidence, isn't true as much as it is \"not yet false\".\n\n**We are about to hit the limit of what we can gain by training LLMs on internet data.** There is only so much reliable,\nuseful text out there in the public domain. A lot of knowledge is either proprietary or not written down. What is not\ndigital cannot be automated. This creates an interesting new market: **a market for writing down useful things.**\n\n### Sampling reality\n\n**This line of thinking gives \"sampling reality\", i.e. scientific experimentation, a critical role in knowledge\ncreation.** But it also highlights the limitations of LLMs. Sampling reality is hard. And deciding what observations are\nrelevant in what situations is hard. Most difficult decisions in life relate to situations with limited access to data.\nYoung people have not gathered as much experience as old people. Startups have not experimented as much as mature\ncompanies. Looking back over the centuries, I think the most significant limitation of science has been our ability to\nsample reality. Humans observe phenomena and try to explain them. But at what resolution are we observing? If we look\ntoo closely, events at the micro-level may obscure emerging macro-phenomenon. On the other hand, if we zoom out too\nmuch, we may imagine explanations for emergent behavior that could easily be explained on the microscopic level. It's\nlike with phenotypes and genotypes. We can inspect the genetic makeup of an organism and list its set of genes and their\nvariants. But the genotype alone is not enough to predict the behaviour of the organism. The phenotype, i.e. the\nobservable characteristics of the organism, is the result of the _interaction of its genotype with the environment_.\nSuch complex, adaptive, dynamic relationships can be found all over the place in nature. Low-level observations are not\nsufficient to explain high-level behaviors and vice versa. The approximate present does not predict the approximate\nfuture. Talking to consumers does not let us easily predict market movements. Hari Seldon has not been born yet. What is\na useful signal and what is just noise? Most people are confused.\n\n**How is this related to LLMs?** Well, I'm starting to realize that most failures in business are the result of managers\nfailing to sample reality with the right frequency and resolution. Their assumptions about how microscopic events\nexplain emergent properties are no longer true. The connection between day-to-day events in a factory and strategic\ndecisions is lost. Poor approximations of reality lead to detached decisions. If something was true for a very long\ntime, people might even reject overwhelming evidence showing things have changed. I think language models will be\nmassively limited by their inability to determine if assumptions have become outdated. We program language models with\nexamples. If something has been true for a long time, it will be all over the internet. A language model will replicate\nthat pattern. It will take time before appending new text to the corpus impacts predictions. What if an entity starts\nbeing referred to in a new way? Or what if a new relationship between two entities appears? Humans aren't great at\nupdating, but we can do it. LLMs need to be retrained.\n\n**Now let me try to segue to whether LLMs are improving our ability to predict the future?** Well, yes and no, but\nmostly no. Yes, in the sense that if you describe a sequence of events, and there is an abstractly similar sequence that\nhas played out in the past, then an LLM can see very subtle similarities. Data-driven decisions sound nice and LLMs are\nmostly great at making data-driven decisions. The problem is: most interesting new things are not an obvious extension\nof the past. They are unexpected outliers. Random events. Creating new things requires the courage to go against what is\nalready accepted and understood. It requires humans that challenge data. Progress requires exploring, not exploiting.\nIt's about injecting noise into the process and seeing what sticks. I think it's about sampling reality in new ways.\nExperimenting. That's how we create knowledge. I'm constantly surprised by how wrong people are about what reality is\nreally like. Some people say: \"That's impossible!\" Other people do the impossible. Those who do the impossible do it\nbecause they did not realize it was supposed to be impossible. They venture out into the world and look at things with\nfresh eyes. Reasoning from first principle, rather than making assumptions. The only laws are the laws of nature. The\nrest is just a social construct. I see no evidence of AI being able to replicate the sort of behavior just\noutlined anytime soon. I won't say ever, but at least not for a long time.\n\nHere is a collection of quotes from Einstein on this topic:\n\n- Imagination is more important than knowledge. For knowledge is limited, whereas imagination embraces the entire world,\n  stimulating progress, giving birth to evolution.\n- The really good ideas, no one knows where they come from.\n- I rarely think in words at all. A thought comes, and I may try to express it in words afterward.\n- We cannot solve our problems with the same thinking we used when we created them.\n\nAll of this contributes to my passion for embodied AI, i.e. AI with a physical manifestation, e.g. robots. We live in\nthe natural world. Exploring this world, and interacting with it, is way more interesting than living in a virtual\nworld. Life is all about sampling reality through experimentation. That requires perception, prediction, planning, and\nactuation. Solving those problems seems way more exciting than compressing slightly more text into an LLM.","src/content/blog/sampling-reality.md","20e7bbd90a9b6120",{"html":615,"metadata":616},"\u003Cp>Iâ€™m exploring three related questions right now:\u003C/p>\n\u003Cul>\n\u003Cli>Can large language models create knowledge?\u003C/li>\n\u003Cli>How do you correctly sample reality?\u003C/li>\n\u003Cli>Are we getting better at predicting the future?\u003C/li>\n\u003C/ul>\n\u003Cp>Language models are useful to compress and interact with knowledge using natural language. Itâ€™s like talking to â€œan\ninternet that can generalizeâ€. Rather than reply with what is explicitly written online, transformer-based LLMs can\nreason abstractly based on patterns. The way I think about it is inspired\nby \u003Ca href=\"https://en.wikipedia.org/wiki/Parse_tree\">dependency parsing\u003C/a> (something NLP people busied themselves with before\nLLMs). Parse trees are a visually accessible way to explain why two sentences can be very similar structurally and still\nrefer to completely different things. Letâ€™s look at two examples:\u003C/p>\n\u003Cp>\u003Cstrong>â€œHow did Albert Einstein describe his methods for scientific discovery?â€\u003C/strong>\n\u003Cstrong>â€œWhat approach did Richard Feynman have to the scientific process?â€\u003C/strong>\u003C/p>\n\u003Cp>\u003Cimg src=\"https://storage.googleapis.com/langkilde-se-images/parse1.png\" alt=\"\">\n\u003Cimg src=\"https://storage.googleapis.com/langkilde-se-images/parse2.png\" alt=\"\">\u003C/p>\n\u003Cp>Albert Einstein and Richard Feynman will both be recognized as Named Entities (i.e. people). If we compare how each of\nthese entities are described in the text their context will likely be very similar, at least compared to most other\npossible entity pairs. Einstein and Feynman will be much closer than e.g. Einstein and Trump. As a result, Einstein and\nFeynman will be represented by similar embeddings.\u003C/p>\n\u003Cp>If we turn to the dependency parse, we can see the subject-verb-object structure. There is a verb connecting a subject\nand an object. Without going too far into the details, a transformer basically learns to represent both the tokens and\nthe sentence structure as context-dependent embeddings. That way, two superficially different sentences can be â€\nunderstoodâ€ as similar. As a result, text that mentions how a scientist thinks about their scientific process will be\nleveraged when replying to the prompts above, but it will be fine-tuned to structures and words that appear together\nwith the named entity. LLMs sort of â€œbendâ€ embeddings based on context.\u003C/p>\n\u003Ch3 id=\"creating-knowledge-by-writing\">Creating knowledge by writing\u003C/h3>\n\u003Cp>\u003Cstrong>The process of â€œcreating knowledgeâ€ for an LLM turns into writing about things.\u003C/strong> The more we write about Einstein and\nFeynman, the better our language models will get at describing them. And if two entities are described in similar ways,\nlanguage models can infer properties. This is very powerful. A major source of scientific discovery today comes from\nmoving between domains. Discoveries in one field inspire progress in other fields. Take fractals for example. Mandelbrot\ndeveloped the concept of fractals in the 1970s. Fractal geometry is today used to analyze and diagnose diseases by\nexamining patterns in medical images, such as MRI scans, where abnormal fractal dimensions may indicate pathology. I\nthink language models can be used to identify patterns in observations that humans would overlook. Once enough is\nwritten about the world, Iâ€™m sure LLMs will find very subtle patterns in how things are described. This, in my opinion,\nwould constitute knowledge creation. Making connections between concepts is discovery.\u003C/p>\n\u003Cp>\u003Cstrong>But writing about a natural phenomenon does not mean what we write is necessarily true in the scientific sense.\u003C/strong> We\nhave developed the scientific process for a reason. Scientists are trained to make observations, form questions, test\nhypotheses, collect data, analyze and report. A hypothesis needs to be falsifiable to be scientifically valid. â€œGod made\nthe universeâ€ is not a falsifiable hypothesis. By putting falsifiable hypotheses at the center of scientific discovery,\nscience remains flexible and self-correcting. A scientific theory, i.e. an explanation of the natural world based on\nrepeated evidence, isnâ€™t true as much as it is â€œnot yet falseâ€.\u003C/p>\n\u003Cp>\u003Cstrong>We are about to hit the limit of what we can gain by training LLMs on internet data.\u003C/strong> There is only so much reliable,\nuseful text out there in the public domain. A lot of knowledge is either proprietary or not written down. What is not\ndigital cannot be automated. This creates an interesting new market: \u003Cstrong>a market for writing down useful things.\u003C/strong>\u003C/p>\n\u003Ch3 id=\"sampling-reality\">Sampling reality\u003C/h3>\n\u003Cp>\u003Cstrong>This line of thinking gives â€œsampling realityâ€, i.e. scientific experimentation, a critical role in knowledge\ncreation.\u003C/strong> But it also highlights the limitations of LLMs. Sampling reality is hard. And deciding what observations are\nrelevant in what situations is hard. Most difficult decisions in life relate to situations with limited access to data.\nYoung people have not gathered as much experience as old people. Startups have not experimented as much as mature\ncompanies. Looking back over the centuries, I think the most significant limitation of science has been our ability to\nsample reality. Humans observe phenomena and try to explain them. But at what resolution are we observing? If we look\ntoo closely, events at the micro-level may obscure emerging macro-phenomenon. On the other hand, if we zoom out too\nmuch, we may imagine explanations for emergent behavior that could easily be explained on the microscopic level. Itâ€™s\nlike with phenotypes and genotypes. We can inspect the genetic makeup of an organism and list its set of genes and their\nvariants. But the genotype alone is not enough to predict the behaviour of the organism. The phenotype, i.e. the\nobservable characteristics of the organism, is the result of the \u003Cem>interaction of its genotype with the environment\u003C/em>.\nSuch complex, adaptive, dynamic relationships can be found all over the place in nature. Low-level observations are not\nsufficient to explain high-level behaviors and vice versa. The approximate present does not predict the approximate\nfuture. Talking to consumers does not let us easily predict market movements. Hari Seldon has not been born yet. What is\na useful signal and what is just noise? Most people are confused.\u003C/p>\n\u003Cp>\u003Cstrong>How is this related to LLMs?\u003C/strong> Well, Iâ€™m starting to realize that most failures in business are the result of managers\nfailing to sample reality with the right frequency and resolution. Their assumptions about how microscopic events\nexplain emergent properties are no longer true. The connection between day-to-day events in a factory and strategic\ndecisions is lost. Poor approximations of reality lead to detached decisions. If something was true for a very long\ntime, people might even reject overwhelming evidence showing things have changed. I think language models will be\nmassively limited by their inability to determine if assumptions have become outdated. We program language models with\nexamples. If something has been true for a long time, it will be all over the internet. A language model will replicate\nthat pattern. It will take time before appending new text to the corpus impacts predictions. What if an entity starts\nbeing referred to in a new way? Or what if a new relationship between two entities appears? Humans arenâ€™t great at\nupdating, but we can do it. LLMs need to be retrained.\u003C/p>\n\u003Cp>\u003Cstrong>Now let me try to segue to whether LLMs are improving our ability to predict the future?\u003C/strong> Well, yes and no, but\nmostly no. Yes, in the sense that if you describe a sequence of events, and there is an abstractly similar sequence that\nhas played out in the past, then an LLM can see very subtle similarities. Data-driven decisions sound nice and LLMs are\nmostly great at making data-driven decisions. The problem is: most interesting new things are not an obvious extension\nof the past. They are unexpected outliers. Random events. Creating new things requires the courage to go against what is\nalready accepted and understood. It requires humans that challenge data. Progress requires exploring, not exploiting.\nItâ€™s about injecting noise into the process and seeing what sticks. I think itâ€™s about sampling reality in new ways.\nExperimenting. Thatâ€™s how we create knowledge. Iâ€™m constantly surprised by how wrong people are about what reality is\nreally like. Some people say: â€œThatâ€™s impossible!â€ Other people do the impossible. Those who do the impossible do it\nbecause they did not realize it was supposed to be impossible. They venture out into the world and look at things with\nfresh eyes. Reasoning from first principle, rather than making assumptions. The only laws are the laws of nature. The\nrest is just a social construct. I see no evidence of AI being able to replicate the sort of behavior just\noutlined anytime soon. I wonâ€™t say ever, but at least not for a long time.\u003C/p>\n\u003Cp>Here is a collection of quotes from Einstein on this topic:\u003C/p>\n\u003Cul>\n\u003Cli>Imagination is more important than knowledge. For knowledge is limited, whereas imagination embraces the entire world,\nstimulating progress, giving birth to evolution.\u003C/li>\n\u003Cli>The really good ideas, no one knows where they come from.\u003C/li>\n\u003Cli>I rarely think in words at all. A thought comes, and I may try to express it in words afterward.\u003C/li>\n\u003Cli>We cannot solve our problems with the same thinking we used when we created them.\u003C/li>\n\u003C/ul>\n\u003Cp>All of this contributes to my passion for embodied AI, i.e. AI with a physical manifestation, e.g. robots. We live in\nthe natural world. Exploring this world, and interacting with it, is way more interesting than living in a virtual\nworld. Life is all about sampling reality through experimentation. That requires perception, prediction, planning, and\nactuation. Solving those problems seems way more exciting than compressing slightly more text into an LLM.\u003C/p>",{"headings":617,"localImagePaths":623,"remoteImagePaths":624,"frontmatter":625,"imagePaths":626},[618,621],{"depth":24,"slug":619,"text":620},"creating-knowledge-by-writing","Creating knowledge by writing",{"depth":24,"slug":606,"text":622},"Sampling reality",[],[],{"pubDate":610,"title":609},[],"sampling-reality.md","should-you-raise-vc-money",{"id":628,"data":630,"body":633,"filePath":634,"digest":635,"rendered":636,"legacyId":671},{"title":631,"pubDate":632},"Should you raise VC money?","2023-12-17","**There is a constant dance between technology and capital.** Technology improves and disrupts, and capital chases the\nlatest and greatest innovation that provides yield. I recently returned to Sweden from an extended stay in the Bay Area.\nMy focus was to learn as much as I could about the fundraising landscape. To build successful, valuable companies you\nneed to understand how financial markets work. Building great products is still the most value-generating work a founder\ncan spend time on, but it isnâ€™t the only piece of the puzzle. Here are some reflections based on my recent experiences\ntalking to investors. A major question for me is â€œWhat businesses are a good fit for venture capital?â€, and Iâ€™ll try and\nestablish that towards the end.\n\n### Amount of Capital in the World\n\nFirst of all: There are massive amounts of capital in the world that need to be allocated. According\nto [SIFMA](https://www.sifma.org/resources/research/research-quarterly-equities/#:~:text=The%20U.S.%20equity%20markets%20are,the%20next%20largest%20market%2C%20China.),\nthe global equity market will be around US$106 trillion dollars in 2023. US$45.5 trillion dollars of that is in the US,\nEU US$11.8 trillion dollars, and China US$11 trillion dollars. According\nto [St. Louise Feb](https://fred.stlouisfed.org/series/MABMM301USM189S), the\nUS [M3 money](https://en.wikipedia.org/wiki/Money_supply) supply (cash, etc) was US$20+ trillion dollars.\n\nThere are around 41,000 listed companies in the world with a combined market value of about US$106 trillion,\naccording to the OECD. The 10,000 largest companies make up 90% of the combined market value. The 10 largest companies\nmake up 10% of the combined market value. That means there is a massive value concentration in the worldâ€™s largest\ncompanies.\n\n![](https://storage.googleapis.com/langkilde-se-images/7302ce6b-c2f0-4924-9590-1b31414f29f9.jpeg)\n\n### Who Owns Global Equity Markets?\n\nWhere is the money that makes up global equity markets coming from? According to the OECD, there are four main\ncategories of owners: Institutional investors (like mutual funds, banking institutions, hedge funds, insurance\ncompanies, venture capital funds, and pension providers), public sector owners (central or local government), private\ncorporations (other companies) and strategic individual investors (rich people). About 41% of the global stock market\ncap is held by institutional investors, making them the largest category. In the West, their ownership is even higher.\n\n### Yield and the Risk-Free Rate\n\n**What do these people want?** More money. One way to get more money is to buy an asset that provides **yield**. The\nyield on a security is a measure of the ex-ante return to a holder of the security. Some assets, like fixed-income\nsecurities like bonds, provide yield in the form of coupon rates. The yield for â€œrisk-freeâ€ assets (i.e. securities with\nvirtually zero risk of loss) set the â€œrisk-free rateâ€. Most people consider 10-year US Treasury bonds (US10Y) to set the\nrisk-free rate. If you buy a US10Y you receive a fixed interest payment every 6 months. The government pays you for\nlocking up money with them for 10 years. Right now, that rate is ~4.4%. Different securities have different ways of\nproviding yield (cash dividends etc) but the principle is the same as for coupon rates.\n\n![](https://storage.googleapis.com/langkilde-se-images/08e663a3-2c2b-418b-a881-37613aeb9bc0.jpeg)\n\n**The risk-free rate has been declining since the 1980s.** This has encouraged investors to take more and more risk. The\nperiod from 2008 to 2021 offered an extraordinarily low cost of capital. Looking back, risk-free rates are now back to\npre-2008 levels of interest rates, and the curve has shot up for the first time in decades. For the last 15 years,\ngovernments have stimulated the economy to first recover from the 2008 meltdown, and then the 2020 Covid lockdown. They\ndid not want people to deposit their money into savings, so they turned down the yield on government-backed securities,\nthereby stimulating the economy. But those times are over now, and investors now get a 4.4% return on their money\nwithout taking any risk at all. Assuming all other assets have more risk, money managers will benchmark assets against\nthe risk-free rate.\n\n### How Interest Rates Affect Startups\n\n**Why does this matter for a startup?** Well, one way to get yield is to seek riskier investments. And startups are\nincredibly risky. I wrote a lot about\nthis [last winter](https://langkilde.se/post/2023-01-09-building-extremely-valuable-companies). While returns can be\nhigh, the variance of return is high.\n\n![](https://storage.googleapis.com/langkilde-se-images/3389b20d-0d01-4755-a007-92b9cc33b94a.jpeg)\n\n![](https://storage.googleapis.com/langkilde-se-images/619a1309-d352-4225-a3a9-31ad6609a7fc.jpeg)\n\n**When the risk-free rate increases, less money is invested in higher-risk assets.** At the peak of the â€œbull marketâ€ (\n2020-2021) investors struggled to get yield, so they chased riskier and riskier investments. This resulted in higher and\nhigher private valuations of not only startups but also public companies. And much more money became available to\nstartups. According to [Meritech](https://www.meritechcapital.com/blog/meritech-software-pulse) public market\nsoftware-as-a-service valuations reached stratospheric levels during Covid. At one point, you had to pay almost 40 times\nthe next twelve-month sales forecast to buy shares in top-performing software companies. Thatâ€™s **_a lot_** considering\nmany of these companies do not pay dividends. Some arenâ€™t even profitable.\n\n![](https://storage.googleapis.com/langkilde-se-images/7c884031-855e-489c-bb01-99c97c2b2863.jpeg)\n\n**The price of an asset should be proportional to its Sharpe ratio, i.e. the (return minus the risk-free rate) / (\nvariance of return).** Of course, you donâ€™t know this number upfront for a specific investment. The job of e.g. venture\ncapitalists is to estimate the return and risk. To do that, they pattern match. They will say they donâ€™t, but they do.\nThey look at as many things as they can and try to conclude what the common denominators are between successful\ncompanies. When they set valuations, they will benchmark against similar companies with known valuations. In private\nmarkets, this becomes a sort of circular argument that is ultimately anchored in the public market. Public markets\nprovide clear prices, as opposed to private companies that arenâ€™t traded regularly (or at all). So when you sell shares\nin a private company, investors need to determine: **What is the potential of this investment compared to other possible\ninvestments I could make, and what is the risk that I lose my money?**\n\n**Letâ€™s create a specific example.** To better explain how valuations work, we will cheat and assume we know all the\nvariables (which you never do). Here comes a ton of numbers:\n\n![](https://storage.googleapis.com/langkilde-se-images/f3e39d09-020e-4aa5-8e51-ef18d1f3a7a0.jpeg)\n\n### Valuation and Expected Returns\n\n**Letâ€™s assume, for the sake of argument, that our company ends up in a\nglorious $500M exit.** Such exits are extraordinarily rare. As a seed investor, we have a few things to consider: At what valuation am I investing, what is a possible exit valuation, and what is the probability of success? Letâ€™s say we are one of the worldâ€™s best seed investors, so 1/20 tickets end up generating a rare exit (I donâ€™t know if anyone can deliver such good odds, but letâ€™s pretend). Considering the dilution from Series A, B, and C, our share of $\n1M could be worth as much as $24M. Holy moly, thatâ€™s a lot of money. But, letâ€™s remember, we only think this happens in 1/20 cases. If we only invested in this one company, the expected annual return is just 2.4%, i.e. much worse than the risk-free rate and NASDAQ. If we placed 20 bets like this, assuming 19 of them will go to zero, weâ€™d have to invest $\n20M to get one $24M outcome. Thatâ€™s $4M net value in 9 years, or 2% annually. Also worse than the risk-free rate and\nNASDAQ. But, letâ€™s change an important variable: letâ€™s pretend we can get a $1B outcome instead. Unicorns. How many\ncompanies become dollar unicorns? Very, very, very, very few. Decacorns? Like 10 in a decade maybe?\n\n![](https://storage.googleapis.com/langkilde-se-images/aa094252-22e0-4111-902c-d287f7f01fce.jpeg)\n\nBabam. Now, all of a sudden, we can get one $48.7M windfall instead. That means weâ€™ve made $28.7M on our seed portfolio\nof 20 companies, or a 43% gain. Thatâ€™s 4.1% annually. So now we are basically on par with the risk-free rate. But we\nneed a company that can swallow almost $200M and generate enough revenue to support a $1B valuation. Venture is about\nfinding outliners that can deliver extraordinary returns in a very short amount of time. If we doubled the number of\nyears it takes to reach the outcome valuation, we cut the expected annualized return in half. **Venture capital works\nwith short timelines ( \u003C10y) and most huge companies take decades to build.**\n\n**When interest rates change, this presents a triple whammy to these sorts of spreadsheets.** On the one hand, it\nincreases the risk-free rate, so companies need to perform better to deliver competitive returns. It also lowers the\nexpected multiples of public companies, thereby lowering the expected market capitalization. Finally, it also means less\nmoney from the trillions of capital that need to be allocated is steered towards venture investments, so raising a fund\ngets harder. The following chart from Battery Venture shows the US10Y vs SaaS multiples. Pretty strong correlation as\nyou can see.\n\n![](https://storage.googleapis.com/langkilde-se-images/924f3891-c589-4a35-b450-b2cb0a1239c5.jpeg)\n\n### Current State of Venture Markets\n\n**What this means is that right now, there are a lot of very highly valued startups that probably arenâ€™t worth the price\nput on them in their latest funding round.** Another chart from Battery shows a very crowded box for $1B+ startups that\nsoon need to start providing liquidity to venture funds. Venture funds are typically close-ended, i.e. investors lock\ntheir money up for 10 years. But after that, they expect to get their money back again. If a VC has a portfolio of\ncompanies that they cannot sell, they cannot return money to their investors. That creates a sort of Mexican standoff.\nIf investors in a VC fund push for liquidity, VCs are forced to â€œmark to marketâ€, i.e. put a price on their assets.\nAnother interesting tidbit: turns out investing in a fund doesnâ€™t mean you have to give them money right away. The VC\nfund instead _calls_ on capital when needed. Right now, some investors might not be able to honor such a cash call,\nsince they havenâ€™t gotten money back from previous investments. If the IPO market is dead, there is limited liquidity in\nthe secondary market, and the company does not provide revenue enough to defend its valuation, you have a toxic\ncocktail. **This is the state of the current market.**\n\n![](https://storage.googleapis.com/langkilde-se-images/f65f010b-6cfd-4449-a3ed-71a66cb3a0aa.jpeg)\n\n### How Venture Firms Respond\n\nHow do venture firms make sure they make money in a market like this? Well, they only invest in truly extraordinary\ncompanies. For Series B, weâ€™re talking:\n\n* Minimum $5-10M ARR\n\n* Minimum 2-3x YoY growth\n\n* Burn multiple of max 1-2x (burn / net new ARR)\n\n* â€œRule of 40â€ needs to be over 40, i.e. EBIT margin + growth = 40\n\n**Very few companies can deliver such metrics.** You can be an extraordinary operator and still not have a chance. It\ntakes a certain market, and a certain sort of business, to reach such stratospheric growth levels. As a result, VCs will\nlook for companies that have:\n\n* **Huge, huge markets.** SMEs and consumer products have this. Sometimes enterprise.\n\n* **Low friction sales motion.** This is why everyone loves product-led growth (PLG). No sales team! ðŸŽ‰\n\n* **Experienced team.** There are a lot of ways to fuck up.\n\n### Alignment Between Founders and Investors\n\n**Here is where VCs and founders (can) have conflicting priorities.** Investors seeking extraordinary outcomes are not\ninterested in â€œsafe betsâ€. If the probability of success is 10%, 20%, or 30% doesnâ€™t change the math as much as looking\nfor companies with a possible $10B outcome instead of a $100M. The 100x difference in potential outcome far exceeds the\nimpact of better odds of survival. And, in the end, most startups fail anyway, so they assume there arenâ€™t any â€œsure\nthingsâ€.\n\n**Tier 1 investors are called Tier 1 because they deliver the best returns to their investors.** The best provide\n20-30%+ net IRR (after fees etc). Some even more. Their business is not to foster innovation, or to fund your science\nproject. They are looking to make tons of money. You should only take on an investment from a Tier 1 VC if you\nunderstand what youâ€™re doing.\n\n> VC money is like powering your car with an unstable nuclear reactor. You will fly fast as fuck, but the most likely\n> outcome is a meltdown.\n\nIâ€™m starting to understand that the best investors seek a mutual fit between the founder, the company, and their\ninvestment. You have to establish shared expectations: How much risk are we taking? What sort of returns are we\nexpecting? What sort of company are you building? How comfortable are you â€œgoing for brokeâ€? Can you\nprovide $100M in returns to a fund? $1B? Does the business you envision support such an outcome? Does the market? *\n*Difficult questions you have to deal with before you raise money.**\n\n### Conclusion: Who Should Raise VC?\n\nPersonally, I think it takes years of experience running a startup before you can honestly reason about these things.\nFirst-time founders have no idea what they are getting into, for better or worse. Second-time founders who had a\nmoderately successful first try, understand how things work, and are _still_ determined to take VC money - those are the\nones who probably should. It doesnâ€™t mean they will succeed, but Iâ€™m certain their odds are way better.","src/content/blog/should-you-raise-vc-money.md","41c1e1c3b4702b39",{"html":637,"metadata":638},"\u003Cp>\u003Cstrong>There is a constant dance between technology and capital.\u003C/strong> Technology improves and disrupts, and capital chases the\nlatest and greatest innovation that provides yield. I recently returned to Sweden from an extended stay in the Bay Area.\nMy focus was to learn as much as I could about the fundraising landscape. To build successful, valuable companies you\nneed to understand how financial markets work. Building great products is still the most value-generating work a founder\ncan spend time on, but it isnâ€™t the only piece of the puzzle. Here are some reflections based on my recent experiences\ntalking to investors. A major question for me is â€œWhat businesses are a good fit for venture capital?â€, and Iâ€™ll try and\nestablish that towards the end.\u003C/p>\n\u003Ch3 id=\"amount-of-capital-in-the-world\">Amount of Capital in the World\u003C/h3>\n\u003Cp>First of all: There are massive amounts of capital in the world that need to be allocated. According\nto \u003Ca href=\"https://www.sifma.org/resources/research/research-quarterly-equities/#:~:text=The%20U.S.%20equity%20markets%20are,the%20next%20largest%20market%2C%20China.\">SIFMA\u003C/a>,\nthe global equity market will be around US$106 trillion dollars in 2023. US$45.5 trillion dollars of that is in the US,\nEU US$11.8 trillion dollars, and China US$11 trillion dollars. According\nto \u003Ca href=\"https://fred.stlouisfed.org/series/MABMM301USM189S\">St. Louise Feb\u003C/a>, the\nUS \u003Ca href=\"https://en.wikipedia.org/wiki/Money_supply\">M3 money\u003C/a> supply (cash, etc) was US$20+ trillion dollars.\u003C/p>\n\u003Cp>There are around 41,000 listed companies in the world with a combined market value of about US$106 trillion,\naccording to the OECD. The 10,000 largest companies make up 90% of the combined market value. The 10 largest companies\nmake up 10% of the combined market value. That means there is a massive value concentration in the worldâ€™s largest\ncompanies.\u003C/p>\n\u003Cp>\u003Cimg src=\"https://storage.googleapis.com/langkilde-se-images/7302ce6b-c2f0-4924-9590-1b31414f29f9.jpeg\" alt=\"\">\u003C/p>\n\u003Ch3 id=\"who-owns-global-equity-markets\">Who Owns Global Equity Markets?\u003C/h3>\n\u003Cp>Where is the money that makes up global equity markets coming from? According to the OECD, there are four main\ncategories of owners: Institutional investors (like mutual funds, banking institutions, hedge funds, insurance\ncompanies, venture capital funds, and pension providers), public sector owners (central or local government), private\ncorporations (other companies) and strategic individual investors (rich people). About 41% of the global stock market\ncap is held by institutional investors, making them the largest category. In the West, their ownership is even higher.\u003C/p>\n\u003Ch3 id=\"yield-and-the-risk-free-rate\">Yield and the Risk-Free Rate\u003C/h3>\n\u003Cp>\u003Cstrong>What do these people want?\u003C/strong> More money. One way to get more money is to buy an asset that provides \u003Cstrong>yield\u003C/strong>. The\nyield on a security is a measure of the ex-ante return to a holder of the security. Some assets, like fixed-income\nsecurities like bonds, provide yield in the form of coupon rates. The yield for â€œrisk-freeâ€ assets (i.e. securities with\nvirtually zero risk of loss) set the â€œrisk-free rateâ€. Most people consider 10-year US Treasury bonds (US10Y) to set the\nrisk-free rate. If you buy a US10Y you receive a fixed interest payment every 6 months. The government pays you for\nlocking up money with them for 10 years. Right now, that rate is ~4.4%. Different securities have different ways of\nproviding yield (cash dividends etc) but the principle is the same as for coupon rates.\u003C/p>\n\u003Cp>\u003Cimg src=\"https://storage.googleapis.com/langkilde-se-images/08e663a3-2c2b-418b-a881-37613aeb9bc0.jpeg\" alt=\"\">\u003C/p>\n\u003Cp>\u003Cstrong>The risk-free rate has been declining since the 1980s.\u003C/strong> This has encouraged investors to take more and more risk. The\nperiod from 2008 to 2021 offered an extraordinarily low cost of capital. Looking back, risk-free rates are now back to\npre-2008 levels of interest rates, and the curve has shot up for the first time in decades. For the last 15 years,\ngovernments have stimulated the economy to first recover from the 2008 meltdown, and then the 2020 Covid lockdown. They\ndid not want people to deposit their money into savings, so they turned down the yield on government-backed securities,\nthereby stimulating the economy. But those times are over now, and investors now get a 4.4% return on their money\nwithout taking any risk at all. Assuming all other assets have more risk, money managers will benchmark assets against\nthe risk-free rate.\u003C/p>\n\u003Ch3 id=\"how-interest-rates-affect-startups\">How Interest Rates Affect Startups\u003C/h3>\n\u003Cp>\u003Cstrong>Why does this matter for a startup?\u003C/strong> Well, one way to get yield is to seek riskier investments. And startups are\nincredibly risky. I wrote a lot about\nthis \u003Ca href=\"https://langkilde.se/post/2023-01-09-building-extremely-valuable-companies\">last winter\u003C/a>. While returns can be\nhigh, the variance of return is high.\u003C/p>\n\u003Cp>\u003Cimg src=\"https://storage.googleapis.com/langkilde-se-images/3389b20d-0d01-4755-a007-92b9cc33b94a.jpeg\" alt=\"\">\u003C/p>\n\u003Cp>\u003Cimg src=\"https://storage.googleapis.com/langkilde-se-images/619a1309-d352-4225-a3a9-31ad6609a7fc.jpeg\" alt=\"\">\u003C/p>\n\u003Cp>\u003Cstrong>When the risk-free rate increases, less money is invested in higher-risk assets.\u003C/strong> At the peak of the â€œbull marketâ€ (\n2020-2021) investors struggled to get yield, so they chased riskier and riskier investments. This resulted in higher and\nhigher private valuations of not only startups but also public companies. And much more money became available to\nstartups. According to \u003Ca href=\"https://www.meritechcapital.com/blog/meritech-software-pulse\">Meritech\u003C/a> public market\nsoftware-as-a-service valuations reached stratospheric levels during Covid. At one point, you had to pay almost 40 times\nthe next twelve-month sales forecast to buy shares in top-performing software companies. Thatâ€™s \u003Cstrong>\u003Cem>a lot\u003C/em>\u003C/strong> considering\nmany of these companies do not pay dividends. Some arenâ€™t even profitable.\u003C/p>\n\u003Cp>\u003Cimg src=\"https://storage.googleapis.com/langkilde-se-images/7c884031-855e-489c-bb01-99c97c2b2863.jpeg\" alt=\"\">\u003C/p>\n\u003Cp>\u003Cstrong>The price of an asset should be proportional to its Sharpe ratio, i.e. the (return minus the risk-free rate) / (\nvariance of return).\u003C/strong> Of course, you donâ€™t know this number upfront for a specific investment. The job of e.g. venture\ncapitalists is to estimate the return and risk. To do that, they pattern match. They will say they donâ€™t, but they do.\nThey look at as many things as they can and try to conclude what the common denominators are between successful\ncompanies. When they set valuations, they will benchmark against similar companies with known valuations. In private\nmarkets, this becomes a sort of circular argument that is ultimately anchored in the public market. Public markets\nprovide clear prices, as opposed to private companies that arenâ€™t traded regularly (or at all). So when you sell shares\nin a private company, investors need to determine: \u003Cstrong>What is the potential of this investment compared to other possible\ninvestments I could make, and what is the risk that I lose my money?\u003C/strong>\u003C/p>\n\u003Cp>\u003Cstrong>Letâ€™s create a specific example.\u003C/strong> To better explain how valuations work, we will cheat and assume we know all the\nvariables (which you never do). Here comes a ton of numbers:\u003C/p>\n\u003Cp>\u003Cimg src=\"https://storage.googleapis.com/langkilde-se-images/f3e39d09-020e-4aa5-8e51-ef18d1f3a7a0.jpeg\" alt=\"\">\u003C/p>\n\u003Ch3 id=\"valuation-and-expected-returns\">Valuation and Expected Returns\u003C/h3>\n\u003Cp>\u003Cstrong>Letâ€™s assume, for the sake of argument, that our company ends up in a\nglorious $500M exit.\u003C/strong> Such exits are extraordinarily rare. As a seed investor, we have a few things to consider: At what valuation am I investing, what is a possible exit valuation, and what is the probability of success? Letâ€™s say we are one of the worldâ€™s best seed investors, so 1/20 tickets end up generating a rare exit (I donâ€™t know if anyone can deliver such good odds, but letâ€™s pretend). Considering the dilution from Series A, B, and C, our share of $\n1M could be worth as much as $24M. Holy moly, thatâ€™s a lot of money. But, letâ€™s remember, we only think this happens in 1/20 cases. If we only invested in this one company, the expected annual return is just 2.4%, i.e. much worse than the risk-free rate and NASDAQ. If we placed 20 bets like this, assuming 19 of them will go to zero, weâ€™d have to invest $\n20M to get one $24M outcome. Thatâ€™s $4M net value in 9 years, or 2% annually. Also worse than the risk-free rate and\nNASDAQ. But, letâ€™s change an important variable: letâ€™s pretend we can get a $1B outcome instead. Unicorns. How many\ncompanies become dollar unicorns? Very, very, very, very few. Decacorns? Like 10 in a decade maybe?\u003C/p>\n\u003Cp>\u003Cimg src=\"https://storage.googleapis.com/langkilde-se-images/aa094252-22e0-4111-902c-d287f7f01fce.jpeg\" alt=\"\">\u003C/p>\n\u003Cp>Babam. Now, all of a sudden, we can get one $48.7M windfall instead. That means weâ€™ve made $28.7M on our seed portfolio\nof 20 companies, or a 43% gain. Thatâ€™s 4.1% annually. So now we are basically on par with the risk-free rate. But we\nneed a company that can swallow almost $200M and generate enough revenue to support a $1B valuation. Venture is about\nfinding outliners that can deliver extraordinary returns in a very short amount of time. If we doubled the number of\nyears it takes to reach the outcome valuation, we cut the expected annualized return in half. \u003Cstrong>Venture capital works\nwith short timelines ( &#x3C;10y) and most huge companies take decades to build.\u003C/strong>\u003C/p>\n\u003Cp>\u003Cstrong>When interest rates change, this presents a triple whammy to these sorts of spreadsheets.\u003C/strong> On the one hand, it\nincreases the risk-free rate, so companies need to perform better to deliver competitive returns. It also lowers the\nexpected multiples of public companies, thereby lowering the expected market capitalization. Finally, it also means less\nmoney from the trillions of capital that need to be allocated is steered towards venture investments, so raising a fund\ngets harder. The following chart from Battery Venture shows the US10Y vs SaaS multiples. Pretty strong correlation as\nyou can see.\u003C/p>\n\u003Cp>\u003Cimg src=\"https://storage.googleapis.com/langkilde-se-images/924f3891-c589-4a35-b450-b2cb0a1239c5.jpeg\" alt=\"\">\u003C/p>\n\u003Ch3 id=\"current-state-of-venture-markets\">Current State of Venture Markets\u003C/h3>\n\u003Cp>\u003Cstrong>What this means is that right now, there are a lot of very highly valued startups that probably arenâ€™t worth the price\nput on them in their latest funding round.\u003C/strong> Another chart from Battery shows a very crowded box for $1B+ startups that\nsoon need to start providing liquidity to venture funds. Venture funds are typically close-ended, i.e. investors lock\ntheir money up for 10 years. But after that, they expect to get their money back again. If a VC has a portfolio of\ncompanies that they cannot sell, they cannot return money to their investors. That creates a sort of Mexican standoff.\nIf investors in a VC fund push for liquidity, VCs are forced to â€œmark to marketâ€, i.e. put a price on their assets.\nAnother interesting tidbit: turns out investing in a fund doesnâ€™t mean you have to give them money right away. The VC\nfund instead \u003Cem>calls\u003C/em> on capital when needed. Right now, some investors might not be able to honor such a cash call,\nsince they havenâ€™t gotten money back from previous investments. If the IPO market is dead, there is limited liquidity in\nthe secondary market, and the company does not provide revenue enough to defend its valuation, you have a toxic\ncocktail. \u003Cstrong>This is the state of the current market.\u003C/strong>\u003C/p>\n\u003Cp>\u003Cimg src=\"https://storage.googleapis.com/langkilde-se-images/f65f010b-6cfd-4449-a3ed-71a66cb3a0aa.jpeg\" alt=\"\">\u003C/p>\n\u003Ch3 id=\"how-venture-firms-respond\">How Venture Firms Respond\u003C/h3>\n\u003Cp>How do venture firms make sure they make money in a market like this? Well, they only invest in truly extraordinary\ncompanies. For Series B, weâ€™re talking:\u003C/p>\n\u003Cul>\n\u003Cli>\n\u003Cp>Minimum $5-10M ARR\u003C/p>\n\u003C/li>\n\u003Cli>\n\u003Cp>Minimum 2-3x YoY growth\u003C/p>\n\u003C/li>\n\u003Cli>\n\u003Cp>Burn multiple of max 1-2x (burn / net new ARR)\u003C/p>\n\u003C/li>\n\u003Cli>\n\u003Cp>â€œRule of 40â€ needs to be over 40, i.e. EBIT margin + growth = 40\u003C/p>\n\u003C/li>\n\u003C/ul>\n\u003Cp>\u003Cstrong>Very few companies can deliver such metrics.\u003C/strong> You can be an extraordinary operator and still not have a chance. It\ntakes a certain market, and a certain sort of business, to reach such stratospheric growth levels. As a result, VCs will\nlook for companies that have:\u003C/p>\n\u003Cul>\n\u003Cli>\n\u003Cp>\u003Cstrong>Huge, huge markets.\u003C/strong> SMEs and consumer products have this. Sometimes enterprise.\u003C/p>\n\u003C/li>\n\u003Cli>\n\u003Cp>\u003Cstrong>Low friction sales motion.\u003C/strong> This is why everyone loves product-led growth (PLG). No sales team! ðŸŽ‰\u003C/p>\n\u003C/li>\n\u003Cli>\n\u003Cp>\u003Cstrong>Experienced team.\u003C/strong> There are a lot of ways to fuck up.\u003C/p>\n\u003C/li>\n\u003C/ul>\n\u003Ch3 id=\"alignment-between-founders-and-investors\">Alignment Between Founders and Investors\u003C/h3>\n\u003Cp>\u003Cstrong>Here is where VCs and founders (can) have conflicting priorities.\u003C/strong> Investors seeking extraordinary outcomes are not\ninterested in â€œsafe betsâ€. If the probability of success is 10%, 20%, or 30% doesnâ€™t change the math as much as looking\nfor companies with a possible $10B outcome instead of a $100M. The 100x difference in potential outcome far exceeds the\nimpact of better odds of survival. And, in the end, most startups fail anyway, so they assume there arenâ€™t any â€œsure\nthingsâ€.\u003C/p>\n\u003Cp>\u003Cstrong>Tier 1 investors are called Tier 1 because they deliver the best returns to their investors.\u003C/strong> The best provide\n20-30%+ net IRR (after fees etc). Some even more. Their business is not to foster innovation, or to fund your science\nproject. They are looking to make tons of money. You should only take on an investment from a Tier 1 VC if you\nunderstand what youâ€™re doing.\u003C/p>\n\u003Cblockquote>\n\u003Cp>VC money is like powering your car with an unstable nuclear reactor. You will fly fast as fuck, but the most likely\noutcome is a meltdown.\u003C/p>\n\u003C/blockquote>\n\u003Cp>Iâ€™m starting to understand that the best investors seek a mutual fit between the founder, the company, and their\ninvestment. You have to establish shared expectations: How much risk are we taking? What sort of returns are we\nexpecting? What sort of company are you building? How comfortable are you â€œgoing for brokeâ€? Can you\nprovide $100M in returns to a fund? $1B? Does the business you envision support such an outcome? Does the market? *\n\u003Cem>Difficult questions you have to deal with before you raise money.\u003C/em>*\u003C/p>\n\u003Ch3 id=\"conclusion-who-should-raise-vc\">Conclusion: Who Should Raise VC?\u003C/h3>\n\u003Cp>Personally, I think it takes years of experience running a startup before you can honestly reason about these things.\nFirst-time founders have no idea what they are getting into, for better or worse. Second-time founders who had a\nmoderately successful first try, understand how things work, and are \u003Cem>still\u003C/em> determined to take VC money - those are the\nones who probably should. It doesnâ€™t mean they will succeed, but Iâ€™m certain their odds are way better.\u003C/p>",{"headings":639,"localImagePaths":667,"remoteImagePaths":668,"frontmatter":669,"imagePaths":670},[640,643,646,649,652,655,658,661,664],{"depth":24,"slug":641,"text":642},"amount-of-capital-in-the-world","Amount of Capital in the World",{"depth":24,"slug":644,"text":645},"who-owns-global-equity-markets","Who Owns Global Equity Markets?",{"depth":24,"slug":647,"text":648},"yield-and-the-risk-free-rate","Yield and the Risk-Free Rate",{"depth":24,"slug":650,"text":651},"how-interest-rates-affect-startups","How Interest Rates Affect Startups",{"depth":24,"slug":653,"text":654},"valuation-and-expected-returns","Valuation and Expected Returns",{"depth":24,"slug":656,"text":657},"current-state-of-venture-markets","Current State of Venture Markets",{"depth":24,"slug":659,"text":660},"how-venture-firms-respond","How Venture Firms Respond",{"depth":24,"slug":662,"text":663},"alignment-between-founders-and-investors","Alignment Between Founders and Investors",{"depth":24,"slug":665,"text":666},"conclusion-who-should-raise-vc","Conclusion: Who Should Raise VC?",[],[],{"pubDate":632,"title":631},[],"should-you-raise-vc-money.md","shareholder-value",{"id":672,"data":674,"body":677,"filePath":678,"digest":679,"rendered":680,"legacyId":710},{"title":675,"pubDate":676},"Shareholder Value","2024-05-06","### The Core Responsibility of a Founder\n\nAs a founder, your most important concern should be the obstacles you are overcoming, and the customers you are\nserving. I try to focus as much time as possible on these two things.\n\n### Funding Your Startup: Profit vs. Equity\n\nBut, in order to solve interesting and hard problems, you need to hire a team and potentially buy things. For startups\nthere are basically two main ways to get resources: turn a profit, or sell equity. You either sell goods and\nservices for more than they cost, or you sell shares. No self-respecting bank would lend money to an untested\nstartup. And you probably shouldn't risk your own savings either.\n\n**Turning a profit as a product company is hard.** It means you have to create a product that is valuable to someone\nelse. That usually requires an upfront investment in both **product development** and **distribution**. Services is\neasier to get started with, but less profitable in the long-run.\n\n### Understanding Startup Valuations and Funding Rounds\n\n**Startups typically raise money by selling shares.** A so-called \"funding round\". Startup people can't stop talking\nabout funding rounds. Pre-seed, seed, series A and so on. If you decide to raise money by selling shares, you will\nquickly discover that **the future value of your company** is critical. This is also pretty obvious: the higher the\nfuture expected value of a company, the higher the current value of the company. The main job of an investor is to\nestimate the future value of a company and compare that to the current price of shares. Given a set of share prices and\nfuture expected values, the investor can start to compare the relative attractiveness of different companies. A rational\ninvestor will buy shares in the company with the most attractive **returns profile**. A returns profile takes into\naccount several different things: how much capital can be invested, how much return can be expected, and how long it\nwill take to get that return. Long books have been written on the subject of investing, but the basic idea is simple:\nthe higher your annual return, the better.\n\n### Valuing Your Startup at the Earliest Stage\n\nLet's say we start from zero: you have no product, no customers, no revenue. You create a company\nand offer angle investors to buy shares. How do you appraise this company? One way to do it would be to ask: \"How much\ndo we think this company could be worth in 10 years if this team is super-successful?\". From what I understand,\nexperienced early stage investors will almost exclusively look at one thing at this point: the founder. Will this\nperson persevere through the countless challenges that lie ahead? Will they be able to attract the right people\nalong the way? Will they be able to make the right decisions? Pricing at this point is mostly a function of\ncompetition. If the founder has ten investors lined up competing to invest, the price will be high. The\ncounter-acting force is that the founder needs to put the company on an attractive equity journey. It's likely not\nin your interest as a founder to maximize the valuation in every round. Ideally, you price the company so that you\ncan raise enough money to get to the next milestone, but not so much that you can't raise money at a higher\nvaluation the next time.\n\n### Metrics and Valuation at Later Stages\n\nAs companies grow, the valuation becomes as much a function of the company's performance as your expectations about\nthe future. Emphasis slowly shifts from the founder and the expectations, to metrics like growth, margin and\nprofitability. Of course, leaders at a company, and expectations, are always a part of the equation.\n\nThis introduces the next critical concept: **Enterprise Value** and **Shareholder Value**. Together with the **Cost of\nCapital**, these are the three most important financial concepts a founder needs to understand. Enterprise value is\nthe value of your company. It's determined as the price per share times the number of shares. The price per share is\ndetermined by supply and demand: how many shares are available to buy, and how much are people willing to pay for\nthem? Willingness to pay is determined by the future expected value of the company. Shareholder Value on the other\nhand is the value shareholders get from holding your shares. Shareholder value primarily comes in two forms: 1)\nincrease in share price or 2) dividends.\n\n> If a company needs capital to grow, it's important to understand if the expected increase in\n> enterprise value over time exceeds the cost of capital. If it does, you will create shareholder value. If not, you\n> will destroy shareholder value.\n\n### The Ultimate Goal: Creating Shareholder Value\n\n**The purpose of a company is to create shareholder value.** If your goal is not to create shareholder value, you should\nfind a different way to solve the problem you are focused on. You can start an NGO, or a charity. Or go into academia.\n\nAs a founder, you need to take this into account. If you determined that it is in your interest to raise money, then\nyou need to convince investors that the future value of your company will be high. The valuation of your company today\ndetermines your cost of capital. The cost of capital, in turn, determines how much and how fast you can invest in\nproduct development and distribution. If you get a really high valuation that translates into a low cost of capital.\nBut, in order to provide shareholder value, you need to increase the enterprise value of your company a lot. You need to\nweigh the following things:\n\n- The cost of capital at which you can raise money\n- The expected future enterprise value of your company\n- The need for capital\n\n### When Should You Raise Money?\n\nIf you think you can convert capital into enterprise value at a higher rate than the cost of capital, you should\nraise. If not, you should aim to turn a profit. I think a lot of startup founders get this wrong. They think the\ngoal is to raise and spend money, when in fact the goal is to create shareholder value.\n\nLet's say you have a company that is growing at 100% per year. You generate $20M in revenue with a 45% margin.\nShould you raise money? The answer comes down to: will it generate long-term shareholder value? Is the cost of\ncapital today versus the expected future enterprise value in favor of raising money?\n\n### Conclusion\n\nThis is a complex question without a simple answer. This post only scratches the surface. But I hope it gives you\nsome food for thought. As a founder, you need to understand the financial concepts that drive your company. That\nsaid, the most important thing is still to focus on the problem you are solving and the customers you are serving.","src/content/blog/shareholder-value.md","4d71f249d6abd46c",{"html":681,"metadata":682},"\u003Ch3 id=\"the-core-responsibility-of-a-founder\">The Core Responsibility of a Founder\u003C/h3>\n\u003Cp>As a founder, your most important concern should be the obstacles you are overcoming, and the customers you are\nserving. I try to focus as much time as possible on these two things.\u003C/p>\n\u003Ch3 id=\"funding-your-startup-profit-vs-equity\">Funding Your Startup: Profit vs. Equity\u003C/h3>\n\u003Cp>But, in order to solve interesting and hard problems, you need to hire a team and potentially buy things. For startups\nthere are basically two main ways to get resources: turn a profit, or sell equity. You either sell goods and\nservices for more than they cost, or you sell shares. No self-respecting bank would lend money to an untested\nstartup. And you probably shouldnâ€™t risk your own savings either.\u003C/p>\n\u003Cp>\u003Cstrong>Turning a profit as a product company is hard.\u003C/strong> It means you have to create a product that is valuable to someone\nelse. That usually requires an upfront investment in both \u003Cstrong>product development\u003C/strong> and \u003Cstrong>distribution\u003C/strong>. Services is\neasier to get started with, but less profitable in the long-run.\u003C/p>\n\u003Ch3 id=\"understanding-startup-valuations-and-funding-rounds\">Understanding Startup Valuations and Funding Rounds\u003C/h3>\n\u003Cp>\u003Cstrong>Startups typically raise money by selling shares.\u003C/strong> A so-called â€œfunding roundâ€. Startup people canâ€™t stop talking\nabout funding rounds. Pre-seed, seed, series A and so on. If you decide to raise money by selling shares, you will\nquickly discover that \u003Cstrong>the future value of your company\u003C/strong> is critical. This is also pretty obvious: the higher the\nfuture expected value of a company, the higher the current value of the company. The main job of an investor is to\nestimate the future value of a company and compare that to the current price of shares. Given a set of share prices and\nfuture expected values, the investor can start to compare the relative attractiveness of different companies. A rational\ninvestor will buy shares in the company with the most attractive \u003Cstrong>returns profile\u003C/strong>. A returns profile takes into\naccount several different things: how much capital can be invested, how much return can be expected, and how long it\nwill take to get that return. Long books have been written on the subject of investing, but the basic idea is simple:\nthe higher your annual return, the better.\u003C/p>\n\u003Ch3 id=\"valuing-your-startup-at-the-earliest-stage\">Valuing Your Startup at the Earliest Stage\u003C/h3>\n\u003Cp>Letâ€™s say we start from zero: you have no product, no customers, no revenue. You create a company\nand offer angle investors to buy shares. How do you appraise this company? One way to do it would be to ask: â€œHow much\ndo we think this company could be worth in 10 years if this team is super-successful?â€. From what I understand,\nexperienced early stage investors will almost exclusively look at one thing at this point: the founder. Will this\nperson persevere through the countless challenges that lie ahead? Will they be able to attract the right people\nalong the way? Will they be able to make the right decisions? Pricing at this point is mostly a function of\ncompetition. If the founder has ten investors lined up competing to invest, the price will be high. The\ncounter-acting force is that the founder needs to put the company on an attractive equity journey. Itâ€™s likely not\nin your interest as a founder to maximize the valuation in every round. Ideally, you price the company so that you\ncan raise enough money to get to the next milestone, but not so much that you canâ€™t raise money at a higher\nvaluation the next time.\u003C/p>\n\u003Ch3 id=\"metrics-and-valuation-at-later-stages\">Metrics and Valuation at Later Stages\u003C/h3>\n\u003Cp>As companies grow, the valuation becomes as much a function of the companyâ€™s performance as your expectations about\nthe future. Emphasis slowly shifts from the founder and the expectations, to metrics like growth, margin and\nprofitability. Of course, leaders at a company, and expectations, are always a part of the equation.\u003C/p>\n\u003Cp>This introduces the next critical concept: \u003Cstrong>Enterprise Value\u003C/strong> and \u003Cstrong>Shareholder Value\u003C/strong>. Together with the \u003Cstrong>Cost of\nCapital\u003C/strong>, these are the three most important financial concepts a founder needs to understand. Enterprise value is\nthe value of your company. Itâ€™s determined as the price per share times the number of shares. The price per share is\ndetermined by supply and demand: how many shares are available to buy, and how much are people willing to pay for\nthem? Willingness to pay is determined by the future expected value of the company. Shareholder Value on the other\nhand is the value shareholders get from holding your shares. Shareholder value primarily comes in two forms: 1)\nincrease in share price or 2) dividends.\u003C/p>\n\u003Cblockquote>\n\u003Cp>If a company needs capital to grow, itâ€™s important to understand if the expected increase in\nenterprise value over time exceeds the cost of capital. If it does, you will create shareholder value. If not, you\nwill destroy shareholder value.\u003C/p>\n\u003C/blockquote>\n\u003Ch3 id=\"the-ultimate-goal-creating-shareholder-value\">The Ultimate Goal: Creating Shareholder Value\u003C/h3>\n\u003Cp>\u003Cstrong>The purpose of a company is to create shareholder value.\u003C/strong> If your goal is not to create shareholder value, you should\nfind a different way to solve the problem you are focused on. You can start an NGO, or a charity. Or go into academia.\u003C/p>\n\u003Cp>As a founder, you need to take this into account. If you determined that it is in your interest to raise money, then\nyou need to convince investors that the future value of your company will be high. The valuation of your company today\ndetermines your cost of capital. The cost of capital, in turn, determines how much and how fast you can invest in\nproduct development and distribution. If you get a really high valuation that translates into a low cost of capital.\nBut, in order to provide shareholder value, you need to increase the enterprise value of your company a lot. You need to\nweigh the following things:\u003C/p>\n\u003Cul>\n\u003Cli>The cost of capital at which you can raise money\u003C/li>\n\u003Cli>The expected future enterprise value of your company\u003C/li>\n\u003Cli>The need for capital\u003C/li>\n\u003C/ul>\n\u003Ch3 id=\"when-should-you-raise-money\">When Should You Raise Money?\u003C/h3>\n\u003Cp>If you think you can convert capital into enterprise value at a higher rate than the cost of capital, you should\nraise. If not, you should aim to turn a profit. I think a lot of startup founders get this wrong. They think the\ngoal is to raise and spend money, when in fact the goal is to create shareholder value.\u003C/p>\n\u003Cp>Letâ€™s say you have a company that is growing at 100% per year. You generate $20M in revenue with a 45% margin.\nShould you raise money? The answer comes down to: will it generate long-term shareholder value? Is the cost of\ncapital today versus the expected future enterprise value in favor of raising money?\u003C/p>\n\u003Ch3 id=\"conclusion\">Conclusion\u003C/h3>\n\u003Cp>This is a complex question without a simple answer. This post only scratches the surface. But I hope it gives you\nsome food for thought. As a founder, you need to understand the financial concepts that drive your company. That\nsaid, the most important thing is still to focus on the problem you are solving and the customers you are serving.\u003C/p>",{"headings":683,"localImagePaths":706,"remoteImagePaths":707,"frontmatter":708,"imagePaths":709},[684,687,690,693,696,699,702,705],{"depth":24,"slug":685,"text":686},"the-core-responsibility-of-a-founder","The Core Responsibility of a Founder",{"depth":24,"slug":688,"text":689},"funding-your-startup-profit-vs-equity","Funding Your Startup: Profit vs. Equity",{"depth":24,"slug":691,"text":692},"understanding-startup-valuations-and-funding-rounds","Understanding Startup Valuations and Funding Rounds",{"depth":24,"slug":694,"text":695},"valuing-your-startup-at-the-earliest-stage","Valuing Your Startup at the Earliest Stage",{"depth":24,"slug":697,"text":698},"metrics-and-valuation-at-later-stages","Metrics and Valuation at Later Stages",{"depth":24,"slug":700,"text":701},"the-ultimate-goal-creating-shareholder-value","The Ultimate Goal: Creating Shareholder Value",{"depth":24,"slug":703,"text":704},"when-should-you-raise-money","When Should You Raise Money?",{"depth":24,"slug":223,"text":224},[],[],{"pubDate":676,"title":675},[],"shareholder-value.md","the-energy-to-keep-going",{"id":711,"data":713,"body":716,"filePath":717,"digest":718,"rendered":719,"legacyId":739},{"title":714,"pubDate":715},"The energy to keep going","2022-04-09","I spend a lot of time evaluating people. Iâ€™d say itâ€™s perhaps the most important part of building a business: identify\nthe job to be done, set expectations, find someone you can trust to get it done, and then give them the support they\nneed. Itâ€™s hard work and requires both curiosity and brutal honesty, but itâ€™s also extremely rewarding and interesting.\nIâ€™ve always been curious about other people. What makes someone get up in the morning? What drives them?\n\n### What Drives High-Performing People?\n\nI believe smart people who are prepared to work hard will always be able to make a living in a peaceful democracy. And\nfor most people, thatâ€™s enough. A job, a family, and the joy of everyday things. I respect that, and I understand that.\nSome, however, for some reason, need more. I really donâ€™t think such people are inherently better or happier, _but_ they\nare typically higher-performing employees.\n\nThe highest performing people Iâ€™ve come across are driven by something like:\n\n- â€œproving myselfâ€\n- â€œwinningâ€\n- â€œhelping othersâ€\n- â€œbeing the bestâ€\n- â€œa callingâ€\n- â€œthe joy of learningâ€\n- â€œproblem-solvingâ€.\n\nFor a while, it can be â€œmaking moneyâ€, but that quickly fades when you have enough to live comfortably.\n\n### Fear is the mind killer\n\nLower-performing people tend to be driven by fear. Fear of being wrong, fear of failure, fear of disappointment, fear of\nnot being good enough. They do not â€œscaleâ€ since they will be unable to rally people around them. People do not trust a\nleader who is scared. They also will not trust someone who is reckless, so find a balance. My point is that there is a\nfine line between motivation, fear, and recklessness, but there is an important difference. And you know it when you see\npeople in action if they are driven by fear, joyful determination or if they are just gambling.\n\n### Pressure Reveals True Motivation\n\nWhen you push someone, their motivation will be revealed in my experience. Put someone in a high-pressure situation and\nask them to choose, and you will learn a lot about their motivation. When reading about people that build huge\ncompanies, or become prominent politicians, I sense they are all people who never say â€œthis is good enough, I donâ€™t need\nmoreâ€ or â€œno, itâ€™s not worth more effortâ€. Sustained determination and grit a rare thing because it usually does not\nmake sense. Working really hard when you are already financially comfortable or successful in your field does not make\nsense. But some keep going.\n\n### Why Do I Keep Going?\n\nI do not stop for some reason. Itâ€™s still never â€œnot worth itâ€ for me. Iâ€™m prepared to fight through a lot of pain to\nbuild. Why? Deep down I guess I want to prove that I can. Probably to childhood bullies. Probably to my mother. Probably\nbecause I was an awkward nerd growing up. Iâ€™m fine with that. I like my life. I enjoy the\npursuit. [I treat myself](https://www.youtube.com/watch?v=ZsABTmT1_M0). I feel alive when building things and solving\nproblems. I cherish the appreciation that comes with that. I get to meet fascinating people and experience exciting\nthings and Iâ€™ve made great friends doing it. Somehow that gives me the energy to keep going.\n\nLet me repeat that I donâ€™t think that makes me better. In some situations, it absolutely makes me a worse person. Either\nway, it helps to know where your partners are on this scale. If you want to build something great, partner with people\nthat keep going. They exist, and they will take you really far.","src/content/blog/the-energy-to-keep-going.md","74636a280fb4b361",{"html":720,"metadata":721},"\u003Cp>I spend a lot of time evaluating people. Iâ€™d say itâ€™s perhaps the most important part of building a business: identify\nthe job to be done, set expectations, find someone you can trust to get it done, and then give them the support they\nneed. Itâ€™s hard work and requires both curiosity and brutal honesty, but itâ€™s also extremely rewarding and interesting.\nIâ€™ve always been curious about other people. What makes someone get up in the morning? What drives them?\u003C/p>\n\u003Ch3 id=\"what-drives-high-performing-people\">What Drives High-Performing People?\u003C/h3>\n\u003Cp>I believe smart people who are prepared to work hard will always be able to make a living in a peaceful democracy. And\nfor most people, thatâ€™s enough. A job, a family, and the joy of everyday things. I respect that, and I understand that.\nSome, however, for some reason, need more. I really donâ€™t think such people are inherently better or happier, \u003Cem>but\u003C/em> they\nare typically higher-performing employees.\u003C/p>\n\u003Cp>The highest performing people Iâ€™ve come across are driven by something like:\u003C/p>\n\u003Cul>\n\u003Cli>â€œproving myselfâ€\u003C/li>\n\u003Cli>â€œwinningâ€\u003C/li>\n\u003Cli>â€œhelping othersâ€\u003C/li>\n\u003Cli>â€œbeing the bestâ€\u003C/li>\n\u003Cli>â€œa callingâ€\u003C/li>\n\u003Cli>â€œthe joy of learningâ€\u003C/li>\n\u003Cli>â€œproblem-solvingâ€.\u003C/li>\n\u003C/ul>\n\u003Cp>For a while, it can be â€œmaking moneyâ€, but that quickly fades when you have enough to live comfortably.\u003C/p>\n\u003Ch3 id=\"fear-is-the-mind-killer\">Fear is the mind killer\u003C/h3>\n\u003Cp>Lower-performing people tend to be driven by fear. Fear of being wrong, fear of failure, fear of disappointment, fear of\nnot being good enough. They do not â€œscaleâ€ since they will be unable to rally people around them. People do not trust a\nleader who is scared. They also will not trust someone who is reckless, so find a balance. My point is that there is a\nfine line between motivation, fear, and recklessness, but there is an important difference. And you know it when you see\npeople in action if they are driven by fear, joyful determination or if they are just gambling.\u003C/p>\n\u003Ch3 id=\"pressure-reveals-true-motivation\">Pressure Reveals True Motivation\u003C/h3>\n\u003Cp>When you push someone, their motivation will be revealed in my experience. Put someone in a high-pressure situation and\nask them to choose, and you will learn a lot about their motivation. When reading about people that build huge\ncompanies, or become prominent politicians, I sense they are all people who never say â€œthis is good enough, I donâ€™t need\nmoreâ€ or â€œno, itâ€™s not worth more effortâ€. Sustained determination and grit a rare thing because it usually does not\nmake sense. Working really hard when you are already financially comfortable or successful in your field does not make\nsense. But some keep going.\u003C/p>\n\u003Ch3 id=\"why-do-i-keep-going\">Why Do I Keep Going?\u003C/h3>\n\u003Cp>I do not stop for some reason. Itâ€™s still never â€œnot worth itâ€ for me. Iâ€™m prepared to fight through a lot of pain to\nbuild. Why? Deep down I guess I want to prove that I can. Probably to childhood bullies. Probably to my mother. Probably\nbecause I was an awkward nerd growing up. Iâ€™m fine with that. I like my life. I enjoy the\npursuit. \u003Ca href=\"https://www.youtube.com/watch?v=ZsABTmT1_M0\">I treat myself\u003C/a>. I feel alive when building things and solving\nproblems. I cherish the appreciation that comes with that. I get to meet fascinating people and experience exciting\nthings and Iâ€™ve made great friends doing it. Somehow that gives me the energy to keep going.\u003C/p>\n\u003Cp>Let me repeat that I donâ€™t think that makes me better. In some situations, it absolutely makes me a worse person. Either\nway, it helps to know where your partners are on this scale. If you want to build something great, partner with people\nthat keep going. They exist, and they will take you really far.\u003C/p>",{"headings":722,"localImagePaths":735,"remoteImagePaths":736,"frontmatter":737,"imagePaths":738},[723,726,729,732],{"depth":24,"slug":724,"text":725},"what-drives-high-performing-people","What Drives High-Performing People?",{"depth":24,"slug":727,"text":728},"fear-is-the-mind-killer","Fear is the mind killer",{"depth":24,"slug":730,"text":731},"pressure-reveals-true-motivation","Pressure Reveals True Motivation",{"depth":24,"slug":733,"text":734},"why-do-i-keep-going","Why Do I Keep Going?",[],[],{"pubDate":715,"title":714},[],"the-energy-to-keep-going.md","the-probability-of-near-term-agi-like-systems",{"id":740,"data":742,"body":745,"filePath":746,"digest":747,"rendered":748,"legacyId":786},{"title":743,"pubDate":744},"The Probability Of Near-Term AGI-Like Systems","2023-03-26","Since I\nwrote â€œ[The State of Machine Learning in 2022](https://langkilde.se/post/2022-04-18-the-state-of-machine-learning-2022),â€\nAI has entered the mainstream. The internet is flooded with content about how GPT-like models will change everything. I\nhazarded to make predictions in â€œ[Next steps?](https://langkilde.se/post/2022-05-10-the-future-of-machine-learning)â€\nthat now seem embarrassingly conservative in hindsight:\n\n* **More modalities are merged.** Outcome => _Confirmed_.\n\n    * We now have text, pictures, sound, 3D models, and more.\n\n* **The Scaling Hypothesis Keeps Holding.** Outcome => _Confirmed_.\n\n    * Recent GPT results show that performance keeps increasing as models get more extensive and are trained on more and\n      more data.\n\n* **New companies are emerging.** Outcome => _Confirmed_.\n\n    * There is an explosion of funding in Generative AI and applications of GPT models. Several of the companies I\n      listed are now unicorns. Some are even decacorns.\n\nSo, where are we now? Most people feel overwhelmed by the rate of progress and struggle to sort through all information.\nThis is an attempt to summarize my view.\n\n### Drastically updated probability of near-term probability of AGI\n\nThose who know me know Iâ€™ve always been skeptical about hyperbolic claims around AI. I always preferred machine learning\nover artificial intelligence because AI felt pompous. My understanding of the available technology gave me no reason to\nthink we were close to some sort of human-like intelligence. But Iâ€™d rather be correct than consistent. **It is fair to\ncall todayâ€™s algorithms a form of AI. And maybe even AGI-like. At the very least, I have changed my mind about the\npossibility of near-term AGI-like systems, and Iâ€™m implementing many behavioral updates to align my life with my new\nview.** This process started more than a year ago, but it has only accelerated since.\n\n### Defining Artificial General Intelligence (AGI) is a distraction\n\n**First of all: Spending time defining â€œwhat is human intelligenceâ€ and â€œwhat is AGIâ€ is a distraction.** I get why the\nquestion is appealing, and I think it is philosophically interesting. But discussing it isnâ€™t necessary for addressing\nthe progress we have made and the opportunities and challenges that brings. Great physicists will tell you that there is\nalways another level of â€œwhyâ€ that will stump them. The challenge is to find questions that we can make meaningful\nprogress on now.\n\nWe know, for a fact, that currently available language models can answer questions that make them a viable substitute\nfor humans for a wide range of tasks. So in that sense, we have access to some form of general intelligence. I do not\nbelieve it is a form equivalent to the intelligence humans possess, but thatâ€™s not important. **Defining the tool, and\nrelating it to humans, has no impact on its usefulness**. As a society, we must accept that large swaths of human\nworkers are about to become obsolete.\n\n### Progress will most likely be faster than we can imagine\n\nThere is evidence that AI researchers use feedback loops based on LLVMs to accelerate progress further. The impact of\nthis is hard to predict. Assuming scaling laws keep holding and more funding is directed to training LLVMs, I think it\nis fair to assume there is a compounding acceleration of progress. That means **progress in AI is on an exponential\ntrajectory.** Of course, it is possible we will find limitations that result in diminishing marginal returns. But from\nmy perspective, there is a higher expected reward from assuming it will continue accelerating.\n\nAs with all new technology, descriptions of progress will be dismissed as hyperbolic. My view that we are at the\nbeginning of an exponential development might sound implausible or grandiose. I empathize with this view. There is good\nreason to be skeptical. Nevertheless, enough evidence exists to prepare for a world where rapid AI progress leads to\ntransformative AI systems.\n\nYou could start to notice in the mid-2010s that LLMs improved. Open AI was founded on the premise that we might get on\nan exponential trajectory toward AGI. The seeds of progress are training data, computation, and improved algorithms. Of\ncourse, it was clear there were many considerable hurdles ahead. Multimodality, logical reasoning, transfer learning\nacross tasks, and long-term memory were all unsolved. But one by one LLVMs are overcoming these hurdles.\n\n### The short-term impact of increasingly capable AI systems is underestimated\n\nPeople tend to be bad at recognizing and acknowledging exponential growth in its early phases. Politics is, ironically,\nboth a slow and a short-term process. Most politicians are currently worried about the price of electricity, inflation,\nor the war in Ukraine. I get that. That said, we need to act with urgency to prepare for the violent disruption that AI\nwill bring to the labor market. Large groups of people will need to reskill quickly. History shows this has a mostly\nnegative impact on earnings. While Iâ€™m optimistic the long-term impact of AI will be positive, we should prepare for the\nshort-term disruption.\n\n### The Alignment Problem\n\nI will quote from [Anthropicâ€™s website](https://www.anthropic.com/index/core-views-on-ai-safety):\n\n> **We do not know how to train AI systems to robustly behave well.** So far, no one knows how to train very powerful AI\n> systems to be robustly helpful, honest, and harmless. Furthermore, rapid AI progress will be disruptive to society and\n> may trigger competitive races that could lead corporations or nations to deploy untrustworthy AI systems. The results of\n> this could be catastrophic, either because AI systems strategically pursue dangerous goals, or because these systems\n> make more innocent mistakes in high-stakes situations.\n\nI think aligning AI systems with human values, and human preferences will be the main activity for both companies and\ngovernments for the foreseeable future. There is a new programming paradigm emerging with the advent of LLVMs. Itâ€™s\nalready over ten years ago that we moved from programming with code to programming with examples. We are now in the\nmiddle of yet another transition: fine-tuning large models based on human feedback. I want to try and explain what I\nmean by that.\n\n### Curating â€œThe Essence of Conceptsâ€ in Latent Spaces\n\n**My interpretation of LLVMs is that they learn â€œthe Essence of Concepts.â€** Let me explain. Around 2010 it became clear\nthat with enough labeled data, you can learn almost any task. Construct your dataset, carefully assemble labels, specify\na loss function and neural network architecture, train your network, and deploy. This approach has been applied\nsuccessfully to many tasks for the past decade.\n\n**But supervised learning has severe limitations** , the most notable of which is the shortage of labeled data. Even\nwith a great Data Engine, such as the one [Kognic](https://www.kognic.com) provides, there wonâ€™t be enough labels to\nlearn everything. Geoffrey Hinton is famous for saying:\n\n> The brain has about 10^14 synapses and we only live for about 10^9 seconds. So we have a lot more parameters than\n> data. This motivates the idea that we must do a lot of unsupervised learning since the perceptual input, including\n> proprioception, is the only place we can get 10^5 dimensions of constraints per second.\n\nRather than relying on text explicitly labeled, GPT models learn latent representations by reading large quantities of\ntext. There is a form of supervision involved since humans had to write everything on the internet first, but it is\ndifferent from explicit labeling targeting a specific task.\n\nUnderstanding the idea of learning â€œthe Essence of Conceptsâ€ requires understanding the inner workings of transformers,\nattention, and latent spaces. But in short: when we expose LLVMs to large amounts of multi-modal data, a representation\nis formed to maximize the probability of predicting the next item in a sequence. This representation abstracts away the\nsuperficial properties of words, objects, and even sentences. Ultimately, **concepts become points in a high-dimensional\nspace.**\n\nModels can decode from these points into whatever modality they can access and predict text or render\nimages. [Zero-shot translation](https://ai.googleblog.com/2016/11/zero-shot-translation-with-googles.html) is an example\nof this, where each language can be considered a modality. Concepts become points in a shared latent space from which\nyou can decode into any language part of the training process. Even when there is no direct mapping present in the\ntraining data.\n\nThe surprising thing in recent years has been the extraordinary capacity demonstrated by GPT-style models to learn many\ndifferent concepts simultaneously. It is from this ability that their power comes. What seems like a magical ability to\nhandle prompts never seen in the training data is most likely because the essence of the concept can be there anyway; we\nmight just not realize it. Humans are bad at thinking about points in high-dimensional spaces, and we cannot\nencode/decode such concepts. So for us, a concept might be missing in the training data. But for the model, some\ncompletely different things in the training data might end up very close to your prompt in the learned latent space. And\nvoila, the model predicts tokens in a way that feels magical.\n\n**The consequence is that programming now becomes a matter of curating the concepts encoded in a latent space. We do not\nhave the tools for this as of today.** For me, the alignment problem is equivalent to curating the concepts encoded in a\nlatent space. We want to shape concepts to align them with human values and human preferences. That way, model\npredictions will be acceptable to users.\n\n### Learn a Policy from Human Feedback (RLHF) on Latent Spaces\n\nSo, how do we align model predictions with human values and preferences? Yann LeCun has been building on Geoffrey\nHintons observation about the brain, and in his 2016 NIPS talk, said that:\n\n> â€œIf intelligence is a cake, the bulk of the cake is unsupervised learning, the icing on the cake is supervised\n> learning, and the cherry on the cake is reinforcement learning (RL).â€\n\nThe battlefield for AI in the coming years, I think, can be found in the intersection between these two ideas: 1) Learn\na latent representation by observing a lot of sequences, and 2) Fine-tune model predictions based on learning a policy\nthrough reinforcement learning from human feedback (RLHF). **This paradigm of RLHF is quickly getting adopted by\ncutting-edge companies.** Thereâ€™s a great outline of this approach [over at ðŸ¤—](https://huggingface.co/blog/rlhf).\n\n![](https://storage.googleapis.com/langkilde-se-images/e54677a4-aa07-46d4-916e-60a0f7a54356.jpeg)\n\nIn the example from ðŸ¤—, humans provide feedback on specific outputs. You prompt the model and then ask a human to rank\ndifferent answers or suggest improved responses. That feedback is then used to fine-tune your language model. However,\nimplicit in the model is the latent space. This latent space encodes everything the model has seen so that the\nrepresentation maximizes your ability to predict items in sequences. We have known for a long time that such latent\nspaces preserve semantic relationships in various ways. Anthropic illustrates a 2D projection of a latent space this\nway:\n\n![](https://storage.googleapis.com/langkilde-se-images/36dcca72-b6d7-4a76-837a-b523bd670102.jpeg)\n\nBy asking humans for feedback, they ascribe human values to sequences that can be grouped in some high-dimensional\nspace. A notable detail is that humans are noisy when asked to assign scalar rewards to outputs directly. Instead, the\nbest way is to ask humans to rank items.\n\nI recently came across an excellent blogpost by Viet Le\ntitled â€œ[Building a Defensible Machine Learning Company in the Age of Foundation Models](https://vietle.substack.com/p/defensible-machine-learning).â€\nHe describes what he thinks a defensible flywheel looks like:\n\n![](https://storage.googleapis.com/langkilde-se-images/f0abc8be-4158-4c07-b479-cd32fcd27d3e.jpeg)\n\n**Combine these ideas, and you get a glimpse of the future.** I expect we will see larger and larger foundation models\ntrained by large companies and institutions. These Foundation Models will learn from observing large quantities of\nempirical data. Companies will then create fine-tuned models based on some user interaction. Winners will be companies\nthat can attract the most users that, in turn, generate the best proprietary feedback for your specific application.\n\nTo speed up the process, we can apply human feedback directly to the latent space. Rather than have humans look at\nthousands of examples, we assume that clusters will form in high-dimensional space.\n\n![](https://storage.googleapis.com/langkilde-se-images/89e6fa94-34dc-47af-a564-af89f77e29f3.jpeg)\n\n### What can the RLHF workflow be applied to?\n\nAnything. Assuming you have enough recorded data in sequences and a ton of computing. Most existing limitations will\nmost likely be overcome with time and money. I expect this is the most viable way to learn how to drive, walk, operate\nmachinery, communicate, and do all the other things humans do. It seems reasonably likely that multi-modal transformers\nwill be enough for many, many applications.\n\n### Does this mean AGI is solved?\n\nNo. Not even close. While LLVMs are an amazing step towards AGI, there are many, many things that such models cannot\nsolve. I think we will see many novel model architectures in the years ahead and that GPT-styled models are a step on\nthe ladder as opposed to the ultimate solution. But again, that doesnâ€™t mean we shouldnâ€™t embrace them and push them to\ntheir limit. It just means thereâ€™s a lot more to explore, discover and create.\n\n### Whatâ€™s next?\n\nWell, a lot, probably. But here are some obvious things:\n\n**All digital products will have embedded intelligence** through integration with some large language model. We are in\nthe middle of the fastest new feature rollout bonanza Iâ€™ve ever seen. Since the integration is simple (just an API call\nto your LLM of choice), anyone can add intelligence to their product in hours.\n\n**Great products will require great RLHF solutions.** The user experience will need to be tuned. Even with perfect\nautomation, humans have preferences and values that we constantly negotiate socially. Updating behaviors will require\nefficient ways to fine-tune the concepts encoded in the latent space of your Foundation Model.\n\n**A growing constraint will become access to computing resources**. These models are still very, very expensive to\ntrain. This has been true for a while for the forerunners, but now everyone will start feeling the pain. Expect to spend\nmillions of dollars on GPUs.\n\n**Mixed modalities will grow fast.** Query and analyze text, video, and sound interchangeably. Store all your company\nmeetings and literally _talk to them_. This will be a game-changer for business productivity.\n\n**Company knowledge bases will be changed forever.** Employees will start talking to their companies. Iâ€™m assuming they\nalready are, but it will expand rapidly. No more hunting around in some shitty intranet. We will query, using natural\nlanguage, all documents inside our companies.\n\nAs a closing reminder: The future is already here. It is just unevenly distributed. **What a time to be alive.**","src/content/blog/the-probability-of-near-term-agi-like-systems.md","5c5dca6ee4c0ba01",{"html":749,"metadata":750},"\u003Cp>Since I\nwrote â€œ\u003Ca href=\"https://langkilde.se/post/2022-04-18-the-state-of-machine-learning-2022\">The State of Machine Learning in 2022\u003C/a>,â€\nAI has entered the mainstream. The internet is flooded with content about how GPT-like models will change everything. I\nhazarded to make predictions in â€œ\u003Ca href=\"https://langkilde.se/post/2022-05-10-the-future-of-machine-learning\">Next steps?\u003C/a>â€\nthat now seem embarrassingly conservative in hindsight:\u003C/p>\n\u003Cul>\n\u003Cli>\n\u003Cp>\u003Cstrong>More modalities are merged.\u003C/strong> Outcome => \u003Cem>Confirmed\u003C/em>.\u003C/p>\n\u003Cul>\n\u003Cli>We now have text, pictures, sound, 3D models, and more.\u003C/li>\n\u003C/ul>\n\u003C/li>\n\u003Cli>\n\u003Cp>\u003Cstrong>The Scaling Hypothesis Keeps Holding.\u003C/strong> Outcome => \u003Cem>Confirmed\u003C/em>.\u003C/p>\n\u003Cul>\n\u003Cli>Recent GPT results show that performance keeps increasing as models get more extensive and are trained on more and\nmore data.\u003C/li>\n\u003C/ul>\n\u003C/li>\n\u003Cli>\n\u003Cp>\u003Cstrong>New companies are emerging.\u003C/strong> Outcome => \u003Cem>Confirmed\u003C/em>.\u003C/p>\n\u003Cul>\n\u003Cli>There is an explosion of funding in Generative AI and applications of GPT models. Several of the companies I\nlisted are now unicorns. Some are even decacorns.\u003C/li>\n\u003C/ul>\n\u003C/li>\n\u003C/ul>\n\u003Cp>So, where are we now? Most people feel overwhelmed by the rate of progress and struggle to sort through all information.\nThis is an attempt to summarize my view.\u003C/p>\n\u003Ch3 id=\"drastically-updated-probability-of-near-term-probability-of-agi\">Drastically updated probability of near-term probability of AGI\u003C/h3>\n\u003Cp>Those who know me know Iâ€™ve always been skeptical about hyperbolic claims around AI. I always preferred machine learning\nover artificial intelligence because AI felt pompous. My understanding of the available technology gave me no reason to\nthink we were close to some sort of human-like intelligence. But Iâ€™d rather be correct than consistent. \u003Cstrong>It is fair to\ncall todayâ€™s algorithms a form of AI. And maybe even AGI-like. At the very least, I have changed my mind about the\npossibility of near-term AGI-like systems, and Iâ€™m implementing many behavioral updates to align my life with my new\nview.\u003C/strong> This process started more than a year ago, but it has only accelerated since.\u003C/p>\n\u003Ch3 id=\"defining-artificial-general-intelligence-agi-is-a-distraction\">Defining Artificial General Intelligence (AGI) is a distraction\u003C/h3>\n\u003Cp>\u003Cstrong>First of all: Spending time defining â€œwhat is human intelligenceâ€ and â€œwhat is AGIâ€ is a distraction.\u003C/strong> I get why the\nquestion is appealing, and I think it is philosophically interesting. But discussing it isnâ€™t necessary for addressing\nthe progress we have made and the opportunities and challenges that brings. Great physicists will tell you that there is\nalways another level of â€œwhyâ€ that will stump them. The challenge is to find questions that we can make meaningful\nprogress on now.\u003C/p>\n\u003Cp>We know, for a fact, that currently available language models can answer questions that make them a viable substitute\nfor humans for a wide range of tasks. So in that sense, we have access to some form of general intelligence. I do not\nbelieve it is a form equivalent to the intelligence humans possess, but thatâ€™s not important. \u003Cstrong>Defining the tool, and\nrelating it to humans, has no impact on its usefulness\u003C/strong>. As a society, we must accept that large swaths of human\nworkers are about to become obsolete.\u003C/p>\n\u003Ch3 id=\"progress-will-most-likely-be-faster-than-we-can-imagine\">Progress will most likely be faster than we can imagine\u003C/h3>\n\u003Cp>There is evidence that AI researchers use feedback loops based on LLVMs to accelerate progress further. The impact of\nthis is hard to predict. Assuming scaling laws keep holding and more funding is directed to training LLVMs, I think it\nis fair to assume there is a compounding acceleration of progress. That means \u003Cstrong>progress in AI is on an exponential\ntrajectory.\u003C/strong> Of course, it is possible we will find limitations that result in diminishing marginal returns. But from\nmy perspective, there is a higher expected reward from assuming it will continue accelerating.\u003C/p>\n\u003Cp>As with all new technology, descriptions of progress will be dismissed as hyperbolic. My view that we are at the\nbeginning of an exponential development might sound implausible or grandiose. I empathize with this view. There is good\nreason to be skeptical. Nevertheless, enough evidence exists to prepare for a world where rapid AI progress leads to\ntransformative AI systems.\u003C/p>\n\u003Cp>You could start to notice in the mid-2010s that LLMs improved. Open AI was founded on the premise that we might get on\nan exponential trajectory toward AGI. The seeds of progress are training data, computation, and improved algorithms. Of\ncourse, it was clear there were many considerable hurdles ahead. Multimodality, logical reasoning, transfer learning\nacross tasks, and long-term memory were all unsolved. But one by one LLVMs are overcoming these hurdles.\u003C/p>\n\u003Ch3 id=\"the-short-term-impact-of-increasingly-capable-ai-systems-is-underestimated\">The short-term impact of increasingly capable AI systems is underestimated\u003C/h3>\n\u003Cp>People tend to be bad at recognizing and acknowledging exponential growth in its early phases. Politics is, ironically,\nboth a slow and a short-term process. Most politicians are currently worried about the price of electricity, inflation,\nor the war in Ukraine. I get that. That said, we need to act with urgency to prepare for the violent disruption that AI\nwill bring to the labor market. Large groups of people will need to reskill quickly. History shows this has a mostly\nnegative impact on earnings. While Iâ€™m optimistic the long-term impact of AI will be positive, we should prepare for the\nshort-term disruption.\u003C/p>\n\u003Ch3 id=\"the-alignment-problem\">The Alignment Problem\u003C/h3>\n\u003Cp>I will quote from \u003Ca href=\"https://www.anthropic.com/index/core-views-on-ai-safety\">Anthropicâ€™s website\u003C/a>:\u003C/p>\n\u003Cblockquote>\n\u003Cp>\u003Cstrong>We do not know how to train AI systems to robustly behave well.\u003C/strong> So far, no one knows how to train very powerful AI\nsystems to be robustly helpful, honest, and harmless. Furthermore, rapid AI progress will be disruptive to society and\nmay trigger competitive races that could lead corporations or nations to deploy untrustworthy AI systems. The results of\nthis could be catastrophic, either because AI systems strategically pursue dangerous goals, or because these systems\nmake more innocent mistakes in high-stakes situations.\u003C/p>\n\u003C/blockquote>\n\u003Cp>I think aligning AI systems with human values, and human preferences will be the main activity for both companies and\ngovernments for the foreseeable future. There is a new programming paradigm emerging with the advent of LLVMs. Itâ€™s\nalready over ten years ago that we moved from programming with code to programming with examples. We are now in the\nmiddle of yet another transition: fine-tuning large models based on human feedback. I want to try and explain what I\nmean by that.\u003C/p>\n\u003Ch3 id=\"curating-the-essence-of-concepts-in-latent-spaces\">Curating â€œThe Essence of Conceptsâ€ in Latent Spaces\u003C/h3>\n\u003Cp>\u003Cstrong>My interpretation of LLVMs is that they learn â€œthe Essence of Concepts.â€\u003C/strong> Let me explain. Around 2010 it became clear\nthat with enough labeled data, you can learn almost any task. Construct your dataset, carefully assemble labels, specify\na loss function and neural network architecture, train your network, and deploy. This approach has been applied\nsuccessfully to many tasks for the past decade.\u003C/p>\n\u003Cp>\u003Cstrong>But supervised learning has severe limitations\u003C/strong> , the most notable of which is the shortage of labeled data. Even\nwith a great Data Engine, such as the one \u003Ca href=\"https://www.kognic.com\">Kognic\u003C/a> provides, there wonâ€™t be enough labels to\nlearn everything. Geoffrey Hinton is famous for saying:\u003C/p>\n\u003Cblockquote>\n\u003Cp>The brain has about 10^14 synapses and we only live for about 10^9 seconds. So we have a lot more parameters than\ndata. This motivates the idea that we must do a lot of unsupervised learning since the perceptual input, including\nproprioception, is the only place we can get 10^5 dimensions of constraints per second.\u003C/p>\n\u003C/blockquote>\n\u003Cp>Rather than relying on text explicitly labeled, GPT models learn latent representations by reading large quantities of\ntext. There is a form of supervision involved since humans had to write everything on the internet first, but it is\ndifferent from explicit labeling targeting a specific task.\u003C/p>\n\u003Cp>Understanding the idea of learning â€œthe Essence of Conceptsâ€ requires understanding the inner workings of transformers,\nattention, and latent spaces. But in short: when we expose LLVMs to large amounts of multi-modal data, a representation\nis formed to maximize the probability of predicting the next item in a sequence. This representation abstracts away the\nsuperficial properties of words, objects, and even sentences. Ultimately, \u003Cstrong>concepts become points in a high-dimensional\nspace.\u003C/strong>\u003C/p>\n\u003Cp>Models can decode from these points into whatever modality they can access and predict text or render\nimages. \u003Ca href=\"https://ai.googleblog.com/2016/11/zero-shot-translation-with-googles.html\">Zero-shot translation\u003C/a> is an example\nof this, where each language can be considered a modality. Concepts become points in a shared latent space from which\nyou can decode into any language part of the training process. Even when there is no direct mapping present in the\ntraining data.\u003C/p>\n\u003Cp>The surprising thing in recent years has been the extraordinary capacity demonstrated by GPT-style models to learn many\ndifferent concepts simultaneously. It is from this ability that their power comes. What seems like a magical ability to\nhandle prompts never seen in the training data is most likely because the essence of the concept can be there anyway; we\nmight just not realize it. Humans are bad at thinking about points in high-dimensional spaces, and we cannot\nencode/decode such concepts. So for us, a concept might be missing in the training data. But for the model, some\ncompletely different things in the training data might end up very close to your prompt in the learned latent space. And\nvoila, the model predicts tokens in a way that feels magical.\u003C/p>\n\u003Cp>\u003Cstrong>The consequence is that programming now becomes a matter of curating the concepts encoded in a latent space. We do not\nhave the tools for this as of today.\u003C/strong> For me, the alignment problem is equivalent to curating the concepts encoded in a\nlatent space. We want to shape concepts to align them with human values and human preferences. That way, model\npredictions will be acceptable to users.\u003C/p>\n\u003Ch3 id=\"learn-a-policy-from-human-feedback-rlhf-on-latent-spaces\">Learn a Policy from Human Feedback (RLHF) on Latent Spaces\u003C/h3>\n\u003Cp>So, how do we align model predictions with human values and preferences? Yann LeCun has been building on Geoffrey\nHintons observation about the brain, and in his 2016 NIPS talk, said that:\u003C/p>\n\u003Cblockquote>\n\u003Cp>â€œIf intelligence is a cake, the bulk of the cake is unsupervised learning, the icing on the cake is supervised\nlearning, and the cherry on the cake is reinforcement learning (RL).â€\u003C/p>\n\u003C/blockquote>\n\u003Cp>The battlefield for AI in the coming years, I think, can be found in the intersection between these two ideas: 1) Learn\na latent representation by observing a lot of sequences, and 2) Fine-tune model predictions based on learning a policy\nthrough reinforcement learning from human feedback (RLHF). \u003Cstrong>This paradigm of RLHF is quickly getting adopted by\ncutting-edge companies.\u003C/strong> Thereâ€™s a great outline of this approach \u003Ca href=\"https://huggingface.co/blog/rlhf\">over at ðŸ¤—\u003C/a>.\u003C/p>\n\u003Cp>\u003Cimg src=\"https://storage.googleapis.com/langkilde-se-images/e54677a4-aa07-46d4-916e-60a0f7a54356.jpeg\" alt=\"\">\u003C/p>\n\u003Cp>In the example from ðŸ¤—, humans provide feedback on specific outputs. You prompt the model and then ask a human to rank\ndifferent answers or suggest improved responses. That feedback is then used to fine-tune your language model. However,\nimplicit in the model is the latent space. This latent space encodes everything the model has seen so that the\nrepresentation maximizes your ability to predict items in sequences. We have known for a long time that such latent\nspaces preserve semantic relationships in various ways. Anthropic illustrates a 2D projection of a latent space this\nway:\u003C/p>\n\u003Cp>\u003Cimg src=\"https://storage.googleapis.com/langkilde-se-images/36dcca72-b6d7-4a76-837a-b523bd670102.jpeg\" alt=\"\">\u003C/p>\n\u003Cp>By asking humans for feedback, they ascribe human values to sequences that can be grouped in some high-dimensional\nspace. A notable detail is that humans are noisy when asked to assign scalar rewards to outputs directly. Instead, the\nbest way is to ask humans to rank items.\u003C/p>\n\u003Cp>I recently came across an excellent blogpost by Viet Le\ntitled â€œ\u003Ca href=\"https://vietle.substack.com/p/defensible-machine-learning\">Building a Defensible Machine Learning Company in the Age of Foundation Models\u003C/a>.â€\nHe describes what he thinks a defensible flywheel looks like:\u003C/p>\n\u003Cp>\u003Cimg src=\"https://storage.googleapis.com/langkilde-se-images/f0abc8be-4158-4c07-b479-cd32fcd27d3e.jpeg\" alt=\"\">\u003C/p>\n\u003Cp>\u003Cstrong>Combine these ideas, and you get a glimpse of the future.\u003C/strong> I expect we will see larger and larger foundation models\ntrained by large companies and institutions. These Foundation Models will learn from observing large quantities of\nempirical data. Companies will then create fine-tuned models based on some user interaction. Winners will be companies\nthat can attract the most users that, in turn, generate the best proprietary feedback for your specific application.\u003C/p>\n\u003Cp>To speed up the process, we can apply human feedback directly to the latent space. Rather than have humans look at\nthousands of examples, we assume that clusters will form in high-dimensional space.\u003C/p>\n\u003Cp>\u003Cimg src=\"https://storage.googleapis.com/langkilde-se-images/89e6fa94-34dc-47af-a564-af89f77e29f3.jpeg\" alt=\"\">\u003C/p>\n\u003Ch3 id=\"what-can-the-rlhf-workflow-be-applied-to\">What can the RLHF workflow be applied to?\u003C/h3>\n\u003Cp>Anything. Assuming you have enough recorded data in sequences and a ton of computing. Most existing limitations will\nmost likely be overcome with time and money. I expect this is the most viable way to learn how to drive, walk, operate\nmachinery, communicate, and do all the other things humans do. It seems reasonably likely that multi-modal transformers\nwill be enough for many, many applications.\u003C/p>\n\u003Ch3 id=\"does-this-mean-agi-is-solved\">Does this mean AGI is solved?\u003C/h3>\n\u003Cp>No. Not even close. While LLVMs are an amazing step towards AGI, there are many, many things that such models cannot\nsolve. I think we will see many novel model architectures in the years ahead and that GPT-styled models are a step on\nthe ladder as opposed to the ultimate solution. But again, that doesnâ€™t mean we shouldnâ€™t embrace them and push them to\ntheir limit. It just means thereâ€™s a lot more to explore, discover and create.\u003C/p>\n\u003Ch3 id=\"whats-next\">Whatâ€™s next?\u003C/h3>\n\u003Cp>Well, a lot, probably. But here are some obvious things:\u003C/p>\n\u003Cp>\u003Cstrong>All digital products will have embedded intelligence\u003C/strong> through integration with some large language model. We are in\nthe middle of the fastest new feature rollout bonanza Iâ€™ve ever seen. Since the integration is simple (just an API call\nto your LLM of choice), anyone can add intelligence to their product in hours.\u003C/p>\n\u003Cp>\u003Cstrong>Great products will require great RLHF solutions.\u003C/strong> The user experience will need to be tuned. Even with perfect\nautomation, humans have preferences and values that we constantly negotiate socially. Updating behaviors will require\nefficient ways to fine-tune the concepts encoded in the latent space of your Foundation Model.\u003C/p>\n\u003Cp>\u003Cstrong>A growing constraint will become access to computing resources\u003C/strong>. These models are still very, very expensive to\ntrain. This has been true for a while for the forerunners, but now everyone will start feeling the pain. Expect to spend\nmillions of dollars on GPUs.\u003C/p>\n\u003Cp>\u003Cstrong>Mixed modalities will grow fast.\u003C/strong> Query and analyze text, video, and sound interchangeably. Store all your company\nmeetings and literally \u003Cem>talk to them\u003C/em>. This will be a game-changer for business productivity.\u003C/p>\n\u003Cp>\u003Cstrong>Company knowledge bases will be changed forever.\u003C/strong> Employees will start talking to their companies. Iâ€™m assuming they\nalready are, but it will expand rapidly. No more hunting around in some shitty intranet. We will query, using natural\nlanguage, all documents inside our companies.\u003C/p>\n\u003Cp>As a closing reminder: The future is already here. It is just unevenly distributed. \u003Cstrong>What a time to be alive.\u003C/strong>\u003C/p>",{"headings":751,"localImagePaths":782,"remoteImagePaths":783,"frontmatter":784,"imagePaths":785},[752,755,758,761,764,767,770,773,776,779],{"depth":24,"slug":753,"text":754},"drastically-updated-probability-of-near-term-probability-of-agi","Drastically updated probability of near-term probability of AGI",{"depth":24,"slug":756,"text":757},"defining-artificial-general-intelligence-agi-is-a-distraction","Defining Artificial General Intelligence (AGI) is a distraction",{"depth":24,"slug":759,"text":760},"progress-will-most-likely-be-faster-than-we-can-imagine","Progress will most likely be faster than we can imagine",{"depth":24,"slug":762,"text":763},"the-short-term-impact-of-increasingly-capable-ai-systems-is-underestimated","The short-term impact of increasingly capable AI systems is underestimated",{"depth":24,"slug":765,"text":766},"the-alignment-problem","The Alignment Problem",{"depth":24,"slug":768,"text":769},"curating-the-essence-of-concepts-in-latent-spaces","Curating â€œThe Essence of Conceptsâ€ in Latent Spaces",{"depth":24,"slug":771,"text":772},"learn-a-policy-from-human-feedback-rlhf-on-latent-spaces","Learn a Policy from Human Feedback (RLHF) on Latent Spaces",{"depth":24,"slug":774,"text":775},"what-can-the-rlhf-workflow-be-applied-to","What can the RLHF workflow be applied to?",{"depth":24,"slug":777,"text":778},"does-this-mean-agi-is-solved","Does this mean AGI is solved?",{"depth":24,"slug":780,"text":781},"whats-next","Whatâ€™s next?",[],[],{"pubDate":744,"title":743},[],"the-probability-of-near-term-agi-like-systems.md","the-importance-of-annotated-data-in-nlp",{"id":787,"data":789,"body":792,"filePath":793,"digest":794,"rendered":795,"legacyId":818},{"title":790,"pubDate":791},"The Importance of Annotated Data in NLP","2016-09-10","Iâ€™ve worked on Natural Language Processing (NLP) applications as an engineer for a few years now. Itâ€™s the most fun Iâ€™ve\never had, but there sure are challenges. Most importantly people underestimate the difficulties involved in getting\nwell-annotated data.\n\nHuman communication, and therefore natural language, is subjective and ambiguous. To succeed in building NLP\napplications you need to deal with this by making it very clear what your goal is, and what data you need to get there.\nSo let us forget about the algorithms for a moment. Here are some of the key data challenges Iâ€™ve come across in trying\nto execute successful NLP projects:\n\n### What do you want from me?\n\nLets say you want me to sort text into two classes. The first thing I need then is **a good annotation guideline**\ndescribing what is required to qualify for each class. \"_I know it when I see it_\" is unacceptable. The guideline needs\nto give examples with corresponding explanations.\n\nOnce you have a guideline written up you need to put it to the test. A good first step is to test it on colleagues\noutside your team or key stakeholders. Give a few people a set of texts, the guideline and ask them to annotate the text\nbased on the guideline. Did they agree on how to annotate the text? If yes, great, then the guideline is probably\nuseful. If no, refine the guideline. And donâ€™t give them easy examples when you test this, give them the real, hard\nones.\n\nWhat you want is a **high**  **inter-annotator agreement**. Basically this is a measure of agreement on what the\nclassification task actually means. Unless you have this you might as well not try at all.\n\n### How do you measure success?\n\nOnce you have agreement on what your task means, you need to get a  **fair test and development set**. These can be\nprocured using the annotation guideline. Make sure you have â€œproductionâ€ data so you actually measure what will happen\nwhen your code hits reality.\n\nThis is also a good time to establish **reasonable performance expectations on the test set  **with your project\nmanager. For example, ask yourself â€œHow well does a human perform?â€. Have someone qualitatively inspect the test set and\nsee that it covers all the critical cases that the system will face in production. This can be time-consuming as NLP\ntasks often are full of strange edge cases. Decide which you need to cover, then let go of the rest. You will never get\nto 100% anyway, natural language is too messy. Make sure your work is evaluated against the test set by management. Itâ€™s\neasy to get feature creep where things outside the specification is tested.\n\n### How much annotated data do you need?\n\nExpect to get the question â€œHow much will it cost to annotate data for this task?â€ This is the same as asking â€œHow many\nsentences do we need to annotate?â€ Itâ€™s very important to understand that the raw number of sentences is irrelevant, it\nis the information in those sentences that matters.\n\nSo really, you **need** to figure out **how to get training data covering all the important cases**  that your algorithm\nwill need to recognize. Depending on how well the algorithm is able to generalize this could be a lot of cases. Then you\ncan do your cost estimate.\n\nUnder the umbrella of active learning, you can find a lot of useful tools for efficiently selecting which sentences you\nwant to label in order to get the best possible learning curve. Select sentences that are hard for the algorithm first,\nand then stop sampling those sentences once it understands them.\n\n### How to get the actual annotations?\n\nIdeally, we now know what we want, how to test if we have it and which sentences we need to annotate to get there. Next\ncomes the actual annotation work.\n\nThere are many platforms out there such\nas [Amazon mTurks](https://www.mturk.com/mturk/welcome), [Crowdflower](http://crowdflower.com/) and others.\n\n**_EDIT:_**_Since writing this post, Iâ€™ve founded_[ _Kognic_](https://www.kognic.com/) _, a company dedicated to\nproducing consistently annotated data. Get in touch if you want to know more._\n\nMaybe one of those works for you. Maybe you need very skilled annotators that require extensive training to understand\nthe guideline. Thereâ€™s no easy answer here. Your task might require special tools such as a way to give certain labels\nto substrings of text. You need to understand that this part is more complicated than you might think. You need to\nfigure out **exactly how workers will produce your annotations**  early on in your project, or you might hit a very hard\nwall.\n\n### Now the coding begins\n\nIf youâ€™re lucky your project made it all the way here and youâ€™ve got your training data. Most people think of this part\nas the â€œactualâ€ machine learning work, i.e. the part where you get to write algorithms and chase down those last few\nperformance points. In order to do well with NLP and machine learning, you need to understand that this is far from the\nonly part. You, or someone in your team, will have to deal with all the challenges leading here as well, or you will\nfail.\n\n**In conclusion, in order to overcome data challenges when executing NLP projects you need to:**\n\n1. Write **a good annotation guideline.**\n\n2. Make sure you have a **high**  **inter-annotator agreement.**\n\n3. Put together a **fair test and development set.**\n\n4. Establish **reasonable performance expectations on the test set.**\n\n5. Figure out **how to get training data covering all the important cases.**\n\n6. Figure out **exactly how workers will produce your annotations.**\n\nAll of the above is part of working with NLP. If you donâ€™t mind these steps, then youâ€™re ready to get to work. Itâ€™s fun,\nI promise!","src/content/blog/the-importance-of-annotated-data-in-nlp.md","37f8115ce6cca47b",{"html":796,"metadata":797},"\u003Cp>Iâ€™ve worked on Natural Language Processing (NLP) applications as an engineer for a few years now. Itâ€™s the most fun Iâ€™ve\never had, but there sure are challenges. Most importantly people underestimate the difficulties involved in getting\nwell-annotated data.\u003C/p>\n\u003Cp>Human communication, and therefore natural language, is subjective and ambiguous. To succeed in building NLP\napplications you need to deal with this by making it very clear what your goal is, and what data you need to get there.\nSo let us forget about the algorithms for a moment. Here are some of the key data challenges Iâ€™ve come across in trying\nto execute successful NLP projects:\u003C/p>\n\u003Ch3 id=\"what-do-you-want-from-me\">What do you want from me?\u003C/h3>\n\u003Cp>Lets say you want me to sort text into two classes. The first thing I need then is \u003Cstrong>a good annotation guideline\u003C/strong>\ndescribing what is required to qualify for each class. â€œ\u003Cem>I know it when I see it\u003C/em>â€ is unacceptable. The guideline needs\nto give examples with corresponding explanations.\u003C/p>\n\u003Cp>Once you have a guideline written up you need to put it to the test. A good first step is to test it on colleagues\noutside your team or key stakeholders. Give a few people a set of texts, the guideline and ask them to annotate the text\nbased on the guideline. Did they agree on how to annotate the text? If yes, great, then the guideline is probably\nuseful. If no, refine the guideline. And donâ€™t give them easy examples when you test this, give them the real, hard\nones.\u003C/p>\n\u003Cp>What you want is a \u003Cstrong>high\u003C/strong>  \u003Cstrong>inter-annotator agreement\u003C/strong>. Basically this is a measure of agreement on what the\nclassification task actually means. Unless you have this you might as well not try at all.\u003C/p>\n\u003Ch3 id=\"how-do-you-measure-success\">How do you measure success?\u003C/h3>\n\u003Cp>Once you have agreement on what your task means, you need to get a  \u003Cstrong>fair test and development set\u003C/strong>. These can be\nprocured using the annotation guideline. Make sure you have â€œproductionâ€ data so you actually measure what will happen\nwhen your code hits reality.\u003C/p>\n\u003Cp>This is also a good time to establish **reasonable performance expectations on the test set  **with your project\nmanager. For example, ask yourself â€œHow well does a human perform?â€. Have someone qualitatively inspect the test set and\nsee that it covers all the critical cases that the system will face in production. This can be time-consuming as NLP\ntasks often are full of strange edge cases. Decide which you need to cover, then let go of the rest. You will never get\nto 100% anyway, natural language is too messy. Make sure your work is evaluated against the test set by management. Itâ€™s\neasy to get feature creep where things outside the specification is tested.\u003C/p>\n\u003Ch3 id=\"how-much-annotated-data-do-you-need\">How much annotated data do you need?\u003C/h3>\n\u003Cp>Expect to get the question â€œHow much will it cost to annotate data for this task?â€ This is the same as asking â€œHow many\nsentences do we need to annotate?â€ Itâ€™s very important to understand that the raw number of sentences is irrelevant, it\nis the information in those sentences that matters.\u003C/p>\n\u003Cp>So really, you \u003Cstrong>need\u003C/strong> to figure out \u003Cstrong>how to get training data covering all the important cases\u003C/strong>  that your algorithm\nwill need to recognize. Depending on how well the algorithm is able to generalize this could be a lot of cases. Then you\ncan do your cost estimate.\u003C/p>\n\u003Cp>Under the umbrella of active learning, you can find a lot of useful tools for efficiently selecting which sentences you\nwant to label in order to get the best possible learning curve. Select sentences that are hard for the algorithm first,\nand then stop sampling those sentences once it understands them.\u003C/p>\n\u003Ch3 id=\"how-to-get-the-actual-annotations\">How to get the actual annotations?\u003C/h3>\n\u003Cp>Ideally, we now know what we want, how to test if we have it and which sentences we need to annotate to get there. Next\ncomes the actual annotation work.\u003C/p>\n\u003Cp>There are many platforms out there such\nas \u003Ca href=\"https://www.mturk.com/mturk/welcome\">Amazon mTurks\u003C/a>, \u003Ca href=\"http://crowdflower.com/\">Crowdflower\u003C/a> and others.\u003C/p>\n\u003Cp>\u003Cstrong>\u003Cem>EDIT:\u003C/em>\u003C/strong>\u003Cem>Since writing this post, Iâ€™ve founded\u003C/em>\u003Ca href=\"https://www.kognic.com/\"> \u003Cem>Kognic\u003C/em>\u003C/a> \u003Cem>, a company dedicated to\nproducing consistently annotated data. Get in touch if you want to know more.\u003C/em>\u003C/p>\n\u003Cp>Maybe one of those works for you. Maybe you need very skilled annotators that require extensive training to understand\nthe guideline. Thereâ€™s no easy answer here. Your task might require special tools such as a way to give certain labels\nto substrings of text. You need to understand that this part is more complicated than you might think. You need to\nfigure out \u003Cstrong>exactly how workers will produce your annotations\u003C/strong>  early on in your project, or you might hit a very hard\nwall.\u003C/p>\n\u003Ch3 id=\"now-the-coding-begins\">Now the coding begins\u003C/h3>\n\u003Cp>If youâ€™re lucky your project made it all the way here and youâ€™ve got your training data. Most people think of this part\nas the â€œactualâ€ machine learning work, i.e. the part where you get to write algorithms and chase down those last few\nperformance points. In order to do well with NLP and machine learning, you need to understand that this is far from the\nonly part. You, or someone in your team, will have to deal with all the challenges leading here as well, or you will\nfail.\u003C/p>\n\u003Cp>\u003Cstrong>In conclusion, in order to overcome data challenges when executing NLP projects you need to:\u003C/strong>\u003C/p>\n\u003Col>\n\u003Cli>\n\u003Cp>Write \u003Cstrong>a good annotation guideline.\u003C/strong>\u003C/p>\n\u003C/li>\n\u003Cli>\n\u003Cp>Make sure you have a \u003Cstrong>high\u003C/strong>  \u003Cstrong>inter-annotator agreement.\u003C/strong>\u003C/p>\n\u003C/li>\n\u003Cli>\n\u003Cp>Put together a \u003Cstrong>fair test and development set.\u003C/strong>\u003C/p>\n\u003C/li>\n\u003Cli>\n\u003Cp>Establish \u003Cstrong>reasonable performance expectations on the test set.\u003C/strong>\u003C/p>\n\u003C/li>\n\u003Cli>\n\u003Cp>Figure out \u003Cstrong>how to get training data covering all the important cases.\u003C/strong>\u003C/p>\n\u003C/li>\n\u003Cli>\n\u003Cp>Figure out \u003Cstrong>exactly how workers will produce your annotations.\u003C/strong>\u003C/p>\n\u003C/li>\n\u003C/ol>\n\u003Cp>All of the above is part of working with NLP. If you donâ€™t mind these steps, then youâ€™re ready to get to work. Itâ€™s fun,\nI promise!\u003C/p>",{"headings":798,"localImagePaths":814,"remoteImagePaths":815,"frontmatter":816,"imagePaths":817},[799,802,805,808,811],{"depth":24,"slug":800,"text":801},"what-do-you-want-from-me","What do you want from me?",{"depth":24,"slug":803,"text":804},"how-do-you-measure-success","How do you measure success?",{"depth":24,"slug":806,"text":807},"how-much-annotated-data-do-you-need","How much annotated data do you need?",{"depth":24,"slug":809,"text":810},"how-to-get-the-actual-annotations","How to get the actual annotations?",{"depth":24,"slug":812,"text":813},"now-the-coding-begins","Now the coding begins",[],[],{"pubDate":791,"title":790},[],"the-importance-of-annotated-data-in-nlp.md","the-state-of-machine-learning-in-2022-next-steps",{"id":819,"data":821,"body":824,"filePath":825,"digest":826,"rendered":827,"legacyId":863},{"title":822,"pubDate":823},"The State of Machine Learning in 2022 - Next steps?","2022-05-12","I recently summarized\nthe [state of machine learning](https://langkilde.se/post/2022-04-18-the-state-of-machine-learning-2022). The post\nserved\nas a way to keep up with what _has happened_ until now. Predictably, it triggered a lot of questions about what _will\nhappen._ Rather than\nmake [bold predictions](https://www.businessinsider.com/elon-musk-history-of-full-self-driving-promise-2022-1?IR=T&r=US#:~:text=In%202015%2C%20billionaire%20Tesla%20CEO,still%20making%20the%20same%20promise.)\nof future breakthroughs, it seems better to ask â€œwhat is a suitable framework based on which we can interpret new\nresults and guess possible future capabilities?â€.\n\nIn general, a challenge with keeping up with machine learning research is that a list of â€œthe latest cool stuffâ€ gets\nold very quickly. At least if results are considered in too much detail. There are new results published all the time,\nbut in reality, â€œbreakthroughsâ€ are rather few. Most papers are â€œimproved state-of-the-art by 1%â€-noise. I do not think\nyou can predict the future of research since a lot of innovation is accidental and unexpected. But we can do a lot\nbetter than random guessing. It is necessary to try predicting the future since there is a lot at stake for society,\nbusiness, and humans. So, here are some thoughts on how to reason about the future of machine learning:\n\nLetâ€™s use two recent papers as examples. They were both published very recently (so recent in fact, that I did not cover\nthem in my previous post). The first one, **PaLM** , was published in early April\n2022 ([blog](https://ai.googleblog.com/2022/04/pathways-language-model-palm-scaling-to.html), [paper](https://arxiv.org/abs/2204.02311))\nand the second one, **Flamingo** , was published in late April\n2022 ([blog](https://www.deepmind.com/blog/tackling-multiple-tasks-with-a-single-visual-language-model), [paper](https://arxiv.org/abs/2204.14198)).\nBoth papers contain mind-blowing demo results (see examples below).\n\n![](https://storage.googleapis.com/langkilde-se-images/3b6f9301-b2b4-4431-abfb-12fbc34bd14b.jpeg)\n**Caption:** Flamingos having conversations with humans.\n\n![](https://storage.googleapis.com/langkilde-se-images/a61fb14d-bfd1-4e34-8269-b49009110502.jpeg)\n**Caption:** PaLM explaining jokes.\n\nSo, how do we make sense of these papers? And what do they mean for the next wave of machine learning applications?\n\nAll research builds on previous results, so we should ask ourselves: what is _actually_ new about these papers? It is\ntempting to focus on the amazing demo output, but a more interesting question is â€œwhy does it work better than before?â€.\nLater, we will of course also focus on when it does not work.\n\nLetâ€™s start with what is _not_ _new_. The core concepts of **numerical optimization** and **deep neural networks** have\nremained largely unchanged for a long time. Neither PaLM nor Flamingo changes anything about these core concepts. Of\ncourse, there are improvements and tricks used to make them perform better, but the fundamental idea is more or less the\nsame. It also turns out both papers make use of the same kind of **embeddings** that weâ€™ve seen for the last 12-13 years\nnow, i.e. models representing information as dense vectors. Finally, both models leverage **attention and transformers**\nto learn improved embeddings. We covered these concepts in\nthe [previous blog post](https://langkilde.se/post/2022-04-18-the-state-of-machine-learning-2022).\n\n### Larger Models are (still) Better\n\nIt turns out that the progress shown in recent papers is mostly about **size** , both in model and data**.** To quote\nthe authors of the PaLM paper:\n\n> Since GPT-3, a number of other large autoregressive language models have been developed which have continued to push\n> the state of the art forward. [â€¦] The improvements in these models have primarily come from one or more of the\n> following\n> approaches: (1) scaling the size of the models in both depth and width; (2) increasing the number of tokens that the\n> model was trained on; (3) training on cleaner datasets from more diverse sources; and (4) increasing model capacity\n> without increasing the computational cost through sparsely activated modules. [â€¦] **This critically demonstrates\nscaling\n> improvements from large LMs have neither plateaued nor reached their saturation point.**\n\nThe fact that transformers can be parallelized, and the emergence of new, innovative ways to train models such\nas [Pathways](https://blog.google/technology/ai/introducing-pathways-next-generation-ai-architecture/) make it possible\nto train larger and larger models. The unexpected result is that **we should expect models to keep improving as they\nkeep growing.** People have been suggesting this for years, but Iâ€™ve always believed more sophisticated representation\nmethods would be required. I mean, intuitively more context when learning should make a model more capable, but the fact\nthat the latent space can organize the information so successfully is surprising. At least to me. It could have very\nwell been that information got â€œjumbledâ€ as the model grows, but it appears not to. It also appears as if concepts can\nbe combined and reused across domains in a surprisingly robust way.\n\n### Chain-of-Thought\n\nBesides size, a new thing from my perspective is that PaLM demonstrates that when model scaling is combined with *\n*chain-of-thought prompting** the model can solve problems that require multi-step mathematical or commonsense reasoning\nto produce the correct answer. I hadnâ€™t read much about this concept before, so _for me,_ this was new. It looks like\nthe best paper to read on this\nis â€œ[Chain of Thought Prompting Elicits Reasoning in Large Language Models](https://arxiv.org/pdf/2201.11903.pdf)â€. The\npurpose is to handle so-called â€œ[system-2](https://en.wikipedia.org/wiki/Thinking,_Fast_and_Slow)â€ tasks such as\nlogical, mathematical, and common sense reasoning. Large language models exhibit flat scaling curves for such tasks,\ni.e. they will not improve with the size of the model. To handle this, the authors propose a way for these models to\ndecompose multi-step problems into intermediate steps. The idea is basically to let the model generate a coherent set of\nshort sentences that lead to the answer to a reasoning problem.\n\nTurning to Flamingo, the most interesting aspect of this model is that it is:\n\n> it is a visually-conditioned autoregressive text generation model able to ingest a sequence of text tokens interleaved\n> with images and/or videos, and produce text as output.\n\nBasically, it can process images and text interchangeably in a sequence and predict a suitable next sequence of text\ntokens. When considered together with DALLE2 I assume itâ€™s just a matter of time before it can also respond with an\nimage every now and then. Imagine the human operator inputting a sequence of text and images, and then asking â€œShow me\nwhat you are thinkingâ€, to which the model would output an image capturing its â€œstate of mindâ€. Such an exchange should\nbe possible.\n\n### Diffusion Models\n\nIt is clear that GANs have a powerful new contender: [diffusion models](https://arxiv.org/pdf/2006.11239.pdf). To\nquote [Lilian Weng](https://lilianweng.github.io/posts/2021-07-11-diffusion-models/):\n\n> Diffusion models are inspired by non-equilibrium thermodynamics. They define a Markov chain of diffusion steps to\n> slowly add random noise to data and then learn to reverse the diffusion process to construct desired data samples from\n> the noise. Unlike VAE or flow models, diffusion models are learned with a fixed procedure and the latent variable has\n> high dimensionality (same as the original data).\n\nDiffusion models are used in DALLE2 to generate data by reversing a gradual noising process. So basically they â€œremove\nnoiseâ€. Noise in this context is a rather complicated concept. Itâ€™s not a lack of sharpness or anything, itâ€™s more\nradical than that. Itâ€™s more like taking a crude vector and finding various suitable images based on it.\n\n![](https://storage.googleapis.com/langkilde-se-images/3da651f8-9397-4252-8693-d968e537f2fa.jpeg)\n**Caption:** Description from original paper.\n\nIf you want to read more about it, I found this post to be very well\nwritten: [How DALL-E2 Actually Works](https://www.assemblyai.com/blog/how-dall-e-2-actually-works/). Below is an example\nfrom the DALLE2 paper showing the variations created by the diffusion model on the same core vector.\n\n![](https://storage.googleapis.com/langkilde-se-images/d389ad7b-016f-4038-8ff9-42c49c5b7f7c.jpeg)\n\nA concept that is not covered by the papers Iâ€™ve focused on, but that is offering new and exciting technology is Graph\nNeural Networks (GNNs). They have been on the fringe of research until recently, but are not exploding in interest. The\nidea is that you can create mesh-based simulations and predict how meshes change over time depending on external\nfactors. That can be used for things like ETA in traffic. They are still not very resource-efficient, but new methods\nlike [RevGNNs](https://arxiv.org/pdf/2106.07476.pdf) appear to lower the cost dramatically. These models appear to be\nuseful for long-time planning in reinforcement learning. An example is this\npaper: â€œ[World Model as a Graph: Learning Latent Landmarks for Planning](https://arxiv.org/pdf/2011.12491.pdf)â€.\n\n![](https://storage.googleapis.com/langkilde-se-images/3f3f940b-fddb-4492-875d-8b0116297084.jpeg)\n\nAs impressive as the demos are, there are still limitations to these models. Knowing their limitations, and how likely\nit is that we can overcome those limitations, will be important to predict what is possible in the future.\n\n### The need for webscale human-curated knowledge\n\nThese models still depend on **annotated data**. You might protest, and the authors of these papers like to highlight\nthat they avoid the need for large amounts of annotated data. At the same time, they clearly rely on â€œwebscale\ndatasetsâ€. It turns out the internet is made by humans. All the text written, and the image captions created, are\nwritten by humans. So in fact, the concepts manifested in the modelâ€™s latent space, need to first be described by humans\nin text and associated with images. And as a result, these models will also learn whatever undesired concepts and biases\nare present online. How to handle that, and mitigate that, will be a big part of making these models aligned with our\ninterests.\n\nWhat these papers show is that _if you have webscale amounts of human-curated knowledge_ a lot of tasks can be solved\nusing the same foundational model. So in that sense, _you do not need task-specific annotated data_ assuming the task is\na subset of what is described on the internet. Which tasks are implicitly described online, and which are not, is not\nclear to me at this point.\n\n### Fixed Amount of Thinking\n\nThese models all have a limited amount of [FLOPS](https://en.wikipedia.org/wiki/FLOPS) to spend, i.e. they are not\nâ€œcontinuously activeâ€. This limits what tasks can be solved. Input is fed through the network and output is generated.\nOnce that is done, nothing else can happen. Iâ€™m not actually sure how big this limitation is scientifically, or if itâ€™s\nmore an issue of cost/energy. Maybe the government or military can keep one of these models spinning continuously. Just\nhook it up to a nuclear reactor or something? Humans can choose to think more about something if it is complicated.\nThese models cannot.\n\n### Models are still Great at Bullshitting\n\nModels are still great at bullshitting when they â€œdo not knowâ€ the answer. I get the impression they are â€œbiased for\nactionâ€ in the sense that most versions of these systems prefer some output over â€œI do not knowâ€. In fact, it seems\nmodels are â€œextremely sureâ€ all the time, even when the output is more or less ungrounded. Paper authors describe this\nas â€œhallucinationsâ€ which might be a case of anthropomorphizing. It could also be that there are sufficiently similar\nconcepts in the data that the model picks a prediction that humans feel is nonsense, but that is actually statistically\naccurate. Which is correct, that which a human finds intuitive, or that which is most statistically likely?\n\n![](https://storage.googleapis.com/langkilde-se-images/8d100b39-b1d8-41f8-b7cb-7e266818795d.jpeg)\n**Caption:** From the Flamingo paper.\n\nOf course, the results you see in the papers are impressive, but there are also a lot of really strange results popping\nup. Iâ€™m less worried about this because if these models do in fact keep getting better and better with size, the\nfrequency of obvious errors will probably go down. But either way, estimating performance based on examples in papers is\nhard. Sure, the benchmarks are there to make sure performance evaluation is unbiased, but when you actually consider the\nnumbers they show, there will be a lot of strange results if you interacted with a model. I also think humans tend to\nwrite leading questions. Take the following example:\n\n![](https://storage.googleapis.com/langkilde-se-images/de13e9d2-5035-4274-8418-c839e7386396.jpeg)\n**Caption:** Example of Flamingo interacting with a human. Are the questions leading it to the right response?\n\nRecent models are still completely virtual. I recently learned about\nthe [Moravecâ€™s paradox](https://en.wikipedia.org/wiki/Moravec%27s_paradox) which hypothesizes that:\n\n> [â€¦] contrary to traditional assumptions, reasoning requires very little computation, but sensorimotor and perception\n> skills require enormous computational resources [â€¦] In general, we're least aware of what our minds do best and we're\n> more aware of simple processes that don't work well than of complex ones that work flawlessly [â€¦] it is comparatively\n> easy to make computers exhibit adult level performance on intelligence tests or playing checkers, and difficult or\n> impossible to give them the skills of a one-year-old when it comes to perception and mobility.\n\nThis feels right to me, but I obviously donâ€™t know. Maybe Iâ€™m just giving myself a false sense of safety. Maybe we\nshould not feel too scared about these algorithms until weâ€™ve actually made a lot more progress on physical robotics.\nMaybe reasoning isnâ€™t actually that hard?!\n\n# What will happen next?\n\nIt might seem like a philosophical question: â€œwhat will the future of machine learning look like?â€. Iâ€™ve long been a\nskeptic. For years Iâ€™ve been\nsaying â€œ[actually, computers are pretty dumb](https://open.spotify.com/episode/61HsG2Xl9zorDyrmEsR7FH)â€. Recently, Iâ€™ve\nstarted changing my mind. The emergence of massive latent spaces and the fact that human knowledge can apparently be\nrepresented in such spaces, makes me rethink things. In my case, I own and run a company that is tightly connected to\nthe future of machine learning, so it is my job to keep track of this. But I think it also matters as a human. So, what\ncan we expect?\n\n**More Modalities are Merged.** The obvious, short-term next step is to combine text, images, and sound. Iâ€™m sure\nthere are already really promising\nresults brewing inside Google and other companies. We will be talking to these models in natural language and getting\naudible responses very soon. Alexa, Siri, and Hey Google are about to get a massive upgrade. With DALLE2 it feels likely\nwe will also see interactive visuals that go with these audio interfaces before long. I think learning human emotion and\nfacial expressions is probably possible if you understand language and images, and have access to the entire internet.\n\n**The Scaling Hypothesis Keeps Holding.** Maybe we are all just brute-forcing life? I highly encourage you to read\nGwerns excellent post\non â€œ[The Scaling Hypothesis](https://www.gwern.net/Scaling-hypothesis)â€. To\nquote [Geoff Hinton](https://nitter.hu/geoffreyhinton/status/1270814602931187715):\n\n> Extrapolating the spectacular performance of GPT3 into the future suggests that the answer to life, the universe and\n> everything is just 4.398 trillion parameters.\n\nThere is no evidence today that very large models will suffer diminishing returns in their ability to learn. If that\nholds over time, these models should approach human-equal performance by the time their parameter space matches our\nbrain. There might be as many as 1 trillion synapses in the brain, i.e. neurons connected to each other and passing\nsignals to each other. The largest language models are approaching 1 trillion parameters. Together with a continuously\ngrowing size of encoded human knowledge, it is now possible that these models will match us in just a few years.\n\nThat does not mean we will have Terminator-style robots in a few years, it means we will have virtual entities that we\ncan talk to that are indistinguishable from humans. Maybe. On the other hand, we might find that â€œOh fuck, there was a\nroadblock here that we didnâ€™t expectâ€ and suddenly improvements are in fact diminishing.\n\n**A lot of new companies are emerging.** The â€œAttention is All You Needâ€ paper lead to the founding of a bunch\nof [new start-ups](https://twitter.com/nathanbenaich/status/1524029269617295361/photo/1). Just the authors alone have\nstarted a bunch, and others have followed in nearby domains. Here are some of my favorites.\n\n* **Adept.** â€œbuild[ing] general intelligence that enables humans and computers to work together creatively to solve\n  problems.â€ ([TechCrunch](https://techcrunch.com/2022/04/26/2304039/))\n\n* **AI21 Labs.** â€œa natural language interface on your company\n  dataâ€. ([website](https://www.ai21.com/blog/jurassic-x-crossing-the-neuro-symbolic-chasm-with-the-mrkl-system))\n\n* **Aleph Alpha.** â€œEuropes OpenAIâ€œ ([website](https://www.aleph-alpha.com))\n\n* **Anthropic**. â€œan AI safety and research company, has raised $580 million in a Series\n  B.â€ ([website](https://www.anthropic.com/news/announcement))\n\n* **Character.ai.** â€œcreating revolutionary open-ended conversational applications through breakthrough\n  research.â€ ([website](https://www.character.ai))\n\n* **Co:here. â€œ** making NLP part of every developer's\n  toolkitâ€****([TechCrunch](https://techcrunch.com/2021/11/17/google-cloud-teams-up-with-nlp-startup-cohere-on-multi-year-partnership/), [website](https://cohere.ai))\n\n* **Inceptive. â€œ** enabling the design of this next generation of RNA molecules through a singular combination of highly\n  scalable experiments and deep learning.â€ ([website](https://inceptive.life))\n\n* **Primer.** â€œlets organizations quickly explore and utilize the worldâ€™s exponentially growing sources of text-based\n  informationâ€ ([website](https://primer.ai))\n\n![](https://storage.googleapis.com/langkilde-se-images/bf57eb94-ae50-4a2b-924d-eee87f919488.jpeg)\n\nPredictably, most of the companies are [based in the US](https://www.stateof.ai):\n\n![](https://storage.googleapis.com/langkilde-se-images/b13d2460-f4d2-4d18-bf30-a3f29412fc95.jpeg)\n\n### Access to Quality Knowledge Becomes Limitation\n\nI think machine learning systems are already suffering from the same problems humans do: a lot of them are garbage. I\nmean, being a human does not guarantee you are a good, productive member of society. Becoming a great person requires\ncareful â€œtuningâ€ through education, parenting, selective reading, coaching, and mentoring. If we just consume everything\naround us all the time and give in to all our urges, we become awful people.\n\nI think we will find that as more capable ML systems emerge, we will lose some of the normal advantages of computers:\npreciseness and predictability. I think thatâ€™s a passing problem since once youâ€™ve perfected the knowledge base for one\nof these entities it could theoretically live forever, and keep improving.\n\nI think we can spend eternity curating a knowledge base and debating what is right. I mean, thatâ€™s how we spend most of\nour time anyway right? As soon as you have enough food and shelter, we climb the Maslow stairs and spend our time\npondering the meaning of life. An algorithm could do that forever without any really progress. Sure, it might pick\nan [optimization problem to focus on](https://www.lesswrong.com/tag/paperclip-maximizer), and that might be bad. But\nitâ€™s also possible it will [just make and watch soap operas](https://en.wikipedia.org/wiki/The_Murderbot_Diaries) all\nday. Who knows?\n\n### Reading Recommendations\n\n**The State of AI.** During my research on this, Iâ€™ve spent a lot of time reading the excellent stuff that Nathan\nBenaich is publishing ([twitter](https://twitter.com/nathanbenaich), [website](https://www.stateof.ai)).\n\n**Gwern.** There are so many good posts on the site:\n\n* [The Scaling Hypothesis](https://www.gwern.net/Scaling-hypothesis)\n\n* [Machine Learning Scaling](https://www.gwern.net/notes/Scaling)\n\nMy last link will be from that site, and it is probably a good place to go next. As Gwern puts it:\n\n> It might help to imagine a hard takeoff scenario using solely known sorts of NN & â scaling effectsâ€¦ [This] is a story\n> which may help stretch your imagination and defamiliarize the 2022 state of machine learning.\n\nRead this: [It Looks Like Youâ€™re Trying To Take Over The World](https://www.gwern.net/fiction/Clippy)\n\n### Conclusion\n\nThe last few weeks have made me begin to adjust my assumptions about what machine learning will be able to do. I now\nthink it is likely that the scaling hypothesis will hold, and that we will experience human-level competency in virtual\nentities in the next few years. Thatâ€™s going to bring massive change to society, work and business. Be prepared.","src/content/blog/the-state-of-machine-learning-in-2022-next-steps.md","a839a32d334ee6e6",{"html":828,"metadata":829},"\u003Cp>I recently summarized\nthe \u003Ca href=\"https://langkilde.se/post/2022-04-18-the-state-of-machine-learning-2022\">state of machine learning\u003C/a>. The post\nserved\nas a way to keep up with what \u003Cem>has happened\u003C/em> until now. Predictably, it triggered a lot of questions about what \u003Cem>will\nhappen.\u003C/em> Rather than\nmake \u003Ca href=\"https://www.businessinsider.com/elon-musk-history-of-full-self-driving-promise-2022-1?IR=T&#x26;r=US#:~:text=In%202015%2C%20billionaire%20Tesla%20CEO,still%20making%20the%20same%20promise.\">bold predictions\u003C/a>\nof future breakthroughs, it seems better to ask â€œwhat is a suitable framework based on which we can interpret new\nresults and guess possible future capabilities?â€.\u003C/p>\n\u003Cp>In general, a challenge with keeping up with machine learning research is that a list of â€œthe latest cool stuffâ€ gets\nold very quickly. At least if results are considered in too much detail. There are new results published all the time,\nbut in reality, â€œbreakthroughsâ€ are rather few. Most papers are â€œimproved state-of-the-art by 1%â€-noise. I do not think\nyou can predict the future of research since a lot of innovation is accidental and unexpected. But we can do a lot\nbetter than random guessing. It is necessary to try predicting the future since there is a lot at stake for society,\nbusiness, and humans. So, here are some thoughts on how to reason about the future of machine learning:\u003C/p>\n\u003Cp>Letâ€™s use two recent papers as examples. They were both published very recently (so recent in fact, that I did not cover\nthem in my previous post). The first one, \u003Cstrong>PaLM\u003C/strong> , was published in early April\n2022 (\u003Ca href=\"https://ai.googleblog.com/2022/04/pathways-language-model-palm-scaling-to.html\">blog\u003C/a>, \u003Ca href=\"https://arxiv.org/abs/2204.02311\">paper\u003C/a>)\nand the second one, \u003Cstrong>Flamingo\u003C/strong> , was published in late April\n2022 (\u003Ca href=\"https://www.deepmind.com/blog/tackling-multiple-tasks-with-a-single-visual-language-model\">blog\u003C/a>, \u003Ca href=\"https://arxiv.org/abs/2204.14198\">paper\u003C/a>).\nBoth papers contain mind-blowing demo results (see examples below).\u003C/p>\n\u003Cp>\u003Cimg src=\"https://storage.googleapis.com/langkilde-se-images/3b6f9301-b2b4-4431-abfb-12fbc34bd14b.jpeg\" alt=\"\">\n\u003Cstrong>Caption:\u003C/strong> Flamingos having conversations with humans.\u003C/p>\n\u003Cp>\u003Cimg src=\"https://storage.googleapis.com/langkilde-se-images/a61fb14d-bfd1-4e34-8269-b49009110502.jpeg\" alt=\"\">\n\u003Cstrong>Caption:\u003C/strong> PaLM explaining jokes.\u003C/p>\n\u003Cp>So, how do we make sense of these papers? And what do they mean for the next wave of machine learning applications?\u003C/p>\n\u003Cp>All research builds on previous results, so we should ask ourselves: what is \u003Cem>actually\u003C/em> new about these papers? It is\ntempting to focus on the amazing demo output, but a more interesting question is â€œwhy does it work better than before?â€.\nLater, we will of course also focus on when it does not work.\u003C/p>\n\u003Cp>Letâ€™s start with what is \u003Cem>not\u003C/em> \u003Cem>new\u003C/em>. The core concepts of \u003Cstrong>numerical optimization\u003C/strong> and \u003Cstrong>deep neural networks\u003C/strong> have\nremained largely unchanged for a long time. Neither PaLM nor Flamingo changes anything about these core concepts. Of\ncourse, there are improvements and tricks used to make them perform better, but the fundamental idea is more or less the\nsame. It also turns out both papers make use of the same kind of \u003Cstrong>embeddings\u003C/strong> that weâ€™ve seen for the last 12-13 years\nnow, i.e. models representing information as dense vectors. Finally, both models leverage \u003Cstrong>attention and transformers\u003C/strong>\nto learn improved embeddings. We covered these concepts in\nthe \u003Ca href=\"https://langkilde.se/post/2022-04-18-the-state-of-machine-learning-2022\">previous blog post\u003C/a>.\u003C/p>\n\u003Ch3 id=\"larger-models-are-still-better\">Larger Models are (still) Better\u003C/h3>\n\u003Cp>It turns out that the progress shown in recent papers is mostly about \u003Cstrong>size\u003C/strong> , both in model and data**.** To quote\nthe authors of the PaLM paper:\u003C/p>\n\u003Cblockquote>\n\u003Cp>Since GPT-3, a number of other large autoregressive language models have been developed which have continued to push\nthe state of the art forward. [â€¦] The improvements in these models have primarily come from one or more of the\nfollowing\napproaches: (1) scaling the size of the models in both depth and width; (2) increasing the number of tokens that the\nmodel was trained on; (3) training on cleaner datasets from more diverse sources; and (4) increasing model capacity\nwithout increasing the computational cost through sparsely activated modules. [â€¦] \u003Cstrong>This critically demonstrates\nscaling\nimprovements from large LMs have neither plateaued nor reached their saturation point.\u003C/strong>\u003C/p>\n\u003C/blockquote>\n\u003Cp>The fact that transformers can be parallelized, and the emergence of new, innovative ways to train models such\nas \u003Ca href=\"https://blog.google/technology/ai/introducing-pathways-next-generation-ai-architecture/\">Pathways\u003C/a> make it possible\nto train larger and larger models. The unexpected result is that \u003Cstrong>we should expect models to keep improving as they\nkeep growing.\u003C/strong> People have been suggesting this for years, but Iâ€™ve always believed more sophisticated representation\nmethods would be required. I mean, intuitively more context when learning should make a model more capable, but the fact\nthat the latent space can organize the information so successfully is surprising. At least to me. It could have very\nwell been that information got â€œjumbledâ€ as the model grows, but it appears not to. It also appears as if concepts can\nbe combined and reused across domains in a surprisingly robust way.\u003C/p>\n\u003Ch3 id=\"chain-of-thought\">Chain-of-Thought\u003C/h3>\n\u003Cp>Besides size, a new thing from my perspective is that PaLM demonstrates that when model scaling is combined with *\n\u003Cem>chain-of-thought prompting\u003C/em>* the model can solve problems that require multi-step mathematical or commonsense reasoning\nto produce the correct answer. I hadnâ€™t read much about this concept before, so \u003Cem>for me,\u003C/em> this was new. It looks like\nthe best paper to read on this\nis â€œ\u003Ca href=\"https://arxiv.org/pdf/2201.11903.pdf\">Chain of Thought Prompting Elicits Reasoning in Large Language Models\u003C/a>â€. The\npurpose is to handle so-called â€œ\u003Ca href=\"https://en.wikipedia.org/wiki/Thinking,_Fast_and_Slow\">system-2\u003C/a>â€ tasks such as\nlogical, mathematical, and common sense reasoning. Large language models exhibit flat scaling curves for such tasks,\ni.e. they will not improve with the size of the model. To handle this, the authors propose a way for these models to\ndecompose multi-step problems into intermediate steps. The idea is basically to let the model generate a coherent set of\nshort sentences that lead to the answer to a reasoning problem.\u003C/p>\n\u003Cp>Turning to Flamingo, the most interesting aspect of this model is that it is:\u003C/p>\n\u003Cblockquote>\n\u003Cp>it is a visually-conditioned autoregressive text generation model able to ingest a sequence of text tokens interleaved\nwith images and/or videos, and produce text as output.\u003C/p>\n\u003C/blockquote>\n\u003Cp>Basically, it can process images and text interchangeably in a sequence and predict a suitable next sequence of text\ntokens. When considered together with DALLE2 I assume itâ€™s just a matter of time before it can also respond with an\nimage every now and then. Imagine the human operator inputting a sequence of text and images, and then asking â€œShow me\nwhat you are thinkingâ€, to which the model would output an image capturing its â€œstate of mindâ€. Such an exchange should\nbe possible.\u003C/p>\n\u003Ch3 id=\"diffusion-models\">Diffusion Models\u003C/h3>\n\u003Cp>It is clear that GANs have a powerful new contender: \u003Ca href=\"https://arxiv.org/pdf/2006.11239.pdf\">diffusion models\u003C/a>. To\nquote \u003Ca href=\"https://lilianweng.github.io/posts/2021-07-11-diffusion-models/\">Lilian Weng\u003C/a>:\u003C/p>\n\u003Cblockquote>\n\u003Cp>Diffusion models are inspired by non-equilibrium thermodynamics. They define a Markov chain of diffusion steps to\nslowly add random noise to data and then learn to reverse the diffusion process to construct desired data samples from\nthe noise. Unlike VAE or flow models, diffusion models are learned with a fixed procedure and the latent variable has\nhigh dimensionality (same as the original data).\u003C/p>\n\u003C/blockquote>\n\u003Cp>Diffusion models are used in DALLE2 to generate data by reversing a gradual noising process. So basically they â€œremove\nnoiseâ€. Noise in this context is a rather complicated concept. Itâ€™s not a lack of sharpness or anything, itâ€™s more\nradical than that. Itâ€™s more like taking a crude vector and finding various suitable images based on it.\u003C/p>\n\u003Cp>\u003Cimg src=\"https://storage.googleapis.com/langkilde-se-images/3da651f8-9397-4252-8693-d968e537f2fa.jpeg\" alt=\"\">\n\u003Cstrong>Caption:\u003C/strong> Description from original paper.\u003C/p>\n\u003Cp>If you want to read more about it, I found this post to be very well\nwritten: \u003Ca href=\"https://www.assemblyai.com/blog/how-dall-e-2-actually-works/\">How DALL-E2 Actually Works\u003C/a>. Below is an example\nfrom the DALLE2 paper showing the variations created by the diffusion model on the same core vector.\u003C/p>\n\u003Cp>\u003Cimg src=\"https://storage.googleapis.com/langkilde-se-images/d389ad7b-016f-4038-8ff9-42c49c5b7f7c.jpeg\" alt=\"\">\u003C/p>\n\u003Cp>A concept that is not covered by the papers Iâ€™ve focused on, but that is offering new and exciting technology is Graph\nNeural Networks (GNNs). They have been on the fringe of research until recently, but are not exploding in interest. The\nidea is that you can create mesh-based simulations and predict how meshes change over time depending on external\nfactors. That can be used for things like ETA in traffic. They are still not very resource-efficient, but new methods\nlike \u003Ca href=\"https://arxiv.org/pdf/2106.07476.pdf\">RevGNNs\u003C/a> appear to lower the cost dramatically. These models appear to be\nuseful for long-time planning in reinforcement learning. An example is this\npaper: â€œ\u003Ca href=\"https://arxiv.org/pdf/2011.12491.pdf\">World Model as a Graph: Learning Latent Landmarks for Planning\u003C/a>â€.\u003C/p>\n\u003Cp>\u003Cimg src=\"https://storage.googleapis.com/langkilde-se-images/3f3f940b-fddb-4492-875d-8b0116297084.jpeg\" alt=\"\">\u003C/p>\n\u003Cp>As impressive as the demos are, there are still limitations to these models. Knowing their limitations, and how likely\nit is that we can overcome those limitations, will be important to predict what is possible in the future.\u003C/p>\n\u003Ch3 id=\"the-need-for-webscale-human-curated-knowledge\">The need for webscale human-curated knowledge\u003C/h3>\n\u003Cp>These models still depend on \u003Cstrong>annotated data\u003C/strong>. You might protest, and the authors of these papers like to highlight\nthat they avoid the need for large amounts of annotated data. At the same time, they clearly rely on â€œwebscale\ndatasetsâ€. It turns out the internet is made by humans. All the text written, and the image captions created, are\nwritten by humans. So in fact, the concepts manifested in the modelâ€™s latent space, need to first be described by humans\nin text and associated with images. And as a result, these models will also learn whatever undesired concepts and biases\nare present online. How to handle that, and mitigate that, will be a big part of making these models aligned with our\ninterests.\u003C/p>\n\u003Cp>What these papers show is that \u003Cem>if you have webscale amounts of human-curated knowledge\u003C/em> a lot of tasks can be solved\nusing the same foundational model. So in that sense, \u003Cem>you do not need task-specific annotated data\u003C/em> assuming the task is\na subset of what is described on the internet. Which tasks are implicitly described online, and which are not, is not\nclear to me at this point.\u003C/p>\n\u003Ch3 id=\"fixed-amount-of-thinking\">Fixed Amount of Thinking\u003C/h3>\n\u003Cp>These models all have a limited amount of \u003Ca href=\"https://en.wikipedia.org/wiki/FLOPS\">FLOPS\u003C/a> to spend, i.e. they are not\nâ€œcontinuously activeâ€. This limits what tasks can be solved. Input is fed through the network and output is generated.\nOnce that is done, nothing else can happen. Iâ€™m not actually sure how big this limitation is scientifically, or if itâ€™s\nmore an issue of cost/energy. Maybe the government or military can keep one of these models spinning continuously. Just\nhook it up to a nuclear reactor or something? Humans can choose to think more about something if it is complicated.\nThese models cannot.\u003C/p>\n\u003Ch3 id=\"models-are-still-great-at-bullshitting\">Models are still Great at Bullshitting\u003C/h3>\n\u003Cp>Models are still great at bullshitting when they â€œdo not knowâ€ the answer. I get the impression they are â€œbiased for\nactionâ€ in the sense that most versions of these systems prefer some output over â€œI do not knowâ€. In fact, it seems\nmodels are â€œextremely sureâ€ all the time, even when the output is more or less ungrounded. Paper authors describe this\nas â€œhallucinationsâ€ which might be a case of anthropomorphizing. It could also be that there are sufficiently similar\nconcepts in the data that the model picks a prediction that humans feel is nonsense, but that is actually statistically\naccurate. Which is correct, that which a human finds intuitive, or that which is most statistically likely?\u003C/p>\n\u003Cp>\u003Cimg src=\"https://storage.googleapis.com/langkilde-se-images/8d100b39-b1d8-41f8-b7cb-7e266818795d.jpeg\" alt=\"\">\n\u003Cstrong>Caption:\u003C/strong> From the Flamingo paper.\u003C/p>\n\u003Cp>Of course, the results you see in the papers are impressive, but there are also a lot of really strange results popping\nup. Iâ€™m less worried about this because if these models do in fact keep getting better and better with size, the\nfrequency of obvious errors will probably go down. But either way, estimating performance based on examples in papers is\nhard. Sure, the benchmarks are there to make sure performance evaluation is unbiased, but when you actually consider the\nnumbers they show, there will be a lot of strange results if you interacted with a model. I also think humans tend to\nwrite leading questions. Take the following example:\u003C/p>\n\u003Cp>\u003Cimg src=\"https://storage.googleapis.com/langkilde-se-images/de13e9d2-5035-4274-8418-c839e7386396.jpeg\" alt=\"\">\n\u003Cstrong>Caption:\u003C/strong> Example of Flamingo interacting with a human. Are the questions leading it to the right response?\u003C/p>\n\u003Cp>Recent models are still completely virtual. I recently learned about\nthe \u003Ca href=\"https://en.wikipedia.org/wiki/Moravec%27s_paradox\">Moravecâ€™s paradox\u003C/a> which hypothesizes that:\u003C/p>\n\u003Cblockquote>\n\u003Cp>[â€¦] contrary to traditional assumptions, reasoning requires very little computation, but sensorimotor and perception\nskills require enormous computational resources [â€¦] In general, weâ€™re least aware of what our minds do best and weâ€™re\nmore aware of simple processes that donâ€™t work well than of complex ones that work flawlessly [â€¦] it is comparatively\neasy to make computers exhibit adult level performance on intelligence tests or playing checkers, and difficult or\nimpossible to give them the skills of a one-year-old when it comes to perception and mobility.\u003C/p>\n\u003C/blockquote>\n\u003Cp>This feels right to me, but I obviously donâ€™t know. Maybe Iâ€™m just giving myself a false sense of safety. Maybe we\nshould not feel too scared about these algorithms until weâ€™ve actually made a lot more progress on physical robotics.\nMaybe reasoning isnâ€™t actually that hard?!\u003C/p>\n\u003Ch1 id=\"what-will-happen-next\">What will happen next?\u003C/h1>\n\u003Cp>It might seem like a philosophical question: â€œwhat will the future of machine learning look like?â€. Iâ€™ve long been a\nskeptic. For years Iâ€™ve been\nsaying â€œ\u003Ca href=\"https://open.spotify.com/episode/61HsG2Xl9zorDyrmEsR7FH\">actually, computers are pretty dumb\u003C/a>â€. Recently, Iâ€™ve\nstarted changing my mind. The emergence of massive latent spaces and the fact that human knowledge can apparently be\nrepresented in such spaces, makes me rethink things. In my case, I own and run a company that is tightly connected to\nthe future of machine learning, so it is my job to keep track of this. But I think it also matters as a human. So, what\ncan we expect?\u003C/p>\n\u003Cp>\u003Cstrong>More Modalities are Merged.\u003C/strong> The obvious, short-term next step is to combine text, images, and sound. Iâ€™m sure\nthere are already really promising\nresults brewing inside Google and other companies. We will be talking to these models in natural language and getting\naudible responses very soon. Alexa, Siri, and Hey Google are about to get a massive upgrade. With DALLE2 it feels likely\nwe will also see interactive visuals that go with these audio interfaces before long. I think learning human emotion and\nfacial expressions is probably possible if you understand language and images, and have access to the entire internet.\u003C/p>\n\u003Cp>\u003Cstrong>The Scaling Hypothesis Keeps Holding.\u003C/strong> Maybe we are all just brute-forcing life? I highly encourage you to read\nGwerns excellent post\non â€œ\u003Ca href=\"https://www.gwern.net/Scaling-hypothesis\">The Scaling Hypothesis\u003C/a>â€. To\nquote \u003Ca href=\"https://nitter.hu/geoffreyhinton/status/1270814602931187715\">Geoff Hinton\u003C/a>:\u003C/p>\n\u003Cblockquote>\n\u003Cp>Extrapolating the spectacular performance of GPT3 into the future suggests that the answer to life, the universe and\neverything is just 4.398 trillion parameters.\u003C/p>\n\u003C/blockquote>\n\u003Cp>There is no evidence today that very large models will suffer diminishing returns in their ability to learn. If that\nholds over time, these models should approach human-equal performance by the time their parameter space matches our\nbrain. There might be as many as 1 trillion synapses in the brain, i.e. neurons connected to each other and passing\nsignals to each other. The largest language models are approaching 1 trillion parameters. Together with a continuously\ngrowing size of encoded human knowledge, it is now possible that these models will match us in just a few years.\u003C/p>\n\u003Cp>That does not mean we will have Terminator-style robots in a few years, it means we will have virtual entities that we\ncan talk to that are indistinguishable from humans. Maybe. On the other hand, we might find that â€œOh fuck, there was a\nroadblock here that we didnâ€™t expectâ€ and suddenly improvements are in fact diminishing.\u003C/p>\n\u003Cp>\u003Cstrong>A lot of new companies are emerging.\u003C/strong> The â€œAttention is All You Needâ€ paper lead to the founding of a bunch\nof \u003Ca href=\"https://twitter.com/nathanbenaich/status/1524029269617295361/photo/1\">new start-ups\u003C/a>. Just the authors alone have\nstarted a bunch, and others have followed in nearby domains. Here are some of my favorites.\u003C/p>\n\u003Cul>\n\u003Cli>\n\u003Cp>\u003Cstrong>Adept.\u003C/strong> â€œbuild[ing] general intelligence that enables humans and computers to work together creatively to solve\nproblems.â€ (\u003Ca href=\"https://techcrunch.com/2022/04/26/2304039/\">TechCrunch\u003C/a>)\u003C/p>\n\u003C/li>\n\u003Cli>\n\u003Cp>\u003Cstrong>AI21 Labs.\u003C/strong> â€œa natural language interface on your company\ndataâ€. (\u003Ca href=\"https://www.ai21.com/blog/jurassic-x-crossing-the-neuro-symbolic-chasm-with-the-mrkl-system\">website\u003C/a>)\u003C/p>\n\u003C/li>\n\u003Cli>\n\u003Cp>\u003Cstrong>Aleph Alpha.\u003C/strong> â€œEuropes OpenAIâ€œ (\u003Ca href=\"https://www.aleph-alpha.com\">website\u003C/a>)\u003C/p>\n\u003C/li>\n\u003Cli>\n\u003Cp>\u003Cstrong>Anthropic\u003C/strong>. â€œan AI safety and research company, has raised $580 million in a Series\nB.â€ (\u003Ca href=\"https://www.anthropic.com/news/announcement\">website\u003C/a>)\u003C/p>\n\u003C/li>\n\u003Cli>\n\u003Cp>\u003Cstrong>Character.ai.\u003C/strong> â€œcreating revolutionary open-ended conversational applications through breakthrough\nresearch.â€ (\u003Ca href=\"https://www.character.ai\">website\u003C/a>)\u003C/p>\n\u003C/li>\n\u003Cli>\n\u003Cp>\u003Cstrong>Co:here. â€œ\u003C/strong> making NLP part of every developerâ€™s\ntoolkitâ€****(\u003Ca href=\"https://techcrunch.com/2021/11/17/google-cloud-teams-up-with-nlp-startup-cohere-on-multi-year-partnership/\">TechCrunch\u003C/a>, \u003Ca href=\"https://cohere.ai\">website\u003C/a>)\u003C/p>\n\u003C/li>\n\u003Cli>\n\u003Cp>\u003Cstrong>Inceptive. â€œ\u003C/strong> enabling the design of this next generation of RNA molecules through a singular combination of highly\nscalable experiments and deep learning.â€ (\u003Ca href=\"https://inceptive.life\">website\u003C/a>)\u003C/p>\n\u003C/li>\n\u003Cli>\n\u003Cp>\u003Cstrong>Primer.\u003C/strong> â€œlets organizations quickly explore and utilize the worldâ€™s exponentially growing sources of text-based\ninformationâ€ (\u003Ca href=\"https://primer.ai\">website\u003C/a>)\u003C/p>\n\u003C/li>\n\u003C/ul>\n\u003Cp>\u003Cimg src=\"https://storage.googleapis.com/langkilde-se-images/bf57eb94-ae50-4a2b-924d-eee87f919488.jpeg\" alt=\"\">\u003C/p>\n\u003Cp>Predictably, most of the companies are \u003Ca href=\"https://www.stateof.ai\">based in the US\u003C/a>:\u003C/p>\n\u003Cp>\u003Cimg src=\"https://storage.googleapis.com/langkilde-se-images/b13d2460-f4d2-4d18-bf30-a3f29412fc95.jpeg\" alt=\"\">\u003C/p>\n\u003Ch3 id=\"access-to-quality-knowledge-becomes-limitation\">Access to Quality Knowledge Becomes Limitation\u003C/h3>\n\u003Cp>I think machine learning systems are already suffering from the same problems humans do: a lot of them are garbage. I\nmean, being a human does not guarantee you are a good, productive member of society. Becoming a great person requires\ncareful â€œtuningâ€ through education, parenting, selective reading, coaching, and mentoring. If we just consume everything\naround us all the time and give in to all our urges, we become awful people.\u003C/p>\n\u003Cp>I think we will find that as more capable ML systems emerge, we will lose some of the normal advantages of computers:\npreciseness and predictability. I think thatâ€™s a passing problem since once youâ€™ve perfected the knowledge base for one\nof these entities it could theoretically live forever, and keep improving.\u003C/p>\n\u003Cp>I think we can spend eternity curating a knowledge base and debating what is right. I mean, thatâ€™s how we spend most of\nour time anyway right? As soon as you have enough food and shelter, we climb the Maslow stairs and spend our time\npondering the meaning of life. An algorithm could do that forever without any really progress. Sure, it might pick\nan \u003Ca href=\"https://www.lesswrong.com/tag/paperclip-maximizer\">optimization problem to focus on\u003C/a>, and that might be bad. But\nitâ€™s also possible it will \u003Ca href=\"https://en.wikipedia.org/wiki/The_Murderbot_Diaries\">just make and watch soap operas\u003C/a> all\nday. Who knows?\u003C/p>\n\u003Ch3 id=\"reading-recommendations\">Reading Recommendations\u003C/h3>\n\u003Cp>\u003Cstrong>The State of AI.\u003C/strong> During my research on this, Iâ€™ve spent a lot of time reading the excellent stuff that Nathan\nBenaich is publishing (\u003Ca href=\"https://twitter.com/nathanbenaich\">twitter\u003C/a>, \u003Ca href=\"https://www.stateof.ai\">website\u003C/a>).\u003C/p>\n\u003Cp>\u003Cstrong>Gwern.\u003C/strong> There are so many good posts on the site:\u003C/p>\n\u003Cul>\n\u003Cli>\n\u003Cp>\u003Ca href=\"https://www.gwern.net/Scaling-hypothesis\">The Scaling Hypothesis\u003C/a>\u003C/p>\n\u003C/li>\n\u003Cli>\n\u003Cp>\u003Ca href=\"https://www.gwern.net/notes/Scaling\">Machine Learning Scaling\u003C/a>\u003C/p>\n\u003C/li>\n\u003C/ul>\n\u003Cp>My last link will be from that site, and it is probably a good place to go next. As Gwern puts it:\u003C/p>\n\u003Cblockquote>\n\u003Cp>It might help to imagine a hard takeoff scenario using solely known sorts of NN &#x26; â scaling effectsâ€¦ [This] is a story\nwhich may help stretch your imagination and defamiliarize the 2022 state of machine learning.\u003C/p>\n\u003C/blockquote>\n\u003Cp>Read this: \u003Ca href=\"https://www.gwern.net/fiction/Clippy\">It Looks Like Youâ€™re Trying To Take Over The World\u003C/a>\u003C/p>\n\u003Ch3 id=\"conclusion\">Conclusion\u003C/h3>\n\u003Cp>The last few weeks have made me begin to adjust my assumptions about what machine learning will be able to do. I now\nthink it is likely that the scaling hypothesis will hold, and that we will experience human-level competency in virtual\nentities in the next few years. Thatâ€™s going to bring massive change to society, work and business. Be prepared.\u003C/p>",{"headings":830,"localImagePaths":859,"remoteImagePaths":860,"frontmatter":861,"imagePaths":862},[831,834,837,840,843,846,849,852,855,858],{"depth":24,"slug":832,"text":833},"larger-models-are-still-better","Larger Models are (still) Better",{"depth":24,"slug":835,"text":836},"chain-of-thought","Chain-of-Thought",{"depth":24,"slug":838,"text":839},"diffusion-models","Diffusion Models",{"depth":24,"slug":841,"text":842},"the-need-for-webscale-human-curated-knowledge","The need for webscale human-curated knowledge",{"depth":24,"slug":844,"text":845},"fixed-amount-of-thinking","Fixed Amount of Thinking",{"depth":24,"slug":847,"text":848},"models-are-still-great-at-bullshitting","Models are still Great at Bullshitting",{"depth":54,"slug":850,"text":851},"what-will-happen-next","What will happen next?",{"depth":24,"slug":853,"text":854},"access-to-quality-knowledge-becomes-limitation","Access to Quality Knowledge Becomes Limitation",{"depth":24,"slug":856,"text":857},"reading-recommendations","Reading Recommendations",{"depth":24,"slug":223,"text":224},[],[],{"pubDate":823,"title":822},[],"the-state-of-machine-learning-in-2022-next-steps.md","understanding-need-risk-excitement",{"id":864,"data":866,"body":869,"filePath":870,"digest":871,"rendered":872,"legacyId":886},{"title":867,"pubDate":868},"Understanding Need, Risk and Excitement","2024-09-16","I've been struggling with the trade-offs between disruptive innovation and incremental innovation for a long time.\nLiterature will tell you there are two types of products: new solutions to new problems, and better solutions to old\nproblems. The former is usually referred to as \"disruptive innovation\", while the latter \"incremental innovation\".\n\n### An understanding of needs\nBoth, however, must be based on a deep understanding of needs. At some abstract level, I think human needs are eternal.\nWe want love, respect, intimacy, comforts, riches and so forth. When a new innovation comes around, it usually presents\nan entirely new way to satisfy these needs. But if it doesn't unlock a way to satisfy a deep desire, it will never be\nsuccessful.\n\nWhen customers express their need it is often tempting to dismiss them as wrong. _\"Oh they don't know what they need, we\nknow better.\"_ That's a slippery slope I've been down many times. While there is a major difference between *\n*_how customers express their need_**, and **_what their actual need is_** - **_there is always a legitimate need!_**.\nYour job as an innovator and product developer is to reflect deeply about the nature of their need, filtering through\neverything they are saying to find what they really, really care about. It's about listening and thinking deeply. There\nis so much bias, noise and confusion getting in the way of understanding what people really want.\n\nYou need to learn to shut out everyone else's opinions. Tons of people will share opinions: team members will try to\nsimplify their work, investors will push for what they think increases market cap short-term, leaders will ask for what\ngrows their powers, and so forth. Don't let all that noise get in the way of listening deeply to customers needs.\n\n### Risk preference\n**Once we have established the nature of the true need, you have to decide how radical you can be when innovating.**\nThat's about risk preference. There are no universal truths when talking about risk, it's all about preference. Action\nalways comes with two costs: time and capital. The more radical the solution, the more time and capital it usually\ntakes, and the more likely you are to fail.\n\n**Allocate based on risk-adjusted reward.** There are times when companies will choose to spend 80%+ of their resources\non incremental innovation. Perhaps their market position is exposed to a lot of competition, and they need to secure\nwhat they have. Others may have a very strong position in their core market, and can afford to take more risk. Such\ncompanies may spend only 20% of their resources on core products, and 80% on new, disruptive products. Some may be\nfacing extinction, and choose to bet everything on a new, hail mary idea. Some have just started and have nothing to\nlose. Ultimately, the choice between risk and reward is a deeply personal one. Companies will be reflections of their\nfounders and shareholders. Some prefer to play it safe, compounding for decades through incremental innovation. Others\nare bored easily and regularly bet everything. I think it's important to think about success on a risk adjusted basis.\nI've started to think about \"risk-adjusted emotions\". If I make a bold bet and fail, I'm less sad than if a sure bet\ngoes sour. Personally, I think most people would benefit from taking more risk, but that's just me.\n\n**Don't go about things in the wrong order.** Don't start with a cool technology, or a cool solution. Always start with\na deep, powerful need. I've started thinking in terms of virality: how likely is it that someone with this need will be\nso excited about your solution that they share it with their friends? It takes a lot for someone to recommend a product.\nYou want to find a desire so powerful that once solved it makes people really, really excited.","src/content/blog/understanding-need-risk-excitement.md","f7aab26f52493c3a",{"html":873,"metadata":874},"\u003Cp>Iâ€™ve been struggling with the trade-offs between disruptive innovation and incremental innovation for a long time.\nLiterature will tell you there are two types of products: new solutions to new problems, and better solutions to old\nproblems. The former is usually referred to as â€œdisruptive innovationâ€, while the latter â€œincremental innovationâ€.\u003C/p>\n\u003Ch3 id=\"an-understanding-of-needs\">An understanding of needs\u003C/h3>\n\u003Cp>Both, however, must be based on a deep understanding of needs. At some abstract level, I think human needs are eternal.\nWe want love, respect, intimacy, comforts, riches and so forth. When a new innovation comes around, it usually presents\nan entirely new way to satisfy these needs. But if it doesnâ€™t unlock a way to satisfy a deep desire, it will never be\nsuccessful.\u003C/p>\n\u003Cp>When customers express their need it is often tempting to dismiss them as wrong. \u003Cem>â€œOh they donâ€™t know what they need, we\nknow better.â€\u003C/em> Thatâ€™s a slippery slope Iâ€™ve been down many times. While there is a major difference between *\n*\u003Cem>how customers express their need\u003C/em>**, and \u003Cstrong>\u003Cem>what their actual need is\u003C/em>\u003C/strong> - \u003Cstrong>\u003Cem>there is always a legitimate need!\u003C/em>\u003C/strong>.\nYour job as an innovator and product developer is to reflect deeply about the nature of their need, filtering through\neverything they are saying to find what they really, really care about. Itâ€™s about listening and thinking deeply. There\nis so much bias, noise and confusion getting in the way of understanding what people really want.\u003C/p>\n\u003Cp>You need to learn to shut out everyone elseâ€™s opinions. Tons of people will share opinions: team members will try to\nsimplify their work, investors will push for what they think increases market cap short-term, leaders will ask for what\ngrows their powers, and so forth. Donâ€™t let all that noise get in the way of listening deeply to customers needs.\u003C/p>\n\u003Ch3 id=\"risk-preference\">Risk preference\u003C/h3>\n\u003Cp>\u003Cstrong>Once we have established the nature of the true need, you have to decide how radical you can be when innovating.\u003C/strong>\nThatâ€™s about risk preference. There are no universal truths when talking about risk, itâ€™s all about preference. Action\nalways comes with two costs: time and capital. The more radical the solution, the more time and capital it usually\ntakes, and the more likely you are to fail.\u003C/p>\n\u003Cp>\u003Cstrong>Allocate based on risk-adjusted reward.\u003C/strong> There are times when companies will choose to spend 80%+ of their resources\non incremental innovation. Perhaps their market position is exposed to a lot of competition, and they need to secure\nwhat they have. Others may have a very strong position in their core market, and can afford to take more risk. Such\ncompanies may spend only 20% of their resources on core products, and 80% on new, disruptive products. Some may be\nfacing extinction, and choose to bet everything on a new, hail mary idea. Some have just started and have nothing to\nlose. Ultimately, the choice between risk and reward is a deeply personal one. Companies will be reflections of their\nfounders and shareholders. Some prefer to play it safe, compounding for decades through incremental innovation. Others\nare bored easily and regularly bet everything. I think itâ€™s important to think about success on a risk adjusted basis.\nIâ€™ve started to think about â€œrisk-adjusted emotionsâ€. If I make a bold bet and fail, Iâ€™m less sad than if a sure bet\ngoes sour. Personally, I think most people would benefit from taking more risk, but thatâ€™s just me.\u003C/p>\n\u003Cp>\u003Cstrong>Donâ€™t go about things in the wrong order.\u003C/strong> Donâ€™t start with a cool technology, or a cool solution. Always start with\na deep, powerful need. Iâ€™ve started thinking in terms of virality: how likely is it that someone with this need will be\nso excited about your solution that they share it with their friends? It takes a lot for someone to recommend a product.\nYou want to find a desire so powerful that once solved it makes people really, really excited.\u003C/p>",{"headings":875,"localImagePaths":882,"remoteImagePaths":883,"frontmatter":884,"imagePaths":885},[876,879],{"depth":24,"slug":877,"text":878},"an-understanding-of-needs","An understanding of needs",{"depth":24,"slug":880,"text":881},"risk-preference","Risk preference",[],[],{"pubDate":868,"title":867},[],"understanding-need-risk-excitement.md","the-state-of-machine-learning-in-2022",{"id":887,"data":889,"body":892,"filePath":893,"digest":894,"rendered":895,"legacyId":918},{"title":890,"pubDate":891},"The State of Machine Learning in 2022","2022-04-18","Iâ€™ve been passionate about machine learning for as long as I can remember. I built my first robot more than 20 years ago\nout of Lego Mindstorm bricks. Itâ€™s been a wild ride since then, and the field keeps evolving. Running a business that is\nclosely tied to the progress of state-of-the-art machine learning means Iâ€™m trying to stay up to date with what is going\non. In this post, we will go through what I consider the most interesting breakthroughs recently. **We will cover\nembeddings, attention, transformers, and multi-modal models.**\n\n**At the end of the post, I will share some thoughts on what this means for society and business.** If you donâ€™t want\nall the technical details, you can skip to the end now. But I encourage you to actually try to understand the recent\nbreakthroughs. Otherwise, you will have a hard time determining what these breakthroughs mean for you and your business.\n\n![DALLE2. Image generated by an algorithm based on caption provided by a human.](https://images.squarespace-cdn.com/content/v1/5c2b12dae17ba3d4ccb3bdfd/7c21fbc9-ca39-41b6-afb0-07b319d7f360/Screenshot+2022-04-20+at+11.03.01.png)\n**Caption:** Teddy bears working on new AI research on the moon in the 1980s\n\n### Learning requires efficient abstractions\n\nMachine learning, in my opinion, is about finding efficient abstractions that enable the robust interpretation of\ndiverse data. The â€œproblemâ€ with reality is that most things are rare. If you look too closely at each data point it\nappears unique. You have to â€œsquintâ€ to cope with all the information we are exposed to. Humans are great at this. We\nhalf-ass most data processing and make heavy use of prejudice in the name of efficiency. This ability has served us well\nin our effort to process diverse data in an energy-efficient way. We are optimized to minimize learning time and energy\nconsumption while maximizing procreation. It is less good if you want a consistent and fair evaluation of data. Humans\nare bad at consistency and fairness.\n\nThink of it this way: if we always considered each situation as a completely new situation based on minor changes we\nwould get exhausted. Instead, we remember previous situations weâ€™ve been in and abstract away the specific details. â€œOh,\nIâ€™m approaching an intersection now, I know there can be cars coming from different directions. Sure, it is a slightly\ndifferent intersection than before but I still have some idea of what might happen.â€\n\nThe challenge for machine learning researchers is to figure out how to extract the most efficient abstractions. If they\nare too crude, the quality of output goes down. If they are too exact, learning becomes very, very expensive. I equate\nthese abstractions to â€œcommon senseâ€.\n\nEmbeddings were my first real machine learning â€œmind-fuckâ€ experience. I still\nremember [reading Mikolovs paper](https://arxiv.org/pdf/1310.4546.pdf) the first time and realizing what a huge thing\nthe embedding concept was going to be. Itâ€™s so simple yet so elegant. I wonâ€™t spend much time on it here since itâ€™s old\nnews, but it still forms the foundation for so many things, so you better make sure you understand this concept. A good\nway to learn is to\nwatch [this presentation from Google](https://developers.google.com/machine-learning/crash-course/embeddings/video-lecture#:~:text=An%20embedding%20is%20a%20relatively,like%20sparse%20vectors%20representing%20words.).\nLetâ€™s say we have 10.000 words and want to represent a word as a vector. One option would be to replace the word with a\nvector of dimension 10000 with all cells set to zero except the one representing our word. Problem is, you would get a\nlot of very large vectors with mostly zeros in them. Instead, we can create lower dimensional vectors representing each\nword. If you create these vectors based on the context in which words ocrrus in it turns they preserve semantic\nproperties and open up for using linear algebra on them in cool ways (like in the picture below). Learn about\nembeddings.\n\n![](https://storage.googleapis.com/langkilde-se-images/672a00d7-ea8d-4c5f-a6ae-db9e50bd5cf6.jpeg)\n\n### Attention and Transformers\n\nIn recent years, the most influential paper in my opinion\nis â€œ[Attention Is All You Need](https://arxiv.org/pdf/1706.03762v5.pdf)â€ from the Brain at Google. This paper\ndemonstrated that attention mechanisms can replace\nboth [recurrent](https://en.wikipedia.org/wiki/Recurrent_neural_network)\nand [convolutional](https://en.wikipedia.org/wiki/Convolutional_neural_network) neural networks, while still both\nimproving results and lowering the cost of training. After years of just pushing the limits of RNNs and CNNs, a new\nparadigm emerged. RNNs had the downside that they did not allow for parallelized training as each new prediction was\npredicated on the previous prediction. Some tried to overcome this limitation\nby [turning sequences into â€œimagesâ€](https://arxiv.org/pdf/1705.03122.pdf) and then applying CNNs instead. The problem\nwith CNNs is that they have a hard time learning distance relationships as â€œsignal strengthâ€ diminishes with distance.\nEnter the Transformer.\n\n![](https://storage.googleapis.com/langkilde-se-images/90d0d7dd-b1b3-47b8-b6af-34fda1c81d44.jpeg)\n\nThe Transformer follows the overall architecture of [encoder/decoders](https://arxiv.org/pdf/1406.1078.pdf).\nTransformers process sentences in the form of a sequence of embeddings that it learns during training. Each token in the\nsentence is represented by a vector (in the original paper they use 512-dim vectors)\nwith [positional encoding](https://huggingface.co/blog/encoder-decoder) added, i.e. the vector also indicates the\nposition of the word in the sentence. The Encoder learns a representation of the input data (encoding) based on which\nthe Decoder produces the target output. This pattern provides a dimensionality reduction step, which goes back to the\nidea of finding abstractions. Transformers only pass on the information necessary for decoding from the input to the\nencoding.\n\n![](https://storage.googleapis.com/langkilde-se-images/e9b1de67-9316-4836-a63d-6b3841448607.jpeg)\n\nBoth the Encoder and Decoder make use of **attention**. So what is attention? The idea behind attention is to replace\nembeddings with _better_ embeddings that also contain information about the context in which the word appears.\nUnderstanding how it works requires linear algebra. The easiest to understand\nis [scaled dot-product attention](https://paperswithcode.com/method/scaled). Letâ€™s assume we have an input sentence\nX = [x_1â€¦x_n] where each word x is an embedding. Our goal is to replace the word x_n with a new vector y_n. We do this\nby summing over all the words in the sentence, with each word weighted by some number. The self-attention layer\nintroduces two matrices, W_Q and W_K by which we transform the words before we combine them. The interpretation of these\nmatrices is not obvious. We want to put numbers into these matrices so that the model considers the right context words\nwhen interpreting a specific word.\n\n![](https://storage.googleapis.com/langkilde-se-images/b5261eb9-c7cc-4059-afd2-1fdd58566943.jpeg)\n\nProf. Lennart Svensson [has a great lecture explaining this](https://www.youtube.com/watch?v=0SmNEp4zTpc). We know that\nwords that are related cluster with respect cosine distance of their word embeddings. One way to interpret the W_K\nmatrix is that we need to select it so that it forms an identity matrix in relation to which the key vectors are\nidentical to the original word embeddings. The keys would preserve the original similarity between words at face value.\nIf we then select W_Q so that our new embedding points in the same direction as the specific words we want the model to\ncare about, their inner product will then be large.\n\n![](https://storage.googleapis.com/langkilde-se-images/bb928c2c-bd19-4770-9a9d-576227ebcafb.jpeg)\n\n**I think of attention this way:** attention means learning parameters that are used to create new embeddings for input\nwords that contain information about the context. All of the parameters that fill these matrices are learned\nsimultaneously. That means that embeddings and attention, along with all other parameters, are selected so that they\ntogether maximize the quality of the network. This gives the model enormous expressive capacity, at the price of a huge\nnumber of parameters and a huge cost of computation.\n\nTransformers use Multi-Head Attention which means that it uses multiple queries per word rather than just one. The\nreasoning is that words could have different meanings depending on context. The model uses these multi-headed attention\nmechanisms in multiple ways. One of these is referred to as â€œself-attentionâ€. The idea behind self-attention is that the\nword itself impacts its own meaning and that the most appropriate word embedding depends on the context. I wonâ€™t go\nthrough all of the details. The original Transformers paper has a nice illustration of the output weights of these\nattention heads for various sentences. As you can see from the first attention head, the weights\nresemble [dependency parsing](https://web.stanford.edu/~jurafsky/slp3/14.pdf), which I guess is exactly the point.\n\n![](https://storage.googleapis.com/langkilde-se-images/566ea5f4-f02c-4278-87c0-91fed6c2b592.jpeg)\n\nAnyway, this is just the first step of the Encoder block. We feed the input sentence as a set of vectors with positional\nencoding, and we get a set of weights back that describe how each token should be regarded based on the entire sentence.\n\n![](https://storage.googleapis.com/langkilde-se-images/bd2aef82-55f2-4750-9751-0a5732653634.jpeg)\n\nWe add residual connections that carry over previous embeddings to subsequent layers, i.e. we mix together the original\nembeddings with the information learned from the multi-head attention mechanism. Finally, we add some layer\nnormalization, and voila we have our basic Encoder block. The transformer then uses six of these stacked, with the\noutput from the last block serving as input to the Decoder.\n\n![](https://storage.googleapis.com/langkilde-se-images/3aa7603f-cbd8-4b8d-9a5e-32486926925e.jpeg)\n\nThe Decoder is similar to the Encoder. One major difference is that the attention mechanism is â€œmaskedâ€, which means it\ngets a gradually increased visibility of the input sentence. This makes sense since we cannot time travel. Another\ndifference is that it treats its most recent output as the last token of its input.\n\n![](https://storage.googleapis.com/langkilde-se-images/8aa0a4d7-68a4-4a34-b258-b0e35daef331.jpeg)\n\nThis kind of processing is called auto-regressive. A nice consequence of this is that the output can have a different\nlength than the input. The Decoder ultimately outputs a vector the size of our known vocabulary, and the softmax layer\nconverts that into a vector of probabilities. It might seem simple to then just pick the most probable word, but it\nturns out using something called beam search produces even better results. Anyway, the predicted word is fed back to the\ndecoder as the last part of the next decoder input. This process continues until we predict the end-of-sentence token.\n\nIn the end, we have a construction that assumes no recurrence or convolutions when processing the input data. As long as\nwe can express our input as sequence data, we can apply this approach even in computer vision or reinforcement learning.\nThe core idea is to enrich the embeddings with features from the global context.\n\nIf you want an even better explanation of all of this, I highly\nrecommend [Prof. Lennart Svenssonâ€™s lecture](https://www.youtube.com/watch?v=0SmNEp4zTpc).\n\n![](https://storage.googleapis.com/langkilde-se-images/b7b48715-f3a3-4959-8085-c48460b0f8ab.jpeg)\n\n### Few-Shot Learners such as GPT-3\n\nIn May of 2020 researchers from OpenAI described the development of GPT-3 in the\npaper â€œ[Language Models are Few-Shot Learners](https://arxiv.org/pdf/2005.14165v4.pdf)â€. The big breakthrough in GPT-3\nis that it removes the need for huge task-specific labeled datasets in order to learn specific tasks, assuming analogous\ntasks are already represented in available language datasets (e.g. all of the internet). To quote from the paper:\n\n> â€¦humans do not require large supervised datasets to learn most language tasks â€“ a brief directive in natural\n> language (e.g. â€œplease tell me if this sentence describes something happy or something sadâ€) or at most a tiny number of\n> demonstrations (e.g. â€œhere are two examples of people acting brave; please give a third example of braveryâ€) is often\n> sufficient to enable a human to perform a new task to at least a reasonable degree of competence. Aside from pointing to\n> a conceptual limitation in our current NLP techniques, this adaptability has practical advantages â€“ it allows humans to\n> seamlessly mix together or switch between many tasks and skills, for example performing addition during a lengthy\n> dialogue. To be broadly useful, we would someday like our NLP systems to have this same fluidity and generality.\n\nIn order to achieve this, they build on the capacity of transformers. There is a race going on where the number of\nparameters in language models is growing almost as fast as transistors. Each increase has brought improvements to all\nsorts of NLP tasks, and there is evidence that they get better and better the larger they get.\n\n![](https://storage.googleapis.com/langkilde-se-images/b84e1a84-9ae6-4543-ac53-5d2dacc54bc5.jpeg)\n\nIn the paper the authors describe four different settings in which they want to evaluate their model. This is relevant\nto understand the title of the paper, and more importantly, when it works and not.\n\n![](https://storage.googleapis.com/langkilde-se-images/cda92869-531e-4abe-86fc-500439be5e45.jpeg)\n\nThe title of the paper refers to â€œFew-Shot Learnersâ€ as it is described in the image above. The model architecture they\nuse is basically the same as in several earlier papers such\nas â€œ[Language Models are Unsupervised Multitask Learner](https://arxiv.org/pdf/2005.14165v4.pdf)â€\nand â€œ[Improving Language Understanding by Generative Pre-Training](https://s3-us-west-2.amazonaws.com/openai-assets/research-covers/language-unsupervised/language_understanding_paper.pdf)â€ (\nthe latter is the paper that coins the term GPT, which is short for Generative Pre-Training). The following figure\ndescribes the basic idea:\n\n![](https://storage.googleapis.com/langkilde-se-images/eebb28a3-0257-47e4-a825-f7c070a7cfb8.jpeg)\n\nGPT uses a generative pre-training stage in which a language model learns language and then adds a supervised\nfine-tuning stage in which the pre-trained model is adapted to a target task. The amount of examples used defines the\ndegree of fine-tuning (zero, one, few, etc). The Transformer architecture serves as the backbone of this pre-training\nstage. Here is how the authors describe the setup:\n\n![](https://storage.googleapis.com/langkilde-se-images/1ec6417e-5d0e-4aaf-b676-c016961dbcdc.jpeg)\n\nSo, they are learning to predict words using Transformers. Notice the use of â€œunsupervised corpusâ€. Personally, I think\nthis is misleading. The corpus is unsupervised in the sense that no one explicitly labeled the meaning of words in the\ncorpus. But it is supervised in the sense that words have been put into sentences by humans, i.e. someone always needs\nto provide structure somehow.\n\nAnyway, since the model is trained on continuous text, and not for example questions and answers, they apply some tricks\nto get data into shape.\n\n![](https://storage.googleapis.com/langkilde-se-images/2af322d4-3070-4f82-b387-c0d8f1f6f785.jpeg)\n\nThis setup is improved on a bit for later versions of GPT, but GPT-3 follows the same pattern. They then feed these\nlearning beasts huge amounts of text:\n\n![](https://storage.googleapis.com/langkilde-se-images/acaf9b09-5825-4cee-894b-420c86132ca9.jpeg)\n\nThatâ€™s a lot of human knowledge right there. This is where the supervised learning part comes in. In order for GPT-3 to\nwork, we need to have access to enormous amounts of documented human knowledge. Whatever the model knows is a result of\nwhat is in these 300 billion tokens of knowledge. Fun fact: a challenge for the authors of the paper was to filter out\nall of the test data from this corpus since most data is somewhere on the internet. The crazy thing that happens when\nyou put this gigantic model to work is that it can generate long sequences of text that read as if written by a human.\nAnd all it needs is a few words to get started. For example, news article generation:\n\n![](https://storage.googleapis.com/langkilde-se-images/9e5c2644-f828-483a-a246-1ae840d89bdb.jpeg)\n\nTo evaluate they asked humans to determine if a news article was written by a human or by GPT-3. Results show that\nhumans have a pretty hard time distinguishing real from robot.\n\n![](https://storage.googleapis.com/langkilde-se-images/2e15223d-cc5b-4467-8fcd-a4610b33fab8.jpeg)\n\nSo how is this possible? By now you should have some idea. By training a huge language model on a huge corpus of text we\nget a model that learns how to interpret words based on their context. Using that model, and a few tokens to give the\nmodel a starting point, it can then predict suitable next words. The attention mechanism gives the model a strong\nâ€œmemoryâ€ that lets it keep track of context.\n\n### Multi-Modal Models\n\nA modality is the type of channel used to communicate such as through images or sound. Humans rely on multi-modal input\nin order to navigate the world. We hear, see and feel. This is an obvious source of inspiration for researchers. Before\nwe jump into state-of-the-art multi-modal models we will review how the pre-training concepts from GPT have been applied\nto visual data.\n\nThe first paper I recommend\nis â€œ[Learning Transferable Visual Models From Natural Language Supervision](https://arxiv.org/pdf/2103.00020.pdf)â€. This\npaper builds on the breakthroughs with autoregressive and masked language models and describes what the authors call\nCLIP (Contrastive Language-Image Pre-training).\n\n![](https://storage.googleapis.com/langkilde-se-images/d56e312d-73bc-40ff-aa7e-fb420a9ef75a.jpeg)\n\nThe idea behind the paper is to learn directly from raw text about images, rather than learn predefined object classes.\nTypically when training object detection models we define a set of classes and then proceed to label each object with\none of these classes. Besides being very tedious, this can also be limiting as not all objects fit into obvious classes.\nSo instead, the paper describes how to learn the connection between an image and its caption. CLIP is an efficient\nmethod of learning this that is similar to GPT that is able to predict the text snippet based on an image.\n\nMore recently, models like [DALLE2](https://openai.com/dall-e-2/) have become the darling of the internet for their\nability to generate realistic images and art from a natural language description. The mechanics of DALLE2 are described\nin the paper â€œ[Hierarchical Text-Conditional Image Generation with CLIP Latents](https://arxiv.org/pdf/2204.06125.pdf)â€.\nThe technique relies on a CLIP latent space but learns an inverted version of CLIP, i.e. a decoder (or â€œunClipâ€). The\nresulting decoder is a non-deterministic function that can generate images given a caption. The encoding/decoding\nprocess generates, similar to GANs, semantically similar images. An even cooler aspect is that you can semantically\nmodify images by moving in the direction of any encoded text vector. This image gives a high-level overview of the\nunClip process.\n\n![](https://storage.googleapis.com/langkilde-se-images/d4936576-92af-41bb-8b64-ba1ade253f61.jpeg)\n\nThe results are very, very cool. For example, you can naturally blend styles by interpolating the CLIP image embedding\nof different images and decoding the vectors.\n\n![](https://storage.googleapis.com/langkilde-se-images/c66ff7f4-12f7-4e26-bec9-2dca5490ebad.jpeg)\n\n![](https://storage.googleapis.com/langkilde-se-images/ade90f01-b3a0-4911-a263-026e21299558.jpeg)\n\nThe reason this sort of continuous interpolation is possible is that the images and text are both embedded in the same\nlatent space. That allows us to apply language-guided image manipulation. You can also write a text into a prompt and\nget an image back. The decoder is based on diffusion models to produce images conditioned on CLIP image embeddings and\noptionally text captions. In order to get high-resolution images, they train diffusion upsampler models. A few more\ntricks are applied to make results even better, but essentially itâ€™s CLIP encoding and then diffusion-based unClip. You\ncan find the details in the paper.\n\n### Conclusions\n\nSo what does all this cool progress mean for humans? Or for businesses that support teams training machine learning\nmodels? I think a few things are clear:\n\n* **Foundational models will be considered commodity infrastructure.** The huge, underlying language and image models\n  that are part of GPT and CLIP will be available from a few major companies like Google, Microsoft, Amazon, etc. At\n  least until these models can be trained at a reasonable cost. I donâ€™t think ML Engineers will train models the way we\n  have until now for much longer. Instead, they will leverage existing infrastructure.\n\n* **Foundational models do not mean we are on the brink of artificial general intelligence.** They are super cool, and\n  clearly, computers can now learn a lot of nuance in a robust way. But in my opinion, independent competency will\n  require combining these concepts with ideas from reinforcement learning and an ability to interact with our\n  surroundings. Personally, I think a robot will need a perception system based on some future, transformers-like\n  architecture (I expect we will find many clever abstractions in coming years) that learns from raw visual feeds and\n  connects that to a reward-based system (like Q-learning) to achieve some seeded goal _could_ result in seemingly\n  intelligent robots. Itâ€™s not pure science fiction anymore, but GPT-3 and DALLE2 do not mean humans are obsolete. Not\n  yet anyway.\n\n* **Whatever shitty opinions and biases are present in the foundational model will be there in the output.** The\n  internet is full of crap. That means there will be a lot of undesirable bias buried in these foundational models.\n  Uncovering such bias, and mitigating it, will be an important part of deploying models responsibly.\n\n* **ML Engineers will tune foundational models to specific applications using specific datasets.** Rather than build\n  huge datasets from scratch, ML Engineers will tune foundational models to specific use-cases. Humans are sloppy, so\n  the foundational models trained on all human knowledge will be full of mistakes and bad decisions. For autonomous\n  mobility specifically, I expect proprietary data to dominate for the time being, and that it is collected with the\n  intention of making GPT/CLIP-like few-shot learners possible for driving specific tasks. I assume all the big players\n  are working on something that essentially amounts to a generalized multi-modal model for driving. Leveraging\n  foundational models in this work will drastically reduce the amount of labeled data required since you can avoid\n  annotating things already mastered by some foundational models. It wonâ€™t be enough for releasing a safe product since\n  you still need to make sure that you do not have a lot of strange stuff in the foundational model, but it will lower\n  the cost of getting to the end goal a lot. Arguably, specialized ground-truth companies already provide this sort of\n  service by automating ground-truth production based on pooled datasets.\n\n* **Safety-critical applications will require detailed validation to find and stop bias and bad judgment.** Humans are\n  not going away when developing and validating safety-critical systems. If youâ€™ve read all of the papers linked above\n  you will see that these models make hilarious mistakes. Mistakes will be fewer with larger datasets and more\n  parameters, but they will still occur. Applying these powerful foundational models will require great attention to\n  detail for many years to come. For autonomous mobility, I think fine-tuning to various tasks and gathering data for an\n  ever-increasing operational design domain will be the challenge. Eventually, we will pack all the human knowledge\n  required to drive into a huge neural network. But until then, we have to do a lot of checking and measuring. Even\n  humans make mistakes after all.","src/content/blog/the-state-of-machine-learning-in-2022.md","7536d4c30bea923e",{"html":896,"metadata":897},"\u003Cp>Iâ€™ve been passionate about machine learning for as long as I can remember. I built my first robot more than 20 years ago\nout of Lego Mindstorm bricks. Itâ€™s been a wild ride since then, and the field keeps evolving. Running a business that is\nclosely tied to the progress of state-of-the-art machine learning means Iâ€™m trying to stay up to date with what is going\non. In this post, we will go through what I consider the most interesting breakthroughs recently. \u003Cstrong>We will cover\nembeddings, attention, transformers, and multi-modal models.\u003C/strong>\u003C/p>\n\u003Cp>\u003Cstrong>At the end of the post, I will share some thoughts on what this means for society and business.\u003C/strong> If you donâ€™t want\nall the technical details, you can skip to the end now. But I encourage you to actually try to understand the recent\nbreakthroughs. Otherwise, you will have a hard time determining what these breakthroughs mean for you and your business.\u003C/p>\n\u003Cp>\u003Cimg src=\"https://images.squarespace-cdn.com/content/v1/5c2b12dae17ba3d4ccb3bdfd/7c21fbc9-ca39-41b6-afb0-07b319d7f360/Screenshot+2022-04-20+at+11.03.01.png\" alt=\"DALLE2. Image generated by an algorithm based on caption provided by a human.\">\n\u003Cstrong>Caption:\u003C/strong> Teddy bears working on new AI research on the moon in the 1980s\u003C/p>\n\u003Ch3 id=\"learning-requires-efficient-abstractions\">Learning requires efficient abstractions\u003C/h3>\n\u003Cp>Machine learning, in my opinion, is about finding efficient abstractions that enable the robust interpretation of\ndiverse data. The â€œproblemâ€ with reality is that most things are rare. If you look too closely at each data point it\nappears unique. You have to â€œsquintâ€ to cope with all the information we are exposed to. Humans are great at this. We\nhalf-ass most data processing and make heavy use of prejudice in the name of efficiency. This ability has served us well\nin our effort to process diverse data in an energy-efficient way. We are optimized to minimize learning time and energy\nconsumption while maximizing procreation. It is less good if you want a consistent and fair evaluation of data. Humans\nare bad at consistency and fairness.\u003C/p>\n\u003Cp>Think of it this way: if we always considered each situation as a completely new situation based on minor changes we\nwould get exhausted. Instead, we remember previous situations weâ€™ve been in and abstract away the specific details. â€œOh,\nIâ€™m approaching an intersection now, I know there can be cars coming from different directions. Sure, it is a slightly\ndifferent intersection than before but I still have some idea of what might happen.â€\u003C/p>\n\u003Cp>The challenge for machine learning researchers is to figure out how to extract the most efficient abstractions. If they\nare too crude, the quality of output goes down. If they are too exact, learning becomes very, very expensive. I equate\nthese abstractions to â€œcommon senseâ€.\u003C/p>\n\u003Cp>Embeddings were my first real machine learning â€œmind-fuckâ€ experience. I still\nremember \u003Ca href=\"https://arxiv.org/pdf/1310.4546.pdf\">reading Mikolovs paper\u003C/a> the first time and realizing what a huge thing\nthe embedding concept was going to be. Itâ€™s so simple yet so elegant. I wonâ€™t spend much time on it here since itâ€™s old\nnews, but it still forms the foundation for so many things, so you better make sure you understand this concept. A good\nway to learn is to\nwatch \u003Ca href=\"https://developers.google.com/machine-learning/crash-course/embeddings/video-lecture#:~:text=An%20embedding%20is%20a%20relatively,like%20sparse%20vectors%20representing%20words.\">this presentation from Google\u003C/a>.\nLetâ€™s say we have 10.000 words and want to represent a word as a vector. One option would be to replace the word with a\nvector of dimension 10000 with all cells set to zero except the one representing our word. Problem is, you would get a\nlot of very large vectors with mostly zeros in them. Instead, we can create lower dimensional vectors representing each\nword. If you create these vectors based on the context in which words ocrrus in it turns they preserve semantic\nproperties and open up for using linear algebra on them in cool ways (like in the picture below). Learn about\nembeddings.\u003C/p>\n\u003Cp>\u003Cimg src=\"https://storage.googleapis.com/langkilde-se-images/672a00d7-ea8d-4c5f-a6ae-db9e50bd5cf6.jpeg\" alt=\"\">\u003C/p>\n\u003Ch3 id=\"attention-and-transformers\">Attention and Transformers\u003C/h3>\n\u003Cp>In recent years, the most influential paper in my opinion\nis â€œ\u003Ca href=\"https://arxiv.org/pdf/1706.03762v5.pdf\">Attention Is All You Need\u003C/a>â€ from the Brain at Google. This paper\ndemonstrated that attention mechanisms can replace\nboth \u003Ca href=\"https://en.wikipedia.org/wiki/Recurrent_neural_network\">recurrent\u003C/a>\nand \u003Ca href=\"https://en.wikipedia.org/wiki/Convolutional_neural_network\">convolutional\u003C/a> neural networks, while still both\nimproving results and lowering the cost of training. After years of just pushing the limits of RNNs and CNNs, a new\nparadigm emerged. RNNs had the downside that they did not allow for parallelized training as each new prediction was\npredicated on the previous prediction. Some tried to overcome this limitation\nby \u003Ca href=\"https://arxiv.org/pdf/1705.03122.pdf\">turning sequences into â€œimagesâ€\u003C/a> and then applying CNNs instead. The problem\nwith CNNs is that they have a hard time learning distance relationships as â€œsignal strengthâ€ diminishes with distance.\nEnter the Transformer.\u003C/p>\n\u003Cp>\u003Cimg src=\"https://storage.googleapis.com/langkilde-se-images/90d0d7dd-b1b3-47b8-b6af-34fda1c81d44.jpeg\" alt=\"\">\u003C/p>\n\u003Cp>The Transformer follows the overall architecture of \u003Ca href=\"https://arxiv.org/pdf/1406.1078.pdf\">encoder/decoders\u003C/a>.\nTransformers process sentences in the form of a sequence of embeddings that it learns during training. Each token in the\nsentence is represented by a vector (in the original paper they use 512-dim vectors)\nwith \u003Ca href=\"https://huggingface.co/blog/encoder-decoder\">positional encoding\u003C/a> added, i.e. the vector also indicates the\nposition of the word in the sentence. The Encoder learns a representation of the input data (encoding) based on which\nthe Decoder produces the target output. This pattern provides a dimensionality reduction step, which goes back to the\nidea of finding abstractions. Transformers only pass on the information necessary for decoding from the input to the\nencoding.\u003C/p>\n\u003Cp>\u003Cimg src=\"https://storage.googleapis.com/langkilde-se-images/e9b1de67-9316-4836-a63d-6b3841448607.jpeg\" alt=\"\">\u003C/p>\n\u003Cp>Both the Encoder and Decoder make use of \u003Cstrong>attention\u003C/strong>. So what is attention? The idea behind attention is to replace\nembeddings with \u003Cem>better\u003C/em> embeddings that also contain information about the context in which the word appears.\nUnderstanding how it works requires linear algebra. The easiest to understand\nis \u003Ca href=\"https://paperswithcode.com/method/scaled\">scaled dot-product attention\u003C/a>. Letâ€™s assume we have an input sentence\nX = [x_1â€¦x_n] where each word x is an embedding. Our goal is to replace the word x_n with a new vector y_n. We do this\nby summing over all the words in the sentence, with each word weighted by some number. The self-attention layer\nintroduces two matrices, W_Q and W_K by which we transform the words before we combine them. The interpretation of these\nmatrices is not obvious. We want to put numbers into these matrices so that the model considers the right context words\nwhen interpreting a specific word.\u003C/p>\n\u003Cp>\u003Cimg src=\"https://storage.googleapis.com/langkilde-se-images/b5261eb9-c7cc-4059-afd2-1fdd58566943.jpeg\" alt=\"\">\u003C/p>\n\u003Cp>Prof. Lennart Svensson \u003Ca href=\"https://www.youtube.com/watch?v=0SmNEp4zTpc\">has a great lecture explaining this\u003C/a>. We know that\nwords that are related cluster with respect cosine distance of their word embeddings. One way to interpret the W_K\nmatrix is that we need to select it so that it forms an identity matrix in relation to which the key vectors are\nidentical to the original word embeddings. The keys would preserve the original similarity between words at face value.\nIf we then select W_Q so that our new embedding points in the same direction as the specific words we want the model to\ncare about, their inner product will then be large.\u003C/p>\n\u003Cp>\u003Cimg src=\"https://storage.googleapis.com/langkilde-se-images/bb928c2c-bd19-4770-9a9d-576227ebcafb.jpeg\" alt=\"\">\u003C/p>\n\u003Cp>\u003Cstrong>I think of attention this way:\u003C/strong> attention means learning parameters that are used to create new embeddings for input\nwords that contain information about the context. All of the parameters that fill these matrices are learned\nsimultaneously. That means that embeddings and attention, along with all other parameters, are selected so that they\ntogether maximize the quality of the network. This gives the model enormous expressive capacity, at the price of a huge\nnumber of parameters and a huge cost of computation.\u003C/p>\n\u003Cp>Transformers use Multi-Head Attention which means that it uses multiple queries per word rather than just one. The\nreasoning is that words could have different meanings depending on context. The model uses these multi-headed attention\nmechanisms in multiple ways. One of these is referred to as â€œself-attentionâ€. The idea behind self-attention is that the\nword itself impacts its own meaning and that the most appropriate word embedding depends on the context. I wonâ€™t go\nthrough all of the details. The original Transformers paper has a nice illustration of the output weights of these\nattention heads for various sentences. As you can see from the first attention head, the weights\nresemble \u003Ca href=\"https://web.stanford.edu/~jurafsky/slp3/14.pdf\">dependency parsing\u003C/a>, which I guess is exactly the point.\u003C/p>\n\u003Cp>\u003Cimg src=\"https://storage.googleapis.com/langkilde-se-images/566ea5f4-f02c-4278-87c0-91fed6c2b592.jpeg\" alt=\"\">\u003C/p>\n\u003Cp>Anyway, this is just the first step of the Encoder block. We feed the input sentence as a set of vectors with positional\nencoding, and we get a set of weights back that describe how each token should be regarded based on the entire sentence.\u003C/p>\n\u003Cp>\u003Cimg src=\"https://storage.googleapis.com/langkilde-se-images/bd2aef82-55f2-4750-9751-0a5732653634.jpeg\" alt=\"\">\u003C/p>\n\u003Cp>We add residual connections that carry over previous embeddings to subsequent layers, i.e. we mix together the original\nembeddings with the information learned from the multi-head attention mechanism. Finally, we add some layer\nnormalization, and voila we have our basic Encoder block. The transformer then uses six of these stacked, with the\noutput from the last block serving as input to the Decoder.\u003C/p>\n\u003Cp>\u003Cimg src=\"https://storage.googleapis.com/langkilde-se-images/3aa7603f-cbd8-4b8d-9a5e-32486926925e.jpeg\" alt=\"\">\u003C/p>\n\u003Cp>The Decoder is similar to the Encoder. One major difference is that the attention mechanism is â€œmaskedâ€, which means it\ngets a gradually increased visibility of the input sentence. This makes sense since we cannot time travel. Another\ndifference is that it treats its most recent output as the last token of its input.\u003C/p>\n\u003Cp>\u003Cimg src=\"https://storage.googleapis.com/langkilde-se-images/8aa0a4d7-68a4-4a34-b258-b0e35daef331.jpeg\" alt=\"\">\u003C/p>\n\u003Cp>This kind of processing is called auto-regressive. A nice consequence of this is that the output can have a different\nlength than the input. The Decoder ultimately outputs a vector the size of our known vocabulary, and the softmax layer\nconverts that into a vector of probabilities. It might seem simple to then just pick the most probable word, but it\nturns out using something called beam search produces even better results. Anyway, the predicted word is fed back to the\ndecoder as the last part of the next decoder input. This process continues until we predict the end-of-sentence token.\u003C/p>\n\u003Cp>In the end, we have a construction that assumes no recurrence or convolutions when processing the input data. As long as\nwe can express our input as sequence data, we can apply this approach even in computer vision or reinforcement learning.\nThe core idea is to enrich the embeddings with features from the global context.\u003C/p>\n\u003Cp>If you want an even better explanation of all of this, I highly\nrecommend \u003Ca href=\"https://www.youtube.com/watch?v=0SmNEp4zTpc\">Prof. Lennart Svenssonâ€™s lecture\u003C/a>.\u003C/p>\n\u003Cp>\u003Cimg src=\"https://storage.googleapis.com/langkilde-se-images/b7b48715-f3a3-4959-8085-c48460b0f8ab.jpeg\" alt=\"\">\u003C/p>\n\u003Ch3 id=\"few-shot-learners-such-as-gpt-3\">Few-Shot Learners such as GPT-3\u003C/h3>\n\u003Cp>In May of 2020 researchers from OpenAI described the development of GPT-3 in the\npaper â€œ\u003Ca href=\"https://arxiv.org/pdf/2005.14165v4.pdf\">Language Models are Few-Shot Learners\u003C/a>â€. The big breakthrough in GPT-3\nis that it removes the need for huge task-specific labeled datasets in order to learn specific tasks, assuming analogous\ntasks are already represented in available language datasets (e.g. all of the internet). To quote from the paper:\u003C/p>\n\u003Cblockquote>\n\u003Cp>â€¦humans do not require large supervised datasets to learn most language tasks â€“ a brief directive in natural\nlanguage (e.g. â€œplease tell me if this sentence describes something happy or something sadâ€) or at most a tiny number of\ndemonstrations (e.g. â€œhere are two examples of people acting brave; please give a third example of braveryâ€) is often\nsufficient to enable a human to perform a new task to at least a reasonable degree of competence. Aside from pointing to\na conceptual limitation in our current NLP techniques, this adaptability has practical advantages â€“ it allows humans to\nseamlessly mix together or switch between many tasks and skills, for example performing addition during a lengthy\ndialogue. To be broadly useful, we would someday like our NLP systems to have this same fluidity and generality.\u003C/p>\n\u003C/blockquote>\n\u003Cp>In order to achieve this, they build on the capacity of transformers. There is a race going on where the number of\nparameters in language models is growing almost as fast as transistors. Each increase has brought improvements to all\nsorts of NLP tasks, and there is evidence that they get better and better the larger they get.\u003C/p>\n\u003Cp>\u003Cimg src=\"https://storage.googleapis.com/langkilde-se-images/b84e1a84-9ae6-4543-ac53-5d2dacc54bc5.jpeg\" alt=\"\">\u003C/p>\n\u003Cp>In the paper the authors describe four different settings in which they want to evaluate their model. This is relevant\nto understand the title of the paper, and more importantly, when it works and not.\u003C/p>\n\u003Cp>\u003Cimg src=\"https://storage.googleapis.com/langkilde-se-images/cda92869-531e-4abe-86fc-500439be5e45.jpeg\" alt=\"\">\u003C/p>\n\u003Cp>The title of the paper refers to â€œFew-Shot Learnersâ€ as it is described in the image above. The model architecture they\nuse is basically the same as in several earlier papers such\nas â€œ\u003Ca href=\"https://arxiv.org/pdf/2005.14165v4.pdf\">Language Models are Unsupervised Multitask Learner\u003C/a>â€\nand â€œ\u003Ca href=\"https://s3-us-west-2.amazonaws.com/openai-assets/research-covers/language-unsupervised/language_understanding_paper.pdf\">Improving Language Understanding by Generative Pre-Training\u003C/a>â€ (\nthe latter is the paper that coins the term GPT, which is short for Generative Pre-Training). The following figure\ndescribes the basic idea:\u003C/p>\n\u003Cp>\u003Cimg src=\"https://storage.googleapis.com/langkilde-se-images/eebb28a3-0257-47e4-a825-f7c070a7cfb8.jpeg\" alt=\"\">\u003C/p>\n\u003Cp>GPT uses a generative pre-training stage in which a language model learns language and then adds a supervised\nfine-tuning stage in which the pre-trained model is adapted to a target task. The amount of examples used defines the\ndegree of fine-tuning (zero, one, few, etc). The Transformer architecture serves as the backbone of this pre-training\nstage. Here is how the authors describe the setup:\u003C/p>\n\u003Cp>\u003Cimg src=\"https://storage.googleapis.com/langkilde-se-images/1ec6417e-5d0e-4aaf-b676-c016961dbcdc.jpeg\" alt=\"\">\u003C/p>\n\u003Cp>So, they are learning to predict words using Transformers. Notice the use of â€œunsupervised corpusâ€. Personally, I think\nthis is misleading. The corpus is unsupervised in the sense that no one explicitly labeled the meaning of words in the\ncorpus. But it is supervised in the sense that words have been put into sentences by humans, i.e. someone always needs\nto provide structure somehow.\u003C/p>\n\u003Cp>Anyway, since the model is trained on continuous text, and not for example questions and answers, they apply some tricks\nto get data into shape.\u003C/p>\n\u003Cp>\u003Cimg src=\"https://storage.googleapis.com/langkilde-se-images/2af322d4-3070-4f82-b387-c0d8f1f6f785.jpeg\" alt=\"\">\u003C/p>\n\u003Cp>This setup is improved on a bit for later versions of GPT, but GPT-3 follows the same pattern. They then feed these\nlearning beasts huge amounts of text:\u003C/p>\n\u003Cp>\u003Cimg src=\"https://storage.googleapis.com/langkilde-se-images/acaf9b09-5825-4cee-894b-420c86132ca9.jpeg\" alt=\"\">\u003C/p>\n\u003Cp>Thatâ€™s a lot of human knowledge right there. This is where the supervised learning part comes in. In order for GPT-3 to\nwork, we need to have access to enormous amounts of documented human knowledge. Whatever the model knows is a result of\nwhat is in these 300 billion tokens of knowledge. Fun fact: a challenge for the authors of the paper was to filter out\nall of the test data from this corpus since most data is somewhere on the internet. The crazy thing that happens when\nyou put this gigantic model to work is that it can generate long sequences of text that read as if written by a human.\nAnd all it needs is a few words to get started. For example, news article generation:\u003C/p>\n\u003Cp>\u003Cimg src=\"https://storage.googleapis.com/langkilde-se-images/9e5c2644-f828-483a-a246-1ae840d89bdb.jpeg\" alt=\"\">\u003C/p>\n\u003Cp>To evaluate they asked humans to determine if a news article was written by a human or by GPT-3. Results show that\nhumans have a pretty hard time distinguishing real from robot.\u003C/p>\n\u003Cp>\u003Cimg src=\"https://storage.googleapis.com/langkilde-se-images/2e15223d-cc5b-4467-8fcd-a4610b33fab8.jpeg\" alt=\"\">\u003C/p>\n\u003Cp>So how is this possible? By now you should have some idea. By training a huge language model on a huge corpus of text we\nget a model that learns how to interpret words based on their context. Using that model, and a few tokens to give the\nmodel a starting point, it can then predict suitable next words. The attention mechanism gives the model a strong\nâ€œmemoryâ€ that lets it keep track of context.\u003C/p>\n\u003Ch3 id=\"multi-modal-models\">Multi-Modal Models\u003C/h3>\n\u003Cp>A modality is the type of channel used to communicate such as through images or sound. Humans rely on multi-modal input\nin order to navigate the world. We hear, see and feel. This is an obvious source of inspiration for researchers. Before\nwe jump into state-of-the-art multi-modal models we will review how the pre-training concepts from GPT have been applied\nto visual data.\u003C/p>\n\u003Cp>The first paper I recommend\nis â€œ\u003Ca href=\"https://arxiv.org/pdf/2103.00020.pdf\">Learning Transferable Visual Models From Natural Language Supervision\u003C/a>â€. This\npaper builds on the breakthroughs with autoregressive and masked language models and describes what the authors call\nCLIP (Contrastive Language-Image Pre-training).\u003C/p>\n\u003Cp>\u003Cimg src=\"https://storage.googleapis.com/langkilde-se-images/d56e312d-73bc-40ff-aa7e-fb420a9ef75a.jpeg\" alt=\"\">\u003C/p>\n\u003Cp>The idea behind the paper is to learn directly from raw text about images, rather than learn predefined object classes.\nTypically when training object detection models we define a set of classes and then proceed to label each object with\none of these classes. Besides being very tedious, this can also be limiting as not all objects fit into obvious classes.\nSo instead, the paper describes how to learn the connection between an image and its caption. CLIP is an efficient\nmethod of learning this that is similar to GPT that is able to predict the text snippet based on an image.\u003C/p>\n\u003Cp>More recently, models like \u003Ca href=\"https://openai.com/dall-e-2/\">DALLE2\u003C/a> have become the darling of the internet for their\nability to generate realistic images and art from a natural language description. The mechanics of DALLE2 are described\nin the paper â€œ\u003Ca href=\"https://arxiv.org/pdf/2204.06125.pdf\">Hierarchical Text-Conditional Image Generation with CLIP Latents\u003C/a>â€.\nThe technique relies on a CLIP latent space but learns an inverted version of CLIP, i.e. a decoder (or â€œunClipâ€). The\nresulting decoder is a non-deterministic function that can generate images given a caption. The encoding/decoding\nprocess generates, similar to GANs, semantically similar images. An even cooler aspect is that you can semantically\nmodify images by moving in the direction of any encoded text vector. This image gives a high-level overview of the\nunClip process.\u003C/p>\n\u003Cp>\u003Cimg src=\"https://storage.googleapis.com/langkilde-se-images/d4936576-92af-41bb-8b64-ba1ade253f61.jpeg\" alt=\"\">\u003C/p>\n\u003Cp>The results are very, very cool. For example, you can naturally blend styles by interpolating the CLIP image embedding\nof different images and decoding the vectors.\u003C/p>\n\u003Cp>\u003Cimg src=\"https://storage.googleapis.com/langkilde-se-images/c66ff7f4-12f7-4e26-bec9-2dca5490ebad.jpeg\" alt=\"\">\u003C/p>\n\u003Cp>\u003Cimg src=\"https://storage.googleapis.com/langkilde-se-images/ade90f01-b3a0-4911-a263-026e21299558.jpeg\" alt=\"\">\u003C/p>\n\u003Cp>The reason this sort of continuous interpolation is possible is that the images and text are both embedded in the same\nlatent space. That allows us to apply language-guided image manipulation. You can also write a text into a prompt and\nget an image back. The decoder is based on diffusion models to produce images conditioned on CLIP image embeddings and\noptionally text captions. In order to get high-resolution images, they train diffusion upsampler models. A few more\ntricks are applied to make results even better, but essentially itâ€™s CLIP encoding and then diffusion-based unClip. You\ncan find the details in the paper.\u003C/p>\n\u003Ch3 id=\"conclusions\">Conclusions\u003C/h3>\n\u003Cp>So what does all this cool progress mean for humans? Or for businesses that support teams training machine learning\nmodels? I think a few things are clear:\u003C/p>\n\u003Cul>\n\u003Cli>\n\u003Cp>\u003Cstrong>Foundational models will be considered commodity infrastructure.\u003C/strong> The huge, underlying language and image models\nthat are part of GPT and CLIP will be available from a few major companies like Google, Microsoft, Amazon, etc. At\nleast until these models can be trained at a reasonable cost. I donâ€™t think ML Engineers will train models the way we\nhave until now for much longer. Instead, they will leverage existing infrastructure.\u003C/p>\n\u003C/li>\n\u003Cli>\n\u003Cp>\u003Cstrong>Foundational models do not mean we are on the brink of artificial general intelligence.\u003C/strong> They are super cool, and\nclearly, computers can now learn a lot of nuance in a robust way. But in my opinion, independent competency will\nrequire combining these concepts with ideas from reinforcement learning and an ability to interact with our\nsurroundings. Personally, I think a robot will need a perception system based on some future, transformers-like\narchitecture (I expect we will find many clever abstractions in coming years) that learns from raw visual feeds and\nconnects that to a reward-based system (like Q-learning) to achieve some seeded goal \u003Cem>could\u003C/em> result in seemingly\nintelligent robots. Itâ€™s not pure science fiction anymore, but GPT-3 and DALLE2 do not mean humans are obsolete. Not\nyet anyway.\u003C/p>\n\u003C/li>\n\u003Cli>\n\u003Cp>\u003Cstrong>Whatever shitty opinions and biases are present in the foundational model will be there in the output.\u003C/strong> The\ninternet is full of crap. That means there will be a lot of undesirable bias buried in these foundational models.\nUncovering such bias, and mitigating it, will be an important part of deploying models responsibly.\u003C/p>\n\u003C/li>\n\u003Cli>\n\u003Cp>\u003Cstrong>ML Engineers will tune foundational models to specific applications using specific datasets.\u003C/strong> Rather than build\nhuge datasets from scratch, ML Engineers will tune foundational models to specific use-cases. Humans are sloppy, so\nthe foundational models trained on all human knowledge will be full of mistakes and bad decisions. For autonomous\nmobility specifically, I expect proprietary data to dominate for the time being, and that it is collected with the\nintention of making GPT/CLIP-like few-shot learners possible for driving specific tasks. I assume all the big players\nare working on something that essentially amounts to a generalized multi-modal model for driving. Leveraging\nfoundational models in this work will drastically reduce the amount of labeled data required since you can avoid\nannotating things already mastered by some foundational models. It wonâ€™t be enough for releasing a safe product since\nyou still need to make sure that you do not have a lot of strange stuff in the foundational model, but it will lower\nthe cost of getting to the end goal a lot. Arguably, specialized ground-truth companies already provide this sort of\nservice by automating ground-truth production based on pooled datasets.\u003C/p>\n\u003C/li>\n\u003Cli>\n\u003Cp>\u003Cstrong>Safety-critical applications will require detailed validation to find and stop bias and bad judgment.\u003C/strong> Humans are\nnot going away when developing and validating safety-critical systems. If youâ€™ve read all of the papers linked above\nyou will see that these models make hilarious mistakes. Mistakes will be fewer with larger datasets and more\nparameters, but they will still occur. Applying these powerful foundational models will require great attention to\ndetail for many years to come. For autonomous mobility, I think fine-tuning to various tasks and gathering data for an\never-increasing operational design domain will be the challenge. Eventually, we will pack all the human knowledge\nrequired to drive into a huge neural network. But until then, we have to do a lot of checking and measuring. Even\nhumans make mistakes after all.\u003C/p>\n\u003C/li>\n\u003C/ul>",{"headings":898,"localImagePaths":914,"remoteImagePaths":915,"frontmatter":916,"imagePaths":917},[899,902,905,908,911],{"depth":24,"slug":900,"text":901},"learning-requires-efficient-abstractions","Learning requires efficient abstractions",{"depth":24,"slug":903,"text":904},"attention-and-transformers","Attention and Transformers",{"depth":24,"slug":906,"text":907},"few-shot-learners-such-as-gpt-3","Few-Shot Learners such as GPT-3",{"depth":24,"slug":909,"text":910},"multi-modal-models","Multi-Modal Models",{"depth":24,"slug":912,"text":913},"conclusions","Conclusions",[],[],{"pubDate":891,"title":890},[],"the-state-of-machine-learning-in-2022.md","the-problem-with-ai-will-not-be-iq-it-will-be-immortality",{"id":919,"data":921,"body":924,"filePath":925,"digest":926,"rendered":927,"legacyId":941},{"title":922,"pubDate":923},"The problem with AI will not be IQ, it will be immortality","2024-04-07","Don Valentine, the legendary founder of Sequoia Capital, said his most significant advantage as a VC was **knowing the\nfuture**. Thatâ€™s both a trivial and profound observation. Of course, knowing the future would be a superpower. Even\nmildly ambitious people could get rich and powerful if they consistently knew the future.\n\nRight now, there is a considerable discussion about the impact of AI. Some throw around statements like, â€œWe will have\nAI as capable as humans in just a few years!â€ Letâ€™s combine Donâ€™s realization of the value of knowing the future with\nthoughts about the possible consequences of super-human AI. These thoughts continue my post\nabout [untangling skill and luck when building a business](https://langkilde.se/post/2024-03-27-untangling-luck-and-skill-in-business).\nMy recent post concluded that human intelligence can help improve the odds of creating a great company, but there is so\nmuch randomness involved that outlier outcomes are still, to a large degree, the result of luck.\n\n### What Would an AI With 10x Human Intelligence Achieve?\n\nLetâ€™s imagine we created an artificial super-entrepreneur with an IQ of 1500, i.e., 10x, a human genius. How much could\nsuch a system increase the odds of building a successful company? Would it generate success after success after success?\nHere are some thoughts:\n\n* **Reality is a dynamic, multi-agent game with tons of noise.** Optimizing behavior in such an environment is much more\n  complex than in a static world. The actions of one agent influence the actions of other agents. The environment\n  changes constantly. Observations about the world are lossy approximations at best.\n\n* **The financial world is long-term growing but short-term zero-sum.** Over a year or two, there is only so much value\n  to capture in any market. The existence of one super-entrepreneur might consolidate a market, but the moment there is\n  more than one, there will be competition. Markets are created or expanded through innovation; then, they are rapidly\n  captured. Some markets grow for a long time (the internet, smartphones, etc.), but eventually, they saturate. Growth\n  requires an underlying productivity increase to support the increased financial value, like the way the internet\n  lowers transaction costs, and smartphones further accelerate the same process.\n\n* **Long-term modeling of markets is very, very hard.** Was there enough information in the 1990s to predict Nvidiaâ€™s\n  meteoric rise in market cap in 2023-2024? Of course not. There are countless alternative timelines in which a subtly\n  different chip architecture becomes the dominant. There are countless other timelines in which AI development took a\n  different path or we got unexpected breakthroughs in some other technology, like quantum computing. Financial quants\n  have tried to predict the future to make money for decades. Even the best in the game, like Renaissance, have realized\n  there are limits to their power (their fund cannot grow beyond $5B, or it starts to move the market).\n\n* **The marginal cost of predicting the future increases exponentially.** We could predict the local future for a while,\n  but the more significant the scope and the longer the time frame, the harder it gets. The more randomness is\n  aggregated.\n\n* **Compound interest is one of the few things we can predict.** Most super-successful financial players focus on\n  compounding value rather than making lucky bets. Warren Buffet runs the opposite of a VC. He does not like gambling.\n  He does not like leverage. He wants his money to compound steadily. In such a universe, stability is the goal. Not\n  disruption. Not change. For people with money, change is the enemy, and compounding interest is the goal. For people\n  without money, disruption is the path to getting money.\n\n* **The key to overcoming volatility is buffering enough so you can average out.** On average, assets are rationally\n  priced. In the short term, they can deviate. With a lot of change, deviations can persist for a long time. Benjamin\n  Graham, the legendary investor and mentor of Warren Buffet, is famous for saying: â€œIn the short-term, the market is a\n  voting machine, but in the long-term, it is a weighing machine.\" If you take risks, make sure to have enough buffer to\n  ride out temporary volatility. Sometimes, all it takes to succeed is to be the only one still playing.\n\n### Immortality Over Intelligence\n\n**Based on all of this, my conclusion is that a (presumably immortal) super-entrepreneur would play the ultimate long\ngame.** It would realize it cannot reliably manifest hit after hit in the short term. Instead, it would establish one\ncash machine after another in relatively low-risk domains and **aggregate and compound**. It might place high-risk bets\nnow and then: some would work, but most would not. Over 100 years, it would be rich. Over 200 years, it would probably\ncontrol the world. Humans dislike this strategy because they want to get rich fast. Life is too short. I think a\nsuper-human AI would look at humans and say: â€œ _Oh, you short-term thinking, short-lived little meat bags. You wonâ€™t\neven realize Iâ€™m winning until itâ€™s too late._ â€\n\n**I donâ€™t think the problem with AI will be IQ;** **I think it will be immortality.** Itâ€™s a good thing humans die. It\nmakes room for the next generation. In the same way, inheritance tax breaks legacy wealth and makes room for new\nplayers. Or anti-trust law breaks up monopolies.\n\n**Always play the long game.**","src/content/blog/the-problem-with-ai-will-not-be-iq-it-will-be-immortality.md","febf8d7d2050fc41",{"html":928,"metadata":929},"\u003Cp>Don Valentine, the legendary founder of Sequoia Capital, said his most significant advantage as a VC was \u003Cstrong>knowing the\nfuture\u003C/strong>. Thatâ€™s both a trivial and profound observation. Of course, knowing the future would be a superpower. Even\nmildly ambitious people could get rich and powerful if they consistently knew the future.\u003C/p>\n\u003Cp>Right now, there is a considerable discussion about the impact of AI. Some throw around statements like, â€œWe will have\nAI as capable as humans in just a few years!â€ Letâ€™s combine Donâ€™s realization of the value of knowing the future with\nthoughts about the possible consequences of super-human AI. These thoughts continue my post\nabout \u003Ca href=\"https://langkilde.se/post/2024-03-27-untangling-luck-and-skill-in-business\">untangling skill and luck when building a business\u003C/a>.\nMy recent post concluded that human intelligence can help improve the odds of creating a great company, but there is so\nmuch randomness involved that outlier outcomes are still, to a large degree, the result of luck.\u003C/p>\n\u003Ch3 id=\"what-would-an-ai-with-10x-human-intelligence-achieve\">What Would an AI With 10x Human Intelligence Achieve?\u003C/h3>\n\u003Cp>Letâ€™s imagine we created an artificial super-entrepreneur with an IQ of 1500, i.e., 10x, a human genius. How much could\nsuch a system increase the odds of building a successful company? Would it generate success after success after success?\nHere are some thoughts:\u003C/p>\n\u003Cul>\n\u003Cli>\n\u003Cp>\u003Cstrong>Reality is a dynamic, multi-agent game with tons of noise.\u003C/strong> Optimizing behavior in such an environment is much more\ncomplex than in a static world. The actions of one agent influence the actions of other agents. The environment\nchanges constantly. Observations about the world are lossy approximations at best.\u003C/p>\n\u003C/li>\n\u003Cli>\n\u003Cp>\u003Cstrong>The financial world is long-term growing but short-term zero-sum.\u003C/strong> Over a year or two, there is only so much value\nto capture in any market. The existence of one super-entrepreneur might consolidate a market, but the moment there is\nmore than one, there will be competition. Markets are created or expanded through innovation; then, they are rapidly\ncaptured. Some markets grow for a long time (the internet, smartphones, etc.), but eventually, they saturate. Growth\nrequires an underlying productivity increase to support the increased financial value, like the way the internet\nlowers transaction costs, and smartphones further accelerate the same process.\u003C/p>\n\u003C/li>\n\u003Cli>\n\u003Cp>\u003Cstrong>Long-term modeling of markets is very, very hard.\u003C/strong> Was there enough information in the 1990s to predict Nvidiaâ€™s\nmeteoric rise in market cap in 2023-2024? Of course not. There are countless alternative timelines in which a subtly\ndifferent chip architecture becomes the dominant. There are countless other timelines in which AI development took a\ndifferent path or we got unexpected breakthroughs in some other technology, like quantum computing. Financial quants\nhave tried to predict the future to make money for decades. Even the best in the game, like Renaissance, have realized\nthere are limits to their power (their fund cannot grow beyond $5B, or it starts to move the market).\u003C/p>\n\u003C/li>\n\u003Cli>\n\u003Cp>\u003Cstrong>The marginal cost of predicting the future increases exponentially.\u003C/strong> We could predict the local future for a while,\nbut the more significant the scope and the longer the time frame, the harder it gets. The more randomness is\naggregated.\u003C/p>\n\u003C/li>\n\u003Cli>\n\u003Cp>\u003Cstrong>Compound interest is one of the few things we can predict.\u003C/strong> Most super-successful financial players focus on\ncompounding value rather than making lucky bets. Warren Buffet runs the opposite of a VC. He does not like gambling.\nHe does not like leverage. He wants his money to compound steadily. In such a universe, stability is the goal. Not\ndisruption. Not change. For people with money, change is the enemy, and compounding interest is the goal. For people\nwithout money, disruption is the path to getting money.\u003C/p>\n\u003C/li>\n\u003Cli>\n\u003Cp>\u003Cstrong>The key to overcoming volatility is buffering enough so you can average out.\u003C/strong> On average, assets are rationally\npriced. In the short term, they can deviate. With a lot of change, deviations can persist for a long time. Benjamin\nGraham, the legendary investor and mentor of Warren Buffet, is famous for saying: â€œIn the short-term, the market is a\nvoting machine, but in the long-term, it is a weighing machine.â€ If you take risks, make sure to have enough buffer to\nride out temporary volatility. Sometimes, all it takes to succeed is to be the only one still playing.\u003C/p>\n\u003C/li>\n\u003C/ul>\n\u003Ch3 id=\"immortality-over-intelligence\">Immortality Over Intelligence\u003C/h3>\n\u003Cp>\u003Cstrong>Based on all of this, my conclusion is that a (presumably immortal) super-entrepreneur would play the ultimate long\ngame.\u003C/strong> It would realize it cannot reliably manifest hit after hit in the short term. Instead, it would establish one\ncash machine after another in relatively low-risk domains and \u003Cstrong>aggregate and compound\u003C/strong>. It might place high-risk bets\nnow and then: some would work, but most would not. Over 100 years, it would be rich. Over 200 years, it would probably\ncontrol the world. Humans dislike this strategy because they want to get rich fast. Life is too short. I think a\nsuper-human AI would look at humans and say: â€œ \u003Cem>Oh, you short-term thinking, short-lived little meat bags. You wonâ€™t\neven realize Iâ€™m winning until itâ€™s too late.\u003C/em> â€\u003C/p>\n\u003Cp>\u003Cstrong>I donâ€™t think the problem with AI will be IQ;\u003C/strong> \u003Cstrong>I think it will be immortality.\u003C/strong> Itâ€™s a good thing humans die. It\nmakes room for the next generation. In the same way, inheritance tax breaks legacy wealth and makes room for new\nplayers. Or anti-trust law breaks up monopolies.\u003C/p>\n\u003Cp>\u003Cstrong>Always play the long game.\u003C/strong>\u003C/p>",{"headings":930,"localImagePaths":937,"remoteImagePaths":938,"frontmatter":939,"imagePaths":940},[931,934],{"depth":24,"slug":932,"text":933},"what-would-an-ai-with-10x-human-intelligence-achieve","What Would an AI With 10x Human Intelligence Achieve?",{"depth":24,"slug":935,"text":936},"immortality-over-intelligence","Immortality Over Intelligence",[],[],{"pubDate":923,"title":922},[],"the-problem-with-ai-will-not-be-iq-it-will-be-immortality.md","untangling-luck-and-skill-in-business",{"id":942,"data":944,"body":947,"filePath":948,"digest":949,"rendered":950,"legacyId":979},{"title":945,"pubDate":946},"Untangling Luck and Skill in Business","2024-03-27","**Letâ€™s be honest: Life is pretty random.** A lot of things are out of your control. Not being in control is hard for\npassionate people with a high internal locus of control. Adverse outcomes are physically painful for me. I don't worry,\nbut I **hate** failing. Since I think most outcomes in my life result from my actions, I take adverse outcomes very\npersonally. If I make a mistake, pain is helpful. It helps me learn fast. But often, the outcome is simply the result of\nbad luck; in those cases, pain is a waste of time. Reversely, itâ€™s humbling to realize that outlier success also\nrequires a lot of luck.\n\n**The more abstract and long-term oriented my work becomes, the more complex it gets to untangle skill and luck.** To\ncope with successes and setbacks, I spend time on trying to separate different factors. Here is an attempt to sort out\nthe following aspects:\n\n1. What it means to be skilled versus lucky\n\n2. What it takes to create and capture value\n\n3. What the primary sources of randomness are\n\n### What Does It Mean to Be Skilled?\n\nI think skill combines IQ, training, experience, communication, determination,\nnetwork, and judgment. You could probably list ten other things, but these are the big ones. Skill is the ability to\nimprove the odds of successful outcomes.\n\n![](https://storage.googleapis.com/langkilde-se-images/a58b069d-d898-457b-b0d8-9076d7076b6c.jpeg)\n\n**Unfortunately, we cannot do much about our IQ.** Weâ€™re born with the brain we get. We can, however, influence most of\nthe rest.\n\n**Training** yourself to apply a systematic, logical approach to exploring, understanding, and acquiring new knowledge\nis incredibly valuable. In my experience, the most powerful thing you can do is to learn about â€œstructures and\nframeworks.â€ Mathematics is a collection of structures and frameworks. It teaches you ways to write down assumptions and\nderive conclusions. Initially, math feels like â€œjust learning rules,â€ but eventually, once those rules are memorized,\nitâ€™s about learning ways to reason.\n\nGaining **Experience** is the process of creating and updating beliefs with new evidence. If training provides\nframeworks, experience gathers observations to estimate probabilities. The more experience we have, the better we know\nwhat to expect. As the world changes, existing experiences become outdated. This is the opportunity young people and\ncompanies have to create new value.\n\n**Communication** is the ability to convey information in an engaging and understandable way. Great leaders are\ntypically also great communicators. They can simplify complex situations and communicate what matters. Noise is the\nenemy of focused action. The world gets complex fast if we let it. Excellent communication can significantly improve\nyour probability of success.\n\n**Determination** is the ability to keep going. It requires a deep belief in oneself. The most successful people in the\nworld believe in themselves almost to the point of delusion. Innovation is to do something before it is obvious. There\nwill not be enough data. Others will doubt you. Managing morale in the face of uncertainty is a critical skill. The\ntricky thing for most people is to balance determination with self-awareness and open-mindedness. Being both stubborn\nand open-minded is a contradiction. Yet, that is what you need to master. By thinking from the first principle and\nrejecting outdated social structures, you can channel your determination toward overcoming the most critical obstacles.\nYou cannot fight the laws of nature, but you must believe everything else can be changed. You need to feel like you can\nbend the world to your will. Most people donâ€™t even try. They accept that things are the way they are. Determination is\nthe opposite of self-doubt. It is the opposite of giving up too early. It means you push hard for an extended time.\nDetermination is a skill.\n\n**Network** is a person's ability to build and maintain relationships. Itâ€™s impossible to change the world on your own.\nYou need a strong network of other skilled people to overcome the critical obstacles you will face. You need great\npeople in your corner. Investing early and patiently in your network provides tremendous, long-term value. The\ndifference between success and failure can come down to making that _one call_ at the right time.\n\n**Judgment** involves making decisions based on sound principles and values. It means distinguishing between right and\nwrong and acting accordingly. Integrity is the ability to hold oneself to a consistent set of ethical principles and do\nthe right thing even when it is inconvenient. It requires self-awareness and reflection to avoid bias and\ninconsistencies.\n\n### What Does It Mean to Be Lucky?\n\nTo be lucky is to benefit from favorable circumstances that occur by chance rather\nthan through one's actions. If you place a bet with 10/1 odds and win, you are lucky. The worse the odds, the luckier\nyou are if you win.\n\n![](https://storage.googleapis.com/langkilde-se-images/f0d6e49a-0c0f-49de-8064-6be6429c90f8.jpeg)\n\n**Untangling skill and luck requires an understanding of:**\n\n* The available set of potential sequences of actions (plans and strategies)\n\n* Probability of a favorable outcome for each sequence of actions (probabilities)\n\n* The ability to rapidly adapt to the arrival of new information (robustness)\n\n### Building a Business Is a Bundle of Bets\n\nYou bet on a market, a trend, a technology, a founder, a CEO, a team,\nan obstacle, a solution, a business model, a plan, a brand, and more. All these different factors are rolled up into one\ngiant bet. Entrepreneurs, executives, and investors are paid on the assumption that they can untangle all the bets and\nimprove the odds. Their IQ, training, experience, communication, determination, network, and judgment should give them\nan edge.\n\n**When I examine my performance as a business leader, Iâ€™m trying to ask myself: Was this outcome the result of skill or\nrandom events?** Did I apply my skill to estimate and influence the distribution of possible outcomes? Could I have\nincreased the odds of a more favorable outcome by better analysis or different actions? Itâ€™s essential in this context\nto factor in time and available information. Retroactively evaluating a decision is only fair with the same time\nconstraints and information. Hindsight is, after all, 20/20.\n\n**A skilled person should, in most cases, be able to estimate and influence the probability distribution of possible\noutcomes in a specific situation.** Question is, how much? Knowing the distribution of potential outcomes allows you to\nmake an informed decision when taking action. If the problem is familiar and the world is stable, an experienced and\nwell-trained person should be able to ensure a decent outcome or at least help you make a well-informed bet. However, it\nis harder to make a skill-based decision in novel situations. There arenâ€™t enough prior observations to estimate\nprobability distributions. Outlier outcomes are, by nature, unlikely. They are most often the result of someone placing\na big bet on an unlikely event and winning. Data supports this as the correlation between income and intelligence is\nmuch stronger than the correlation between net worth and intelligence.\n\n![](https://storage.googleapis.com/langkilde-se-images/1fd2a726-bb07-4263-bfab-da1a2c5c7287.jpeg)\n\n[Source](https://gwern.net/doc/iq/ses/2007-zagorsky.pdf)\n\nAnother way to put this is: Can you â€œmanufacture luckâ€ when building a business? I think you can, to a point. There are\ndefinitely powerful frameworks that can improve your odds.\n\n### Bold Visions and Critical Obstacles\n\nA critical factor necessary to create an outlier outcome is to have a bold vision and overcome huge obstacles. Iâ€™m\ninspired by The Crux, a book by Richard Rumelt, one of the world's leading authorities on strategy. The book\nsuggests how to identify problems that are valuable to solve. His advice is simple: Focus your energy on the most\ncritical obstacle you can overcome to accelerate the world toward your vision. By definition, a critical obstacle is\nunsolved in a satisfactory way. If it already has a solution, itâ€™s not a critical obstacle.\n\n![](https://storage.googleapis.com/langkilde-se-images/fbd3e874-129f-4844-b104-f327048f9513.jpeg)\n\n**You need to decide what your vision is.** No one can tell you your purpose; thatâ€™s up to you. I like to imagine what I\nwant the world to look like in 10 years, 50 years, or 100 years. Then I work my way backward: What are the most critical\nobstacles to overcome to accelerate the world toward my vision? You can get to work once you find the intersection\nbetween our current knowledge, existing technologies, and the most immediate obstacle. My favorite quote from Gibson is:\nâ€œThe future is already here, just unevenly distributed.â€ My takeaway is that what is â€˜table stakesâ€™ in 10 years is\nprobably already available today in â€˜pockets of the future.â€™ The more universal the vision and the more significant the\nobstacle, the more value you create if you overcome the obstacle. If you solve a meaningful problem, skilled people will\nwant to help you.\n\n**Pursuing a bold vision and working to overcome a huge obstacle means you invite randomness into your life. Solutions\nto overcome critical obstacles do not appear in a structured, predictable way.** Skilled, prolific people can come up\nwith more and better ideas, but they cannot just â€˜manifest solutionsâ€™ out of thin air. It takes persistence and\nexperimentation to expand into the unknown. Inventing new things is extremely hard work that doesnâ€™t necessarily produce\nthe results you want. In my experience, all you can do is â€˜trust the process.â€™ Create the most powerful platform you can\nfor experimentation (team, resources, capital, etc.) and aim to address the most critical obstacles between you and your\nvision for as long as you can. The more capital you can access to fund your platform for experimentation and the more\nprolific, skilled people you can hire, the higher the probability of overcoming critical obstacles. For example, Nobel\nlaureates publish 5x more than average scientists during their early careers. Itâ€™s not enough to be smart; you must also\nbe prolific.\n\n**To make commercial product innovation even more complex, it depends on other people, i.e., your customers.** A\nsufficiently large group of customers must agree that they face the critical obstacle you focus on. And they must agree\nwith you that your solution overcomes their obstacle in a satisfying way. And they must be in a position to pay for your\nsolution. Most companies fail to launch valuable products because they fail to validate with customers that the obstacle\nis critical.\n\n### The Complexity of Customer Validation\n\n**I think customer feedback is the most confusing aspect of entrepreneurship.** During times of major disruption, when\nnew technology emerges that solves problems in an unseen way, social structures become a major adoption factor. Maybe\nyour customer is scared of change and unwilling to risk their current status quo? Or perhaps they want to buy, but\nmanagement will not approve it? Or maybe the buyer's status is threatened by this new technology? Or does your solution\nrisk replacing existing teams? Or maybe customers are just so invested in their current way of working that they want to\navoid disrupting that? This feedback can easily be confused with â€œyou are not overcoming a critical obstacle.â€ You might\nhave a way to overcome a critical obstacle; your customer may not realize or appreciate it. But they could also be\nright, and you could be wrong. Or you are both right; the timing just isnâ€™t there. There is a big graveyard of startups\nwith products overcoming obstacles that arenâ€™t critical. This is a significant source of randomness when building a\nbusiness. Not only are you betting you can overcome a critical obstacle, but you are also betting there will be demand\nfor your solution. There is a saying that \"first-time founders focus on products, second-time founders focus on\ndistribution.\"\n\n### The Role of Determination\n\nOutlier outcomes require placing high-conviction bets before it is\nobvious and being right. I quote from earlier:\n\n> Innovation is to do something before it is obvious. There will not be enough data. Others will doubt you. Managing\n> morale in the face of uncertainty is a critical skill. The tricky thing for most people is to balance determination\n> with\n> self-awareness and open-mindedness. Being both stubborn and open-minded is a contradiction. Yet, that is what you need\n> to master.\n\nAt this point, we have made two significant bets:\n\n* That we can overcome the most critical obstacle between us and our vision\n\n* That we can generate enough demand for our solution from customers\n\n![](https://storage.googleapis.com/langkilde-se-images/27cd9685-0b46-47c4-9232-026e26b4c601.jpeg)\n\n**The next random element is capital requirements.** Every company needs capital to fund innovation, but the early stage\nis unpredictable. You need to invest in both the experimentation platform mentioned earlier and the go-to-market\nactivities required to generate customer demand. Neither is a predictable process.\n\n**To be a good capital allocator, you invest proportionately to the value you can create and capture.** So, you need to\nmake assumptions about the number of customers you can serve and the amount they will be willing to pay. This is the\nnext major bet you are placing. Markets are chaotic. Thousands of companies crash into each other. Countless fundamental\nfactors are aggregated. All of them crash into each other in â€œthe marketâ€.\n\n![](https://storage.googleapis.com/langkilde-se-images/8dbdd99f-bf89-4ae2-8416-5c877f125b9c.jpeg)\n\nA system of 3 bodies interacting gravitationally is chaotic.\n\n> Chaos is when the present determines the future but the approximate present does not approximately determine the\n> future.\n>\n> -- Edward Norton Lorenz\n\nSince world market is chaotic, estimating how much value you can create is very hard. Most huge companies today feel\nobvious in retrospect. â€œOf course Nvidia is a successful company!â€ But the reality is that it was usually far from\nobvious for a very long time.\n\n### Creating and Capturing Value\n\n**To make matters worse, creating value is not enough. You also need to capture value.** Inspired by\nthe [Acquired podcast](https://www.acquired.fm), Iâ€™ve become fond of the **\"7 Powers\" framework** to understand a\ncompanyâ€™s ability to capture value.\n\n![](https://storage.googleapis.com/langkilde-se-images/80bf68b4-9880-46e8-926f-5f4c16e0be26.jpeg)\n\n\"7 Powers\" was created by Hamilton Helmer, describing possible sources of persistent competitive advantage. A lot of\nit is focused on differentials against competitors. You want to establish a flywheel motion that compounds into a\ngrowing advantage. Once that flywheel is started, you must ensure you do not run out of money. Sooner or later, you will\nbe unstoppable. That is, until the world changes. When the internet was invented, the power dynamics of markets changed\nvery quickly. The transaction cost of exchanging goods basically disappears, and that rapidly disrupted incumbents. No\nbusiness is safe. The faster the rate of change in the world, the more important it is to evolve constantly.\n\nBusinesses are technical, social, and financial experiments. They bundle a considerable number of sources of randomness.\n\n* The team\n\n* The vision\n\n* The critical obstacle\n\n* The teamâ€™s ability to overcome the obstacle\n\n* The teamâ€™s ability to generate demand for the solution\n\n* The size and growth of the market\n\n* The ability to gain the power to sustain profits\n\nSkill improves your odds of good outcomes. Outlier outcomes require luck. The outcome is not only the result of your\nactions as an entrepreneur. Even the most skilled operators can fail when\nmaking many bundled bets. **I am undaunted. Be busy building.**","src/content/blog/untangling-luck-and-skill-in-business.md","2410575e5864f189",{"html":951,"metadata":952},"\u003Cp>\u003Cstrong>Letâ€™s be honest: Life is pretty random.\u003C/strong> A lot of things are out of your control. Not being in control is hard for\npassionate people with a high internal locus of control. Adverse outcomes are physically painful for me. I donâ€™t worry,\nbut I \u003Cstrong>hate\u003C/strong> failing. Since I think most outcomes in my life result from my actions, I take adverse outcomes very\npersonally. If I make a mistake, pain is helpful. It helps me learn fast. But often, the outcome is simply the result of\nbad luck; in those cases, pain is a waste of time. Reversely, itâ€™s humbling to realize that outlier success also\nrequires a lot of luck.\u003C/p>\n\u003Cp>\u003Cstrong>The more abstract and long-term oriented my work becomes, the more complex it gets to untangle skill and luck.\u003C/strong> To\ncope with successes and setbacks, I spend time on trying to separate different factors. Here is an attempt to sort out\nthe following aspects:\u003C/p>\n\u003Col>\n\u003Cli>\n\u003Cp>What it means to be skilled versus lucky\u003C/p>\n\u003C/li>\n\u003Cli>\n\u003Cp>What it takes to create and capture value\u003C/p>\n\u003C/li>\n\u003Cli>\n\u003Cp>What the primary sources of randomness are\u003C/p>\n\u003C/li>\n\u003C/ol>\n\u003Ch3 id=\"what-does-it-mean-to-be-skilled\">What Does It Mean to Be Skilled?\u003C/h3>\n\u003Cp>I think skill combines IQ, training, experience, communication, determination,\nnetwork, and judgment. You could probably list ten other things, but these are the big ones. Skill is the ability to\nimprove the odds of successful outcomes.\u003C/p>\n\u003Cp>\u003Cimg src=\"https://storage.googleapis.com/langkilde-se-images/a58b069d-d898-457b-b0d8-9076d7076b6c.jpeg\" alt=\"\">\u003C/p>\n\u003Cp>\u003Cstrong>Unfortunately, we cannot do much about our IQ.\u003C/strong> Weâ€™re born with the brain we get. We can, however, influence most of\nthe rest.\u003C/p>\n\u003Cp>\u003Cstrong>Training\u003C/strong> yourself to apply a systematic, logical approach to exploring, understanding, and acquiring new knowledge\nis incredibly valuable. In my experience, the most powerful thing you can do is to learn about â€œstructures and\nframeworks.â€ Mathematics is a collection of structures and frameworks. It teaches you ways to write down assumptions and\nderive conclusions. Initially, math feels like â€œjust learning rules,â€ but eventually, once those rules are memorized,\nitâ€™s about learning ways to reason.\u003C/p>\n\u003Cp>Gaining \u003Cstrong>Experience\u003C/strong> is the process of creating and updating beliefs with new evidence. If training provides\nframeworks, experience gathers observations to estimate probabilities. The more experience we have, the better we know\nwhat to expect. As the world changes, existing experiences become outdated. This is the opportunity young people and\ncompanies have to create new value.\u003C/p>\n\u003Cp>\u003Cstrong>Communication\u003C/strong> is the ability to convey information in an engaging and understandable way. Great leaders are\ntypically also great communicators. They can simplify complex situations and communicate what matters. Noise is the\nenemy of focused action. The world gets complex fast if we let it. Excellent communication can significantly improve\nyour probability of success.\u003C/p>\n\u003Cp>\u003Cstrong>Determination\u003C/strong> is the ability to keep going. It requires a deep belief in oneself. The most successful people in the\nworld believe in themselves almost to the point of delusion. Innovation is to do something before it is obvious. There\nwill not be enough data. Others will doubt you. Managing morale in the face of uncertainty is a critical skill. The\ntricky thing for most people is to balance determination with self-awareness and open-mindedness. Being both stubborn\nand open-minded is a contradiction. Yet, that is what you need to master. By thinking from the first principle and\nrejecting outdated social structures, you can channel your determination toward overcoming the most critical obstacles.\nYou cannot fight the laws of nature, but you must believe everything else can be changed. You need to feel like you can\nbend the world to your will. Most people donâ€™t even try. They accept that things are the way they are. Determination is\nthe opposite of self-doubt. It is the opposite of giving up too early. It means you push hard for an extended time.\nDetermination is a skill.\u003C/p>\n\u003Cp>\u003Cstrong>Network\u003C/strong> is a personâ€™s ability to build and maintain relationships. Itâ€™s impossible to change the world on your own.\nYou need a strong network of other skilled people to overcome the critical obstacles you will face. You need great\npeople in your corner. Investing early and patiently in your network provides tremendous, long-term value. The\ndifference between success and failure can come down to making that \u003Cem>one call\u003C/em> at the right time.\u003C/p>\n\u003Cp>\u003Cstrong>Judgment\u003C/strong> involves making decisions based on sound principles and values. It means distinguishing between right and\nwrong and acting accordingly. Integrity is the ability to hold oneself to a consistent set of ethical principles and do\nthe right thing even when it is inconvenient. It requires self-awareness and reflection to avoid bias and\ninconsistencies.\u003C/p>\n\u003Ch3 id=\"what-does-it-mean-to-be-lucky\">What Does It Mean to Be Lucky?\u003C/h3>\n\u003Cp>To be lucky is to benefit from favorable circumstances that occur by chance rather\nthan through oneâ€™s actions. If you place a bet with 10/1 odds and win, you are lucky. The worse the odds, the luckier\nyou are if you win.\u003C/p>\n\u003Cp>\u003Cimg src=\"https://storage.googleapis.com/langkilde-se-images/f0d6e49a-0c0f-49de-8064-6be6429c90f8.jpeg\" alt=\"\">\u003C/p>\n\u003Cp>\u003Cstrong>Untangling skill and luck requires an understanding of:\u003C/strong>\u003C/p>\n\u003Cul>\n\u003Cli>\n\u003Cp>The available set of potential sequences of actions (plans and strategies)\u003C/p>\n\u003C/li>\n\u003Cli>\n\u003Cp>Probability of a favorable outcome for each sequence of actions (probabilities)\u003C/p>\n\u003C/li>\n\u003Cli>\n\u003Cp>The ability to rapidly adapt to the arrival of new information (robustness)\u003C/p>\n\u003C/li>\n\u003C/ul>\n\u003Ch3 id=\"building-a-business-is-a-bundle-of-bets\">Building a Business Is a Bundle of Bets\u003C/h3>\n\u003Cp>You bet on a market, a trend, a technology, a founder, a CEO, a team,\nan obstacle, a solution, a business model, a plan, a brand, and more. All these different factors are rolled up into one\ngiant bet. Entrepreneurs, executives, and investors are paid on the assumption that they can untangle all the bets and\nimprove the odds. Their IQ, training, experience, communication, determination, network, and judgment should give them\nan edge.\u003C/p>\n\u003Cp>\u003Cstrong>When I examine my performance as a business leader, Iâ€™m trying to ask myself: Was this outcome the result of skill or\nrandom events?\u003C/strong> Did I apply my skill to estimate and influence the distribution of possible outcomes? Could I have\nincreased the odds of a more favorable outcome by better analysis or different actions? Itâ€™s essential in this context\nto factor in time and available information. Retroactively evaluating a decision is only fair with the same time\nconstraints and information. Hindsight is, after all, 20/20.\u003C/p>\n\u003Cp>\u003Cstrong>A skilled person should, in most cases, be able to estimate and influence the probability distribution of possible\noutcomes in a specific situation.\u003C/strong> Question is, how much? Knowing the distribution of potential outcomes allows you to\nmake an informed decision when taking action. If the problem is familiar and the world is stable, an experienced and\nwell-trained person should be able to ensure a decent outcome or at least help you make a well-informed bet. However, it\nis harder to make a skill-based decision in novel situations. There arenâ€™t enough prior observations to estimate\nprobability distributions. Outlier outcomes are, by nature, unlikely. They are most often the result of someone placing\na big bet on an unlikely event and winning. Data supports this as the correlation between income and intelligence is\nmuch stronger than the correlation between net worth and intelligence.\u003C/p>\n\u003Cp>\u003Cimg src=\"https://storage.googleapis.com/langkilde-se-images/1fd2a726-bb07-4263-bfab-da1a2c5c7287.jpeg\" alt=\"\">\u003C/p>\n\u003Cp>\u003Ca href=\"https://gwern.net/doc/iq/ses/2007-zagorsky.pdf\">Source\u003C/a>\u003C/p>\n\u003Cp>Another way to put this is: Can you â€œmanufacture luckâ€ when building a business? I think you can, to a point. There are\ndefinitely powerful frameworks that can improve your odds.\u003C/p>\n\u003Ch3 id=\"bold-visions-and-critical-obstacles\">Bold Visions and Critical Obstacles\u003C/h3>\n\u003Cp>A critical factor necessary to create an outlier outcome is to have a bold vision and overcome huge obstacles. Iâ€™m\ninspired by The Crux, a book by Richard Rumelt, one of the worldâ€™s leading authorities on strategy. The book\nsuggests how to identify problems that are valuable to solve. His advice is simple: Focus your energy on the most\ncritical obstacle you can overcome to accelerate the world toward your vision. By definition, a critical obstacle is\nunsolved in a satisfactory way. If it already has a solution, itâ€™s not a critical obstacle.\u003C/p>\n\u003Cp>\u003Cimg src=\"https://storage.googleapis.com/langkilde-se-images/fbd3e874-129f-4844-b104-f327048f9513.jpeg\" alt=\"\">\u003C/p>\n\u003Cp>\u003Cstrong>You need to decide what your vision is.\u003C/strong> No one can tell you your purpose; thatâ€™s up to you. I like to imagine what I\nwant the world to look like in 10 years, 50 years, or 100 years. Then I work my way backward: What are the most critical\nobstacles to overcome to accelerate the world toward my vision? You can get to work once you find the intersection\nbetween our current knowledge, existing technologies, and the most immediate obstacle. My favorite quote from Gibson is:\nâ€œThe future is already here, just unevenly distributed.â€ My takeaway is that what is â€˜table stakesâ€™ in 10 years is\nprobably already available today in â€˜pockets of the future.â€™ The more universal the vision and the more significant the\nobstacle, the more value you create if you overcome the obstacle. If you solve a meaningful problem, skilled people will\nwant to help you.\u003C/p>\n\u003Cp>\u003Cstrong>Pursuing a bold vision and working to overcome a huge obstacle means you invite randomness into your life. Solutions\nto overcome critical obstacles do not appear in a structured, predictable way.\u003C/strong> Skilled, prolific people can come up\nwith more and better ideas, but they cannot just â€˜manifest solutionsâ€™ out of thin air. It takes persistence and\nexperimentation to expand into the unknown. Inventing new things is extremely hard work that doesnâ€™t necessarily produce\nthe results you want. In my experience, all you can do is â€˜trust the process.â€™ Create the most powerful platform you can\nfor experimentation (team, resources, capital, etc.) and aim to address the most critical obstacles between you and your\nvision for as long as you can. The more capital you can access to fund your platform for experimentation and the more\nprolific, skilled people you can hire, the higher the probability of overcoming critical obstacles. For example, Nobel\nlaureates publish 5x more than average scientists during their early careers. Itâ€™s not enough to be smart; you must also\nbe prolific.\u003C/p>\n\u003Cp>\u003Cstrong>To make commercial product innovation even more complex, it depends on other people, i.e., your customers.\u003C/strong> A\nsufficiently large group of customers must agree that they face the critical obstacle you focus on. And they must agree\nwith you that your solution overcomes their obstacle in a satisfying way. And they must be in a position to pay for your\nsolution. Most companies fail to launch valuable products because they fail to validate with customers that the obstacle\nis critical.\u003C/p>\n\u003Ch3 id=\"the-complexity-of-customer-validation\">The Complexity of Customer Validation\u003C/h3>\n\u003Cp>\u003Cstrong>I think customer feedback is the most confusing aspect of entrepreneurship.\u003C/strong> During times of major disruption, when\nnew technology emerges that solves problems in an unseen way, social structures become a major adoption factor. Maybe\nyour customer is scared of change and unwilling to risk their current status quo? Or perhaps they want to buy, but\nmanagement will not approve it? Or maybe the buyerâ€™s status is threatened by this new technology? Or does your solution\nrisk replacing existing teams? Or maybe customers are just so invested in their current way of working that they want to\navoid disrupting that? This feedback can easily be confused with â€œyou are not overcoming a critical obstacle.â€ You might\nhave a way to overcome a critical obstacle; your customer may not realize or appreciate it. But they could also be\nright, and you could be wrong. Or you are both right; the timing just isnâ€™t there. There is a big graveyard of startups\nwith products overcoming obstacles that arenâ€™t critical. This is a significant source of randomness when building a\nbusiness. Not only are you betting you can overcome a critical obstacle, but you are also betting there will be demand\nfor your solution. There is a saying that â€œfirst-time founders focus on products, second-time founders focus on\ndistribution.â€\u003C/p>\n\u003Ch3 id=\"the-role-of-determination\">The Role of Determination\u003C/h3>\n\u003Cp>Outlier outcomes require placing high-conviction bets before it is\nobvious and being right. I quote from earlier:\u003C/p>\n\u003Cblockquote>\n\u003Cp>Innovation is to do something before it is obvious. There will not be enough data. Others will doubt you. Managing\nmorale in the face of uncertainty is a critical skill. The tricky thing for most people is to balance determination\nwith\nself-awareness and open-mindedness. Being both stubborn and open-minded is a contradiction. Yet, that is what you need\nto master.\u003C/p>\n\u003C/blockquote>\n\u003Cp>At this point, we have made two significant bets:\u003C/p>\n\u003Cul>\n\u003Cli>\n\u003Cp>That we can overcome the most critical obstacle between us and our vision\u003C/p>\n\u003C/li>\n\u003Cli>\n\u003Cp>That we can generate enough demand for our solution from customers\u003C/p>\n\u003C/li>\n\u003C/ul>\n\u003Cp>\u003Cimg src=\"https://storage.googleapis.com/langkilde-se-images/27cd9685-0b46-47c4-9232-026e26b4c601.jpeg\" alt=\"\">\u003C/p>\n\u003Cp>\u003Cstrong>The next random element is capital requirements.\u003C/strong> Every company needs capital to fund innovation, but the early stage\nis unpredictable. You need to invest in both the experimentation platform mentioned earlier and the go-to-market\nactivities required to generate customer demand. Neither is a predictable process.\u003C/p>\n\u003Cp>\u003Cstrong>To be a good capital allocator, you invest proportionately to the value you can create and capture.\u003C/strong> So, you need to\nmake assumptions about the number of customers you can serve and the amount they will be willing to pay. This is the\nnext major bet you are placing. Markets are chaotic. Thousands of companies crash into each other. Countless fundamental\nfactors are aggregated. All of them crash into each other in â€œthe marketâ€.\u003C/p>\n\u003Cp>\u003Cimg src=\"https://storage.googleapis.com/langkilde-se-images/8dbdd99f-bf89-4ae2-8416-5c877f125b9c.jpeg\" alt=\"\">\u003C/p>\n\u003Cp>A system of 3 bodies interacting gravitationally is chaotic.\u003C/p>\n\u003Cblockquote>\n\u003Cp>Chaos is when the present determines the future but the approximate present does not approximately determine the\nfuture.\u003C/p>\n\u003Cp>â€” Edward Norton Lorenz\u003C/p>\n\u003C/blockquote>\n\u003Cp>Since world market is chaotic, estimating how much value you can create is very hard. Most huge companies today feel\nobvious in retrospect. â€œOf course Nvidia is a successful company!â€ But the reality is that it was usually far from\nobvious for a very long time.\u003C/p>\n\u003Ch3 id=\"creating-and-capturing-value\">Creating and Capturing Value\u003C/h3>\n\u003Cp>\u003Cstrong>To make matters worse, creating value is not enough. You also need to capture value.\u003C/strong> Inspired by\nthe \u003Ca href=\"https://www.acquired.fm\">Acquired podcast\u003C/a>, Iâ€™ve become fond of the \u003Cstrong>â€œ7 Powersâ€ framework\u003C/strong> to understand a\ncompanyâ€™s ability to capture value.\u003C/p>\n\u003Cp>\u003Cimg src=\"https://storage.googleapis.com/langkilde-se-images/80bf68b4-9880-46e8-926f-5f4c16e0be26.jpeg\" alt=\"\">\u003C/p>\n\u003Cp>â€œ7 Powersâ€ was created by Hamilton Helmer, describing possible sources of persistent competitive advantage. A lot of\nit is focused on differentials against competitors. You want to establish a flywheel motion that compounds into a\ngrowing advantage. Once that flywheel is started, you must ensure you do not run out of money. Sooner or later, you will\nbe unstoppable. That is, until the world changes. When the internet was invented, the power dynamics of markets changed\nvery quickly. The transaction cost of exchanging goods basically disappears, and that rapidly disrupted incumbents. No\nbusiness is safe. The faster the rate of change in the world, the more important it is to evolve constantly.\u003C/p>\n\u003Cp>Businesses are technical, social, and financial experiments. They bundle a considerable number of sources of randomness.\u003C/p>\n\u003Cul>\n\u003Cli>\n\u003Cp>The team\u003C/p>\n\u003C/li>\n\u003Cli>\n\u003Cp>The vision\u003C/p>\n\u003C/li>\n\u003Cli>\n\u003Cp>The critical obstacle\u003C/p>\n\u003C/li>\n\u003Cli>\n\u003Cp>The teamâ€™s ability to overcome the obstacle\u003C/p>\n\u003C/li>\n\u003Cli>\n\u003Cp>The teamâ€™s ability to generate demand for the solution\u003C/p>\n\u003C/li>\n\u003Cli>\n\u003Cp>The size and growth of the market\u003C/p>\n\u003C/li>\n\u003Cli>\n\u003Cp>The ability to gain the power to sustain profits\u003C/p>\n\u003C/li>\n\u003C/ul>\n\u003Cp>Skill improves your odds of good outcomes. Outlier outcomes require luck. The outcome is not only the result of your\nactions as an entrepreneur. Even the most skilled operators can fail when\nmaking many bundled bets. \u003Cstrong>I am undaunted. Be busy building.\u003C/strong>\u003C/p>",{"headings":953,"localImagePaths":975,"remoteImagePaths":976,"frontmatter":977,"imagePaths":978},[954,957,960,963,966,969,972],{"depth":24,"slug":955,"text":956},"what-does-it-mean-to-be-skilled","What Does It Mean to Be Skilled?",{"depth":24,"slug":958,"text":959},"what-does-it-mean-to-be-lucky","What Does It Mean to Be Lucky?",{"depth":24,"slug":961,"text":962},"building-a-business-is-a-bundle-of-bets","Building a Business Is a Bundle of Bets",{"depth":24,"slug":964,"text":965},"bold-visions-and-critical-obstacles","Bold Visions and Critical Obstacles",{"depth":24,"slug":967,"text":968},"the-complexity-of-customer-validation","The Complexity of Customer Validation",{"depth":24,"slug":970,"text":971},"the-role-of-determination","The Role of Determination",{"depth":24,"slug":973,"text":974},"creating-and-capturing-value","Creating and Capturing Value",[],[],{"pubDate":946,"title":945},[],"untangling-luck-and-skill-in-business.md","when-will-we-have-autonomous-vehicles",{"id":980,"data":982,"body":985,"filePath":986,"digest":987,"rendered":988,"legacyId":1002},{"title":983,"pubDate":984},"When will we have Autonomous Vehicles?","2019-10-18","[Kognic](https://www.kognic.com), the company Oscar and I founded last year, has decided to focus exclusively on ground\ntruth generation for autonomous vehicles. This means we get the privilege of working with a lot of different companies\ninvolved in developing autonomous vehicles. It also means the most common question I get is â€œWhen do you think we will\nhave self-driving cars?â€ **I think we are still decades away from regular people getting into their car and asking it to\ndrive them to work. Let me explain why.**\n\n### Three words matter in my opinion: sparsity, fragility and complexity.\n\n**Sparse** is when something is thinly distributed. The world is sparse in that a lot of things rarely happen. Sure, a\nlot of our everyday life is boring business as usual. But every so often something unexpected happens. Modern machine\nlearning systems are unable to improvise, or generalize to the unseen. That means they act unpredictably when handling\nrare events.\n\n**Fragile** is when something is easily broken. We know that even small changes in input format can render modern\nmachine learning systems useless. And I donâ€™t even mean adversarial examples. Something as simple as a color decoding\nissue can severely impact an ML modelâ€™s ability to understand an image. If we were, for example, to change the color of\nthe lines on the road, adjustments would need to be made to the self-driving system. The changes might not have to be\nmassive, but probably big enough to interfere with the self-driving abilities of the vehicle.\n\n**Complex** is when a system of things are linked in a complicated way. Each thing might not be complicated, but\ntogether they form a complex system. Even if we can make a vehicle understand everything around us from a perception\nstandpoint, we still need to train it to understand how the various objects around us interact.\n\nTo build an autonomous vehicle you need to deal with complex object interactions, the a long tail of rare events, and\nthe fragility of ML models. Humans who act in this environment are much more advanced than our existing ML models. They\nalso have the benefit of reasoning based on a real-world model that has been learned over an entire lifetime.\n\n**There are parts of driving that computers probably will do better.** For example the long, boring high-way parts of\ndriving. Computers do not fall asleep or get distracted the same way humans do, so for these parts they might even be\nsafer. Long queues on the way to and from work will probably work fine too. These are all situations with few unexpected\nevents, and fewer complex interactions.\n\n**Then there are parts of driving that will be very, very hard for computers.** Construction sites, temporary roads,\ncomplex intersections, environments with lots of pedestrians, poorly marked roads and more. These situations are extra\nsparse, fragile and complex, which is why it will take a very long time for autonomous vehicles to fully master them.\n\n### So what does this mean for autonomous vehicles?\n\n**Well, Iâ€™m an optimist but a realist.** On the way to full self-driving, i.e. just riding in your car, not driving it,\nwe will have increasingly competent active safety systems. These systems will save lives in a range of situations, and\nsave drivers from long, boring stretches of highway driving. This will be valuable, but not game-changing. The more\nradical economic results from autonomous vehicles will not occur until we can remove the driver. One option to make this\nhappen sooner is to create special zones where we reduce the sparsity, fragility, and complexity of things. For example,\nspecial zones where only goods transportation is allowed, and no pedestrians can enter.\n\n**My experience so far is that autonomous vehicles are way more expensive and time consuming to develop than most\ncompanies expected.** Mostly because there are so many sources of errors. You are faced with errors from hardware,\ncalibration, time synchronization, data communication, signal processing, object classification, target tracking, path\nplanning, actuation, human intervention, complex object interactions and more. This doesnâ€™t mean we shouldnâ€™t pursue\nautonomous vehicles, but it impacts my estimate of when we will get to a point where we jump into our car and tell it to\ndrive us to work!\n\n**Want to be part of developing autonomous vehicles?** Annotell is looking for engineers to make managing the data\naspects of the process easier. [See list of open positions here.](https://careers.kognic.com)","src/content/blog/when-will-we-have-autonomous-vehicles.md","fb57a4ecd0587118",{"html":989,"metadata":990},"\u003Cp>\u003Ca href=\"https://www.kognic.com\">Kognic\u003C/a>, the company Oscar and I founded last year, has decided to focus exclusively on ground\ntruth generation for autonomous vehicles. This means we get the privilege of working with a lot of different companies\ninvolved in developing autonomous vehicles. It also means the most common question I get is â€œWhen do you think we will\nhave self-driving cars?â€ \u003Cstrong>I think we are still decades away from regular people getting into their car and asking it to\ndrive them to work. Let me explain why.\u003C/strong>\u003C/p>\n\u003Ch3 id=\"three-words-matter-in-my-opinion-sparsity-fragility-and-complexity\">Three words matter in my opinion: sparsity, fragility and complexity.\u003C/h3>\n\u003Cp>\u003Cstrong>Sparse\u003C/strong> is when something is thinly distributed. The world is sparse in that a lot of things rarely happen. Sure, a\nlot of our everyday life is boring business as usual. But every so often something unexpected happens. Modern machine\nlearning systems are unable to improvise, or generalize to the unseen. That means they act unpredictably when handling\nrare events.\u003C/p>\n\u003Cp>\u003Cstrong>Fragile\u003C/strong> is when something is easily broken. We know that even small changes in input format can render modern\nmachine learning systems useless. And I donâ€™t even mean adversarial examples. Something as simple as a color decoding\nissue can severely impact an ML modelâ€™s ability to understand an image. If we were, for example, to change the color of\nthe lines on the road, adjustments would need to be made to the self-driving system. The changes might not have to be\nmassive, but probably big enough to interfere with the self-driving abilities of the vehicle.\u003C/p>\n\u003Cp>\u003Cstrong>Complex\u003C/strong> is when a system of things are linked in a complicated way. Each thing might not be complicated, but\ntogether they form a complex system. Even if we can make a vehicle understand everything around us from a perception\nstandpoint, we still need to train it to understand how the various objects around us interact.\u003C/p>\n\u003Cp>To build an autonomous vehicle you need to deal with complex object interactions, the a long tail of rare events, and\nthe fragility of ML models. Humans who act in this environment are much more advanced than our existing ML models. They\nalso have the benefit of reasoning based on a real-world model that has been learned over an entire lifetime.\u003C/p>\n\u003Cp>\u003Cstrong>There are parts of driving that computers probably will do better.\u003C/strong> For example the long, boring high-way parts of\ndriving. Computers do not fall asleep or get distracted the same way humans do, so for these parts they might even be\nsafer. Long queues on the way to and from work will probably work fine too. These are all situations with few unexpected\nevents, and fewer complex interactions.\u003C/p>\n\u003Cp>\u003Cstrong>Then there are parts of driving that will be very, very hard for computers.\u003C/strong> Construction sites, temporary roads,\ncomplex intersections, environments with lots of pedestrians, poorly marked roads and more. These situations are extra\nsparse, fragile and complex, which is why it will take a very long time for autonomous vehicles to fully master them.\u003C/p>\n\u003Ch3 id=\"so-what-does-this-mean-for-autonomous-vehicles\">So what does this mean for autonomous vehicles?\u003C/h3>\n\u003Cp>\u003Cstrong>Well, Iâ€™m an optimist but a realist.\u003C/strong> On the way to full self-driving, i.e. just riding in your car, not driving it,\nwe will have increasingly competent active safety systems. These systems will save lives in a range of situations, and\nsave drivers from long, boring stretches of highway driving. This will be valuable, but not game-changing. The more\nradical economic results from autonomous vehicles will not occur until we can remove the driver. One option to make this\nhappen sooner is to create special zones where we reduce the sparsity, fragility, and complexity of things. For example,\nspecial zones where only goods transportation is allowed, and no pedestrians can enter.\u003C/p>\n\u003Cp>\u003Cstrong>My experience so far is that autonomous vehicles are way more expensive and time consuming to develop than most\ncompanies expected.\u003C/strong> Mostly because there are so many sources of errors. You are faced with errors from hardware,\ncalibration, time synchronization, data communication, signal processing, object classification, target tracking, path\nplanning, actuation, human intervention, complex object interactions and more. This doesnâ€™t mean we shouldnâ€™t pursue\nautonomous vehicles, but it impacts my estimate of when we will get to a point where we jump into our car and tell it to\ndrive us to work!\u003C/p>\n\u003Cp>\u003Cstrong>Want to be part of developing autonomous vehicles?\u003C/strong> Annotell is looking for engineers to make managing the data\naspects of the process easier. \u003Ca href=\"https://careers.kognic.com\">See list of open positions here.\u003C/a>\u003C/p>",{"headings":991,"localImagePaths":998,"remoteImagePaths":999,"frontmatter":1000,"imagePaths":1001},[992,995],{"depth":24,"slug":993,"text":994},"three-words-matter-in-my-opinion-sparsity-fragility-and-complexity","Three words matter in my opinion: sparsity, fragility and complexity.",{"depth":24,"slug":996,"text":997},"so-what-does-this-mean-for-autonomous-vehicles","So what does this mean for autonomous vehicles?",[],[],{"pubDate":984,"title":983},[],"when-will-we-have-autonomous-vehicles.md","why-i-am-excited-about-ai",{"id":1003,"data":1005,"body":1008,"filePath":1009,"digest":1010,"rendered":1011,"legacyId":1019},{"title":1006,"pubDate":1007},"Why I am excited about.astro AI","2023-06-08","The debate about the impact of increasingly capable AI systems rages on. Three main currents have emerged in the\ndiscourse:\n\n* **The â€œexcitedâ€** led by Marc Andreessen, Yann LeCunn, Andrew Ng, and others.\n\n    * [Why AI Will Save The World](https://pmarca.substack.com/p/why-ai-will-save-the-world)\n\n* **The â€œworriedâ€** led by Geoff Hinton, Yoshua Bengio, Stuart Russell, and others.\n\n    * [â€˜The Godfather of A.I.â€™ Leaves Google and Warns of Danger Ahead](https://www.nytimes.com/2023/05/01/technology/ai-google-chatbot-engineer-quits-hinton.html)\n\n* **The â€œterrifiedâ€** led by Eliezer Yudkowsky and others.\n\n    * [AGI Ruin: A List of Lethalities](https://www.lesswrong.com/posts/uMQ3cqWDPHhjtiesc/agi-ruin-a-list-of-lethalities)\n\nIt almost feels like we are faced with\nan [underdetermined](https://en.wikipedia.org/wiki/Underdetermined_system#:~:text=In%20mathematics%2C%20a%20system%20of,the%20concept%20of%20constraint%20counting.)\nsystem of equations. People often resort to emotional claims guided by ideology when there are too many free variables\nand no single solution. We are still trying to get â€œthe lay of the land,â€ so being completely sure about anything right\nnow is to make things too simple. Iâ€™ve entertained many possible futures and tried to keep an open mind since it became\nclear how capable Transformers are. Iâ€™ve oscillated from terrified to worried to excited and back again. I always try to\nexplore all perspectives before I decide what I believe in.\n\nFinally, I feel like my mind is settling down and that I am converging on a position. **Despite some clear risks,** *\n*Iâ€™ve decided Iâ€™m excited about AI ðŸŽ‰** Here are the assumptions that led me to this:\n\n**#1. All human lives are equally important and humans are more important than machines  \n** I bring this up first because Iâ€™m honestly not sure all advocates of AI care about most humans. Part of what made me\nworried for a while is that I consider humans more important than machines. My vision for the future is not some\ntech-dystopia run by robots. I want humans to be in charge. I canâ€™t prove why; I consider it an axiom. Humans are more\nimportant than anything else. Itâ€™s our moral obligation to protect the subjective human experience of consciousness.\nIâ€™m [anthropocentric](https://langkilde.se/post/2023-04-24-alignment-anthropocentrism-personalization) in that sense.\nWhen leaders question this, [catastrophe](https://en.wikipedia.org/wiki/The_Holocaust) often follows. If AI does become\na threat to humans at any point (not saying itâ€™s now), I value humans more than machines.\n\n**#2. Technological and scientific progress, in general, makes the world better  \n** Iâ€™m an optimist at heart and a deep believer in the benefits of technological progress. I think itâ€™s humanityâ€™s\npurpose to explore the universe. We have dramatically improved our standard of living since we emerged from our caves,\nand thatâ€™s a good thing. Of course, all progress comes with some creative destruction but that which emerges is better,\ntaken as a whole. Increasingly capable AI is no different. Some appear to â€œmiss simpler timesâ€ and want to stop\nprogress. I do not believe in that. I think itâ€™s our purpose to move forward constantly.\n\n**#3. AI can accelerate our efforts to improve the world  \n** Almost 1 billion people live on less than $3/day, i.e., in extreme poverty. Every year, millions of children die\nbefore they even get a chance to explore the world. We face a growing environmental crisis that requires new sources of\nenergy. The list goes on. While some jobs might be displaced due to automation, there is no shortage of problems to\nsolve. If each person can get smarter and more productive with the help of an AI assistant, I welcome that! Technology\nis our best bet to enable all humans to live prosperous lives.\n\n**#4. AI probably wonâ€™t cause a labor shortage but displacement needs to be managed**  \nIâ€™m not worried we will run out of jobs. So many things need to be done that higher productivity is welcome. But, we\nshouldnâ€™t dismiss the short-term tumultuous nature of labor displacement. I recommend reading Daron Acemoglu and Simon\nJohnsonsâ€™\nbook â€œ[Power and Progress](https://www.amazon.com/Power-Progress-Thousand-Year-Technology-Prosperity/dp/1541702530).â€\nWhile AI is inevitable, how we implement it is far from pre-determined. It will depend on the balance of power in\nmillions of workplaces, regulation, the outcome of fights about working conditions, compensation levels, and the\ndistribution of productivity gains. Portraying AI as an inevitable change is to make it too simple. We can influence\n_how_ that change is implemented, and our actions during implementation will impact the quality of life for millions of\npeople. One example of bad implementation is\nthe [exploitation of annotators](https://www.linkedin.com/posts/daniellangkilde_this-is-unusual-for-me-but-i-feel-we-have-activity-7061967340048932865-Q_Co?utm_medium=member_desktop&utm_source=share).\n\n**#5. AI cannot be regulated on speculation  \n** Free-market democracy is the best way to enable all humans to live prosperous lives. There has always been a\ntemptation for those in power to think on behalf of other people. When a ruler thinks, â€œI know better,â€ you are about to\nget into trouble. Governments should fear the people, not the other way around. That does not mean we do not need some\nregulation.\nThe â€œ[tragedy of the commons](https://langkilde.se/post/2023-04-24-alignment-anthropocentrism-personalization)â€ is a\nreal thing. Some mechanisms are impossible to price into operating a business, so we need help. But, it is not clear\ntoday that AI poses a threat requiring regulation. We cannot regulate against hypotheticals, and most threats are\nhypothetical today. Waiting to regulate is better than imposing bad regulations like\nthe [EU AI Act](https://artificialintelligenceact.eu). The EU AI Act is the first time something feels worse than GDPR.\nIâ€™m not against regulation that protects us from depleting common goods because we cannot price in negative\nexternalities, but I am against speculative regulation.\n\n**#6. AI needs to be shaped by liberal democracies  \n** Iâ€™ve lived in China, and I speak decent Mandarin. The Chinese Communist Party (CCP) and its friends in Russia, Iran,\nand North Korea are a menace to humanity. These are autocratic countries without any respect for individual freedom and\nliberty. If you are gay in any of these countries, you face major legal and social challenges. If you build something\nvaluable, there is no guarantee the government wonâ€™t seize it. If you belong to the wrong ethnic minority, you might not\nbe allowed to practice your religious and ethnic beliefs. China views AI as an opportunity for more efficient population\ncontrol. Just read\nthe â€œ[New Generation Artificial Intelligence Development Plan](https://digichina.stanford.edu/work/full-translation-chinas-new-generation-artificial-intelligence-development-plan-2017/).â€\n\n**#7. AI can and will reflect diverse human values and preferences  \n** There is no â€œsystem free of moral bias.â€ Moral is, by definition, biased. Morals are concerned with the principles of\nright and wrong. Several moral systems have evolved over millennia and their merits are the subject of endless debate.\nCulture is the constant shaping of our moral system. The idea of creating a global AI free from bias is naive. Diversity\nis good and needs to be embraced. If we think we can force AI only to learn â€œgood things,â€ we will struggle. If we think\nwe can regulate against â€œbad things,â€ we will struggle. Let's instead defend every personâ€™s freedom. If we start\nconfusing AI regulation with the â€œwoke-anti-woke-continuum,â€ we are in trouble. AI will need to reflect the diversity of\nhumanity. Rather than unify all AIs, we will want ways to fine-tune systems to our preferences. I think our diversity of\npurpose is ultimately our best defense against AI. You cannot automate humans because we do not know why we exist.\n\n**#8. AI algorithms are being democratized fast  \n** Iâ€™m not worried that a few large companies will monopolize AI. Companies like [Hugging Face](https://huggingface.co)\nand open-source models like [LLaMA](https://huggingface.co/docs/transformers/main/model_doc/llama)\nare [scaring the shit out of giant companies](https://www.semianalysis.com/p/google-we-have-no-moat-and-neither) like\nGoogle. And thatâ€™s a good thing! Proprietary data is what will differentiate models, but it looks like you might not\nneed as much as we feared. Even small amounts of fine-tuning can make your model uniquely valuable. This is good for\nconsumers.\n\n**#9. Increased volumes of synthetic information will make life different  \n** Day by day, we are moving closer to being able to synthesize audio-visual information completely. Itâ€™s just a matter\nof time before anyone can â€œspoofâ€ your personality and pretend to be you. Algorithms can learn to look and talk like you\nfrom short audio and video snippets. With access to enough of your writing or voice recordings, such algorithms will\nalso be able to talk and write like you. This will make life different in interesting ways. Iâ€™m careful not to assume\nthis is bad. I think it will increase the value of journalism and it will contribute to a booming market for\nauthentication mechanisms. I will want proof of identity to talk.\n\n**#10. AI algorithms are currently bad for the environment  \n** We have to make these systems less power-hungry. Currently, the amount of carbon emissions from training and\ninference is skyrocketing. This can be solved, but itâ€™s still pretty important and urgent.\n\n**#11. The emergence of self-improving systems is still hypothetical  \n** The two central questions to the existential risk aspect that had me worried or even terrified are:  \n**#11a.** What is the probability that learning algorithms can become self-improving?   \n**#11b.** Once an algorithm asymptotically self-improves, what will it do?  \nYour position on these largely determines if you are _for_ or _against_ AI. Some say we are so far away from\nself-improving systems that the entire premise is irrelevant. Some argue that the moment self-improvement kicks in,\nweâ€™re all screwed. Clearly, there is a control problem in the event of super-learners. At this point, I cannot reject\nthe possibility of self-improving algorithms. I acknowledge that itâ€™s scientifically possible that they will emerge. I\neven think they inevitably will at some point. But I have no idea how likely it is or when it will happen. And I do not\nthink it will happen soon. What will such a system do once it comes online? I have no idea. Anyone who claims to know is\nspeculating. In the end, I think itâ€™s a matter\nof [tail-risk hedging](https://langkilde.se/post/2023-04-06-artificial-intelligence-scaling-laws-s-curves-tail-risk-and-practicalities).\nWhat do you do if there is a tiny, tiny probability of a really, really bad outcome? Iâ€™ve decided I will stay optimistic\ndespite such a risk.\n\n**Despite the risks and negative sides, Iâ€™m excited about AI! ðŸš€** I have not seen enough evidence of imminent\nself-improvement to miss out on all the value we can create with AI. We should leverage advanced machine learning to\nimprove the world. If we are all more productive, we stand a better chance of enabling all humans to live prosperous\nlives. We will face challenges, but thatâ€™s always part of life.\n\nAs long as humans remain in charge and we can _steer AI toward our goals_ , the world will be better off!","src/content/blog/why-i-am-excited-about-ai.md","7eb4cdd0bab25aba",{"html":1012,"metadata":1013},"\u003Cp>The debate about the impact of increasingly capable AI systems rages on. Three main currents have emerged in the\ndiscourse:\u003C/p>\n\u003Cul>\n\u003Cli>\n\u003Cp>\u003Cstrong>The â€œexcitedâ€\u003C/strong> led by Marc Andreessen, Yann LeCunn, Andrew Ng, and others.\u003C/p>\n\u003Cul>\n\u003Cli>\u003Ca href=\"https://pmarca.substack.com/p/why-ai-will-save-the-world\">Why AI Will Save The World\u003C/a>\u003C/li>\n\u003C/ul>\n\u003C/li>\n\u003Cli>\n\u003Cp>\u003Cstrong>The â€œworriedâ€\u003C/strong> led by Geoff Hinton, Yoshua Bengio, Stuart Russell, and others.\u003C/p>\n\u003Cul>\n\u003Cli>\u003Ca href=\"https://www.nytimes.com/2023/05/01/technology/ai-google-chatbot-engineer-quits-hinton.html\">â€˜The Godfather of A.I.â€™ Leaves Google and Warns of Danger Ahead\u003C/a>\u003C/li>\n\u003C/ul>\n\u003C/li>\n\u003Cli>\n\u003Cp>\u003Cstrong>The â€œterrifiedâ€\u003C/strong> led by Eliezer Yudkowsky and others.\u003C/p>\n\u003Cul>\n\u003Cli>\u003Ca href=\"https://www.lesswrong.com/posts/uMQ3cqWDPHhjtiesc/agi-ruin-a-list-of-lethalities\">AGI Ruin: A List of Lethalities\u003C/a>\u003C/li>\n\u003C/ul>\n\u003C/li>\n\u003C/ul>\n\u003Cp>It almost feels like we are faced with\nan \u003Ca href=\"https://en.wikipedia.org/wiki/Underdetermined_system#:~:text=In%20mathematics%2C%20a%20system%20of,the%20concept%20of%20constraint%20counting.\">underdetermined\u003C/a>\nsystem of equations. People often resort to emotional claims guided by ideology when there are too many free variables\nand no single solution. We are still trying to get â€œthe lay of the land,â€ so being completely sure about anything right\nnow is to make things too simple. Iâ€™ve entertained many possible futures and tried to keep an open mind since it became\nclear how capable Transformers are. Iâ€™ve oscillated from terrified to worried to excited and back again. I always try to\nexplore all perspectives before I decide what I believe in.\u003C/p>\n\u003Cp>Finally, I feel like my mind is settling down and that I am converging on a position. \u003Cstrong>Despite some clear risks,\u003C/strong> *\n\u003Cem>Iâ€™ve decided Iâ€™m excited about AI ðŸŽ‰\u003C/em>* Here are the assumptions that led me to this:\u003C/p>\n\u003Cp>**#1. All human lives are equally important and humans are more important than machines\u003Cbr>\n** I bring this up first because Iâ€™m honestly not sure all advocates of AI care about most humans. Part of what made me\nworried for a while is that I consider humans more important than machines. My vision for the future is not some\ntech-dystopia run by robots. I want humans to be in charge. I canâ€™t prove why; I consider it an axiom. Humans are more\nimportant than anything else. Itâ€™s our moral obligation to protect the subjective human experience of consciousness.\nIâ€™m \u003Ca href=\"https://langkilde.se/post/2023-04-24-alignment-anthropocentrism-personalization\">anthropocentric\u003C/a> in that sense.\nWhen leaders question this, \u003Ca href=\"https://en.wikipedia.org/wiki/The_Holocaust\">catastrophe\u003C/a> often follows. If AI does become\na threat to humans at any point (not saying itâ€™s now), I value humans more than machines.\u003C/p>\n\u003Cp>**#2. Technological and scientific progress, in general, makes the world better\u003Cbr>\n** Iâ€™m an optimist at heart and a deep believer in the benefits of technological progress. I think itâ€™s humanityâ€™s\npurpose to explore the universe. We have dramatically improved our standard of living since we emerged from our caves,\nand thatâ€™s a good thing. Of course, all progress comes with some creative destruction but that which emerges is better,\ntaken as a whole. Increasingly capable AI is no different. Some appear to â€œmiss simpler timesâ€ and want to stop\nprogress. I do not believe in that. I think itâ€™s our purpose to move forward constantly.\u003C/p>\n\u003Cp>**#3. AI can accelerate our efforts to improve the world\u003Cbr>\n** Almost 1 billion people live on less than $3/day, i.e., in extreme poverty. Every year, millions of children die\nbefore they even get a chance to explore the world. We face a growing environmental crisis that requires new sources of\nenergy. The list goes on. While some jobs might be displaced due to automation, there is no shortage of problems to\nsolve. If each person can get smarter and more productive with the help of an AI assistant, I welcome that! Technology\nis our best bet to enable all humans to live prosperous lives.\u003C/p>\n\u003Cp>\u003Cstrong>#4. AI probably wonâ€™t cause a labor shortage but displacement needs to be managed\u003C/strong>\u003Cbr>\nIâ€™m not worried we will run out of jobs. So many things need to be done that higher productivity is welcome. But, we\nshouldnâ€™t dismiss the short-term tumultuous nature of labor displacement. I recommend reading Daron Acemoglu and Simon\nJohnsonsâ€™\nbook â€œ\u003Ca href=\"https://www.amazon.com/Power-Progress-Thousand-Year-Technology-Prosperity/dp/1541702530\">Power and Progress\u003C/a>.â€\nWhile AI is inevitable, how we implement it is far from pre-determined. It will depend on the balance of power in\nmillions of workplaces, regulation, the outcome of fights about working conditions, compensation levels, and the\ndistribution of productivity gains. Portraying AI as an inevitable change is to make it too simple. We can influence\n\u003Cem>how\u003C/em> that change is implemented, and our actions during implementation will impact the quality of life for millions of\npeople. One example of bad implementation is\nthe \u003Ca href=\"https://www.linkedin.com/posts/daniellangkilde_this-is-unusual-for-me-but-i-feel-we-have-activity-7061967340048932865-Q_Co?utm_medium=member_desktop&#x26;utm_source=share\">exploitation of annotators\u003C/a>.\u003C/p>\n\u003Cp>**#5. AI cannot be regulated on speculation\u003Cbr>\n** Free-market democracy is the best way to enable all humans to live prosperous lives. There has always been a\ntemptation for those in power to think on behalf of other people. When a ruler thinks, â€œI know better,â€ you are about to\nget into trouble. Governments should fear the people, not the other way around. That does not mean we do not need some\nregulation.\nThe â€œ\u003Ca href=\"https://langkilde.se/post/2023-04-24-alignment-anthropocentrism-personalization\">tragedy of the commons\u003C/a>â€ is a\nreal thing. Some mechanisms are impossible to price into operating a business, so we need help. But, it is not clear\ntoday that AI poses a threat requiring regulation. We cannot regulate against hypotheticals, and most threats are\nhypothetical today. Waiting to regulate is better than imposing bad regulations like\nthe \u003Ca href=\"https://artificialintelligenceact.eu\">EU AI Act\u003C/a>. The EU AI Act is the first time something feels worse than GDPR.\nIâ€™m not against regulation that protects us from depleting common goods because we cannot price in negative\nexternalities, but I am against speculative regulation.\u003C/p>\n\u003Cp>**#6. AI needs to be shaped by liberal democracies\u003Cbr>\n** Iâ€™ve lived in China, and I speak decent Mandarin. The Chinese Communist Party (CCP) and its friends in Russia, Iran,\nand North Korea are a menace to humanity. These are autocratic countries without any respect for individual freedom and\nliberty. If you are gay in any of these countries, you face major legal and social challenges. If you build something\nvaluable, there is no guarantee the government wonâ€™t seize it. If you belong to the wrong ethnic minority, you might not\nbe allowed to practice your religious and ethnic beliefs. China views AI as an opportunity for more efficient population\ncontrol. Just read\nthe â€œ\u003Ca href=\"https://digichina.stanford.edu/work/full-translation-chinas-new-generation-artificial-intelligence-development-plan-2017/\">New Generation Artificial Intelligence Development Plan\u003C/a>.â€\u003C/p>\n\u003Cp>**#7. AI can and will reflect diverse human values and preferences\u003Cbr>\n** There is no â€œsystem free of moral bias.â€ Moral is, by definition, biased. Morals are concerned with the principles of\nright and wrong. Several moral systems have evolved over millennia and their merits are the subject of endless debate.\nCulture is the constant shaping of our moral system. The idea of creating a global AI free from bias is naive. Diversity\nis good and needs to be embraced. If we think we can force AI only to learn â€œgood things,â€ we will struggle. If we think\nwe can regulate against â€œbad things,â€ we will struggle. Letâ€™s instead defend every personâ€™s freedom. If we start\nconfusing AI regulation with the â€œwoke-anti-woke-continuum,â€ we are in trouble. AI will need to reflect the diversity of\nhumanity. Rather than unify all AIs, we will want ways to fine-tune systems to our preferences. I think our diversity of\npurpose is ultimately our best defense against AI. You cannot automate humans because we do not know why we exist.\u003C/p>\n\u003Cp>**#8. AI algorithms are being democratized fast\u003Cbr>\n** Iâ€™m not worried that a few large companies will monopolize AI. Companies like \u003Ca href=\"https://huggingface.co\">Hugging Face\u003C/a>\nand open-source models like \u003Ca href=\"https://huggingface.co/docs/transformers/main/model_doc/llama\">LLaMA\u003C/a>\nare \u003Ca href=\"https://www.semianalysis.com/p/google-we-have-no-moat-and-neither\">scaring the shit out of giant companies\u003C/a> like\nGoogle. And thatâ€™s a good thing! Proprietary data is what will differentiate models, but it looks like you might not\nneed as much as we feared. Even small amounts of fine-tuning can make your model uniquely valuable. This is good for\nconsumers.\u003C/p>\n\u003Cp>**#9. Increased volumes of synthetic information will make life different\u003Cbr>\n** Day by day, we are moving closer to being able to synthesize audio-visual information completely. Itâ€™s just a matter\nof time before anyone can â€œspoofâ€ your personality and pretend to be you. Algorithms can learn to look and talk like you\nfrom short audio and video snippets. With access to enough of your writing or voice recordings, such algorithms will\nalso be able to talk and write like you. This will make life different in interesting ways. Iâ€™m careful not to assume\nthis is bad. I think it will increase the value of journalism and it will contribute to a booming market for\nauthentication mechanisms. I will want proof of identity to talk.\u003C/p>\n\u003Cp>**#10. AI algorithms are currently bad for the environment\u003Cbr>\n** We have to make these systems less power-hungry. Currently, the amount of carbon emissions from training and\ninference is skyrocketing. This can be solved, but itâ€™s still pretty important and urgent.\u003C/p>\n\u003Cp>**#11. The emergence of self-improving systems is still hypothetical\u003Cbr>\n** The two central questions to the existential risk aspect that had me worried or even terrified are:\u003Cbr>\n\u003Cstrong>#11a.\u003C/strong> What is the probability that learning algorithms can become self-improving?\u003Cbr>\n\u003Cstrong>#11b.\u003C/strong> Once an algorithm asymptotically self-improves, what will it do?\u003Cbr>\nYour position on these largely determines if you are \u003Cem>for\u003C/em> or \u003Cem>against\u003C/em> AI. Some say we are so far away from\nself-improving systems that the entire premise is irrelevant. Some argue that the moment self-improvement kicks in,\nweâ€™re all screwed. Clearly, there is a control problem in the event of super-learners. At this point, I cannot reject\nthe possibility of self-improving algorithms. I acknowledge that itâ€™s scientifically possible that they will emerge. I\neven think they inevitably will at some point. But I have no idea how likely it is or when it will happen. And I do not\nthink it will happen soon. What will such a system do once it comes online? I have no idea. Anyone who claims to know is\nspeculating. In the end, I think itâ€™s a matter\nof \u003Ca href=\"https://langkilde.se/post/2023-04-06-artificial-intelligence-scaling-laws-s-curves-tail-risk-and-practicalities\">tail-risk hedging\u003C/a>.\nWhat do you do if there is a tiny, tiny probability of a really, really bad outcome? Iâ€™ve decided I will stay optimistic\ndespite such a risk.\u003C/p>\n\u003Cp>\u003Cstrong>Despite the risks and negative sides, Iâ€™m excited about AI! ðŸš€\u003C/strong> I have not seen enough evidence of imminent\nself-improvement to miss out on all the value we can create with AI. We should leverage advanced machine learning to\nimprove the world. If we are all more productive, we stand a better chance of enabling all humans to live prosperous\nlives. We will face challenges, but thatâ€™s always part of life.\u003C/p>\n\u003Cp>As long as humans remain in charge and we can \u003Cem>steer AI toward our goals\u003C/em> , the world will be better off!\u003C/p>",{"headings":1014,"localImagePaths":1015,"remoteImagePaths":1016,"frontmatter":1017,"imagePaths":1018},[],[],[],{"pubDate":1007,"title":1006},[],"why-i-am-excited-about-ai.md"]